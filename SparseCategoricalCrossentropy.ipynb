{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparseCategoricalCrossentropy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObI14i4s4n2UJz/I+WkuYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericalcaraz/Proyecto-CFGS/blob/master/SparseCategoricalCrossentropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESN8bzEL-h-g",
        "colab_type": "text"
      },
      "source": [
        "#Breast Cancer Neuronal Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8XBHaRs-WLk",
        "colab_type": "text"
      },
      "source": [
        "##Import all frameworks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVjo59QMStbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgDSHqhl-uW-",
        "colab_type": "text"
      },
      "source": [
        "##Upload breast cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBIgsL-0tesI",
        "colab_type": "code",
        "outputId": "e234b261-1bf1-4368-8bc1-70f0ec6d12dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "!git clone https://github.com/ericalcaraz/Proyecto-CFGS.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Proyecto-CFGS'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 18 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNiVN_FGtuQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Proyecto-CFGS/data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRNKTfZy-2nv",
        "colab_type": "text"
      },
      "source": [
        "##Modify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqawCEF_GRAp",
        "colab_type": "code",
        "outputId": "4f0798da-fc38-473b-d280-00b18d1d3f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPTJPJzIGwh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapdict = {'M':1,'B':0}\n",
        "df['diagnosis'] = df['diagnosis'].map(mapdict)\n",
        "df = df.drop(columns=['Unnamed: 32'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOORgIWG3wV",
        "colab_type": "code",
        "outputId": "1fad1256-029e-47d2-a621-61cbc6149b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>0</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0      842302          1  ...          0.4601                  0.11890\n",
              "1      842517          1  ...          0.2750                  0.08902\n",
              "2    84300903          1  ...          0.3613                  0.08758\n",
              "3    84348301          1  ...          0.6638                  0.17300\n",
              "4    84358402          1  ...          0.2364                  0.07678\n",
              "..        ...        ...  ...             ...                      ...\n",
              "564    926424          1  ...          0.2060                  0.07115\n",
              "565    926682          1  ...          0.2572                  0.06637\n",
              "566    926954          1  ...          0.2218                  0.07820\n",
              "567    927241          1  ...          0.4087                  0.12400\n",
              "568     92751          0  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd8LH4LEGUP6",
        "colab_type": "code",
        "outputId": "a35a22f5-7fe6-4a78-846f-db81f700f664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>0.372583</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>0.483918</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id   diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.690000e+02  569.000000  ...      569.000000               569.000000\n",
              "mean   3.037183e+07    0.372583  ...        0.290076                 0.083946\n",
              "std    1.250206e+08    0.483918  ...        0.061867                 0.018061\n",
              "min    8.670000e+03    0.000000  ...        0.156500                 0.055040\n",
              "25%    8.692180e+05    0.000000  ...        0.250400                 0.071460\n",
              "50%    9.060240e+05    0.000000  ...        0.282200                 0.080040\n",
              "75%    8.813129e+06    1.000000  ...        0.317900                 0.092080\n",
              "max    9.113205e+08    1.000000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omDLWgfcGSQS",
        "colab_type": "code",
        "outputId": "1683beed-f7cf-44f6-8e95-34cc480d455a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "df.corr()['diagnosis'].sort_values(ascending=[False])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis                  1.000000\n",
              "concave points_worst       0.793566\n",
              "perimeter_worst            0.782914\n",
              "concave points_mean        0.776614\n",
              "radius_worst               0.776454\n",
              "perimeter_mean             0.742636\n",
              "area_worst                 0.733825\n",
              "radius_mean                0.730029\n",
              "area_mean                  0.708984\n",
              "concavity_mean             0.696360\n",
              "concavity_worst            0.659610\n",
              "compactness_mean           0.596534\n",
              "compactness_worst          0.590998\n",
              "radius_se                  0.567134\n",
              "perimeter_se               0.556141\n",
              "area_se                    0.548236\n",
              "texture_worst              0.456903\n",
              "smoothness_worst           0.421465\n",
              "symmetry_worst             0.416294\n",
              "texture_mean               0.415185\n",
              "concave points_se          0.408042\n",
              "smoothness_mean            0.358560\n",
              "symmetry_mean              0.330499\n",
              "fractal_dimension_worst    0.323872\n",
              "compactness_se             0.292999\n",
              "concavity_se               0.253730\n",
              "fractal_dimension_se       0.077972\n",
              "id                         0.039769\n",
              "symmetry_se               -0.006522\n",
              "texture_se                -0.008303\n",
              "fractal_dimension_mean    -0.012838\n",
              "smoothness_se             -0.067016\n",
              "Name: diagnosis, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU5cJ1X4_Icc",
        "colab_type": "text"
      },
      "source": [
        "##Extract the data by **Features** and **Labels** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx_NI-PjTC_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1)\n",
        "labels = df['diagnosis']\n",
        "my_features = ['concave points_worst',\n",
        "               'perimeter_worst',\n",
        "               'concave points_mean',\n",
        "               'radius_worst',\n",
        "               'perimeter_mean',\n",
        "               'area_worst',\n",
        "               'radius_mean',\n",
        "               'area_mean',\n",
        "               'concavity_mean',\n",
        "               'concavity_worst',\n",
        "               'compactness_mean',\n",
        "               'compactness_worst'\n",
        "               ]\n",
        "features = df[my_features]\n",
        "labels = labels.to_numpy()\n",
        "features = features.to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfy7-7oHUq8I",
        "colab_type": "code",
        "outputId": "76c05532-471d-4547-ccd8-3bbcf858fffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(type(labels))\n",
        "print(type(features))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZtRmMMVEA9",
        "colab_type": "code",
        "outputId": "821fcbe3-7970-4c1b-d677-4511cf0ddbe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print('Labels')\n",
        "print(labels.shape, end=' ')\n",
        "print(labels.ndim)\n",
        "\n",
        "print('\\nFeatures:')\n",
        "print(features.shape, end=' ')\n",
        "print(features.ndim)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels\n",
            "(569,) 1\n",
            "\n",
            "Features:\n",
            "(569, 12) 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPMK5fBJ_PiU",
        "colab_type": "text"
      },
      "source": [
        "###Split the data between train, validation and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61qphebkCKqa",
        "colab_type": "text"
      },
      "source": [
        "Should try split more the data with train, validation and test data to check if the model is overfited."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdLnMS1LngbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Features & Targets Train\n",
        "train_features = features[:455]\n",
        "train_labels = labels[:455]\n",
        "\n",
        "#Features & Targets Validation\n",
        "validation_features = features[455:]\n",
        "validation_labels = labels[455:]\n",
        "\n",
        "# Test data\n",
        "test_features = train_features[:57]\n",
        "test_labels = train_labels[:57]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViiHvgJTgce7",
        "colab_type": "code",
        "outputId": "2eeb9b4a-fce3-4951-baa0-18283123773d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print('Train')\n",
        "print('Features: ', train_features.shape, end=' Labels: ')\n",
        "print(train_labels.shape)\n",
        "print('Validation')\n",
        "print('Features: ', validation_features.shape, end=' Labels: ')\n",
        "print(validation_labels.shape)\n",
        "print('Test')\n",
        "print('Features: ', test_features.shape, end=' Labels: ')\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Features:  (455, 12) Labels: (455,)\n",
            "Validation\n",
            "Features:  (114, 12) Labels: (114,)\n",
            "Test\n",
            "Features:  (57, 12) Labels: (57,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib9tJFsLcEma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = tf.convert_to_tensor(train_features, np.float64)\n",
        "train_labels = tf.convert_to_tensor(train_labels, np.float64)\n",
        "\n",
        "validation_features = tf.convert_to_tensor(validation_features, np.float64)\n",
        "validation_labels = tf.convert_to_tensor(validation_labels, np.float64)\n",
        "\n",
        "test_features = tf.convert_to_tensor(test_features, np.float64)\n",
        "test_labels = tf.convert_to_tensor(test_labels, np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqtO8GfTAN4D",
        "colab_type": "text"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTrjfobpZOxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_model(epochs, batch_size, lr):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(12, activation='relu', input_shape=[12]),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(2, activation='softmax'),\n",
        "  ])\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  trained = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    steps_per_epoch=len(train_features)//batch_size,\n",
        "    validation_steps=len(validation_features)//batch_size,\n",
        "    validation_data=(validation_features, validation_labels)\n",
        "  )\n",
        "  return trained, model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7DAJObTAgLB",
        "colab_type": "text"
      },
      "source": [
        "###Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q20syxnPZMaF",
        "colab_type": "code",
        "outputId": "56e51e09-62b3-459c-916f-06e086ff7394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history, model = my_model(epochs=150, batch_size=16, lr=0.00085)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "28/28 - 0s - loss: 39.0817 - accuracy: 0.4933 - val_loss: 5.2624 - val_accuracy: 0.4375\n",
            "Epoch 2/150\n",
            "28/28 - 0s - loss: 30.1794 - accuracy: 0.5125 - val_loss: 0.1555 - val_accuracy: 0.9196\n",
            "Epoch 3/150\n",
            "28/28 - 0s - loss: 21.9102 - accuracy: 0.4943 - val_loss: 0.1938 - val_accuracy: 0.9286\n",
            "Epoch 4/150\n",
            "28/28 - 0s - loss: 15.0322 - accuracy: 0.5080 - val_loss: 0.1700 - val_accuracy: 0.9375\n",
            "Epoch 5/150\n",
            "28/28 - 0s - loss: 13.4881 - accuracy: 0.5376 - val_loss: 0.4868 - val_accuracy: 0.8661\n",
            "Epoch 6/150\n",
            "28/28 - 0s - loss: 10.6439 - accuracy: 0.5285 - val_loss: 0.3175 - val_accuracy: 0.8750\n",
            "Epoch 7/150\n",
            "28/28 - 0s - loss: 10.6871 - accuracy: 0.5239 - val_loss: 0.4493 - val_accuracy: 0.8393\n",
            "Epoch 8/150\n",
            "28/28 - 0s - loss: 7.4024 - accuracy: 0.5718 - val_loss: 0.6824 - val_accuracy: 0.8036\n",
            "Epoch 9/150\n",
            "28/28 - 0s - loss: 8.0943 - accuracy: 0.5399 - val_loss: 0.8333 - val_accuracy: 0.6875\n",
            "Epoch 10/150\n",
            "28/28 - 0s - loss: 5.3008 - accuracy: 0.6219 - val_loss: 0.2557 - val_accuracy: 0.9018\n",
            "Epoch 11/150\n",
            "28/28 - 0s - loss: 5.6432 - accuracy: 0.6173 - val_loss: 0.2747 - val_accuracy: 0.8929\n",
            "Epoch 12/150\n",
            "28/28 - 0s - loss: 5.4640 - accuracy: 0.5672 - val_loss: 0.3632 - val_accuracy: 0.8482\n",
            "Epoch 13/150\n",
            "28/28 - 0s - loss: 4.3505 - accuracy: 0.5945 - val_loss: 0.1764 - val_accuracy: 0.9196\n",
            "Epoch 14/150\n",
            "28/28 - 0s - loss: 3.5244 - accuracy: 0.6492 - val_loss: 0.4839 - val_accuracy: 0.8125\n",
            "Epoch 15/150\n",
            "28/28 - 0s - loss: 3.6563 - accuracy: 0.6128 - val_loss: 0.2950 - val_accuracy: 0.9018\n",
            "Epoch 16/150\n",
            "28/28 - 0s - loss: 3.5260 - accuracy: 0.6538 - val_loss: 0.1861 - val_accuracy: 0.9375\n",
            "Epoch 17/150\n",
            "28/28 - 0s - loss: 2.5554 - accuracy: 0.6743 - val_loss: 0.3169 - val_accuracy: 0.8750\n",
            "Epoch 18/150\n",
            "28/28 - 0s - loss: 2.5736 - accuracy: 0.6355 - val_loss: 0.2241 - val_accuracy: 0.9375\n",
            "Epoch 19/150\n",
            "28/28 - 0s - loss: 2.2780 - accuracy: 0.7084 - val_loss: 0.1841 - val_accuracy: 0.9554\n",
            "Epoch 20/150\n",
            "28/28 - 0s - loss: 2.1850 - accuracy: 0.6424 - val_loss: 0.2372 - val_accuracy: 0.9107\n",
            "Epoch 21/150\n",
            "28/28 - 0s - loss: 1.7551 - accuracy: 0.7198 - val_loss: 0.1958 - val_accuracy: 0.9464\n",
            "Epoch 22/150\n",
            "28/28 - 0s - loss: 2.3086 - accuracy: 0.6287 - val_loss: 0.1572 - val_accuracy: 0.9286\n",
            "Epoch 23/150\n",
            "28/28 - 0s - loss: 1.4793 - accuracy: 0.7472 - val_loss: 0.1597 - val_accuracy: 0.9464\n",
            "Epoch 24/150\n",
            "28/28 - 0s - loss: 1.7968 - accuracy: 0.7221 - val_loss: 0.1674 - val_accuracy: 0.9375\n",
            "Epoch 25/150\n",
            "28/28 - 0s - loss: 1.3451 - accuracy: 0.7631 - val_loss: 0.1643 - val_accuracy: 0.9554\n",
            "Epoch 26/150\n",
            "28/28 - 0s - loss: 1.5074 - accuracy: 0.7312 - val_loss: 0.1732 - val_accuracy: 0.9554\n",
            "Epoch 27/150\n",
            "28/28 - 0s - loss: 1.1537 - accuracy: 0.7563 - val_loss: 0.2196 - val_accuracy: 0.9375\n",
            "Epoch 28/150\n",
            "28/28 - 0s - loss: 1.3684 - accuracy: 0.7130 - val_loss: 0.1823 - val_accuracy: 0.9464\n",
            "Epoch 29/150\n",
            "28/28 - 0s - loss: 1.0927 - accuracy: 0.7677 - val_loss: 0.2010 - val_accuracy: 0.9375\n",
            "Epoch 30/150\n",
            "28/28 - 0s - loss: 1.0459 - accuracy: 0.7567 - val_loss: 0.1858 - val_accuracy: 0.9286\n",
            "Epoch 31/150\n",
            "28/28 - 0s - loss: 1.0708 - accuracy: 0.7403 - val_loss: 0.1890 - val_accuracy: 0.9464\n",
            "Epoch 32/150\n",
            "28/28 - 0s - loss: 0.9553 - accuracy: 0.7768 - val_loss: 0.1799 - val_accuracy: 0.9464\n",
            "Epoch 33/150\n",
            "28/28 - 0s - loss: 0.9123 - accuracy: 0.7563 - val_loss: 0.1717 - val_accuracy: 0.9286\n",
            "Epoch 34/150\n",
            "28/28 - 0s - loss: 0.8055 - accuracy: 0.7585 - val_loss: 0.1610 - val_accuracy: 0.9375\n",
            "Epoch 35/150\n",
            "28/28 - 0s - loss: 0.7762 - accuracy: 0.7677 - val_loss: 0.1668 - val_accuracy: 0.9464\n",
            "Epoch 36/150\n",
            "28/28 - 0s - loss: 1.0941 - accuracy: 0.7472 - val_loss: 0.1921 - val_accuracy: 0.9554\n",
            "Epoch 37/150\n",
            "28/28 - 0s - loss: 0.7242 - accuracy: 0.7882 - val_loss: 0.1976 - val_accuracy: 0.9375\n",
            "Epoch 38/150\n",
            "28/28 - 0s - loss: 0.8103 - accuracy: 0.7540 - val_loss: 0.1737 - val_accuracy: 0.9375\n",
            "Epoch 39/150\n",
            "28/28 - 0s - loss: 0.7545 - accuracy: 0.7927 - val_loss: 0.1861 - val_accuracy: 0.9464\n",
            "Epoch 40/150\n",
            "28/28 - 0s - loss: 0.6473 - accuracy: 0.8018 - val_loss: 0.1827 - val_accuracy: 0.9375\n",
            "Epoch 41/150\n",
            "28/28 - 0s - loss: 0.6703 - accuracy: 0.8451 - val_loss: 0.1834 - val_accuracy: 0.9375\n",
            "Epoch 42/150\n",
            "28/28 - 0s - loss: 0.7091 - accuracy: 0.8064 - val_loss: 0.1958 - val_accuracy: 0.9375\n",
            "Epoch 43/150\n",
            "28/28 - 0s - loss: 0.6305 - accuracy: 0.7995 - val_loss: 0.1962 - val_accuracy: 0.9464\n",
            "Epoch 44/150\n",
            "28/28 - 0s - loss: 0.7420 - accuracy: 0.8018 - val_loss: 0.1947 - val_accuracy: 0.9375\n",
            "Epoch 45/150\n",
            "28/28 - 0s - loss: 0.5829 - accuracy: 0.8337 - val_loss: 0.2032 - val_accuracy: 0.9375\n",
            "Epoch 46/150\n",
            "28/28 - 0s - loss: 0.6118 - accuracy: 0.8087 - val_loss: 0.2123 - val_accuracy: 0.9286\n",
            "Epoch 47/150\n",
            "28/28 - 0s - loss: 0.5412 - accuracy: 0.8178 - val_loss: 0.2006 - val_accuracy: 0.9464\n",
            "Epoch 48/150\n",
            "28/28 - 0s - loss: 0.5867 - accuracy: 0.8018 - val_loss: 0.2037 - val_accuracy: 0.9375\n",
            "Epoch 49/150\n",
            "28/28 - 0s - loss: 0.5803 - accuracy: 0.8292 - val_loss: 0.2036 - val_accuracy: 0.9464\n",
            "Epoch 50/150\n",
            "28/28 - 0s - loss: 0.6018 - accuracy: 0.8246 - val_loss: 0.2241 - val_accuracy: 0.9196\n",
            "Epoch 51/150\n",
            "28/28 - 0s - loss: 0.4334 - accuracy: 0.8383 - val_loss: 0.2260 - val_accuracy: 0.9196\n",
            "Epoch 52/150\n",
            "28/28 - 0s - loss: 0.4673 - accuracy: 0.8497 - val_loss: 0.2109 - val_accuracy: 0.9196\n",
            "Epoch 53/150\n",
            "28/28 - 0s - loss: 0.4467 - accuracy: 0.8405 - val_loss: 0.2018 - val_accuracy: 0.9286\n",
            "Epoch 54/150\n",
            "28/28 - 0s - loss: 0.3806 - accuracy: 0.8428 - val_loss: 0.1969 - val_accuracy: 0.9375\n",
            "Epoch 55/150\n",
            "28/28 - 0s - loss: 0.6025 - accuracy: 0.8246 - val_loss: 0.1975 - val_accuracy: 0.9286\n",
            "Epoch 56/150\n",
            "28/28 - 0s - loss: 0.4012 - accuracy: 0.8588 - val_loss: 0.2030 - val_accuracy: 0.9196\n",
            "Epoch 57/150\n",
            "28/28 - 0s - loss: 0.4083 - accuracy: 0.8656 - val_loss: 0.1926 - val_accuracy: 0.9286\n",
            "Epoch 58/150\n",
            "28/28 - 0s - loss: 0.3944 - accuracy: 0.8497 - val_loss: 0.1950 - val_accuracy: 0.9286\n",
            "Epoch 59/150\n",
            "28/28 - 0s - loss: 0.4035 - accuracy: 0.8594 - val_loss: 0.1913 - val_accuracy: 0.9286\n",
            "Epoch 60/150\n",
            "28/28 - 0s - loss: 0.3483 - accuracy: 0.8815 - val_loss: 0.1904 - val_accuracy: 0.9286\n",
            "Epoch 61/150\n",
            "28/28 - 0s - loss: 0.3466 - accuracy: 0.8702 - val_loss: 0.1909 - val_accuracy: 0.9375\n",
            "Epoch 62/150\n",
            "28/28 - 0s - loss: 0.3291 - accuracy: 0.8770 - val_loss: 0.1933 - val_accuracy: 0.9375\n",
            "Epoch 63/150\n",
            "28/28 - 0s - loss: 0.2840 - accuracy: 0.8929 - val_loss: 0.2020 - val_accuracy: 0.9375\n",
            "Epoch 64/150\n",
            "28/28 - 0s - loss: 0.4243 - accuracy: 0.8633 - val_loss: 0.2093 - val_accuracy: 0.9286\n",
            "Epoch 65/150\n",
            "28/28 - 0s - loss: 0.3304 - accuracy: 0.8838 - val_loss: 0.2125 - val_accuracy: 0.9196\n",
            "Epoch 66/150\n",
            "28/28 - 0s - loss: 0.3407 - accuracy: 0.8747 - val_loss: 0.1977 - val_accuracy: 0.9286\n",
            "Epoch 67/150\n",
            "28/28 - 0s - loss: 0.3258 - accuracy: 0.8793 - val_loss: 0.2021 - val_accuracy: 0.9196\n",
            "Epoch 68/150\n",
            "28/28 - 0s - loss: 0.3200 - accuracy: 0.8747 - val_loss: 0.1897 - val_accuracy: 0.9196\n",
            "Epoch 69/150\n",
            "28/28 - 0s - loss: 0.2977 - accuracy: 0.8679 - val_loss: 0.1805 - val_accuracy: 0.9286\n",
            "Epoch 70/150\n",
            "28/28 - 0s - loss: 0.3228 - accuracy: 0.8724 - val_loss: 0.1745 - val_accuracy: 0.9464\n",
            "Epoch 71/150\n",
            "28/28 - 0s - loss: 0.3206 - accuracy: 0.8724 - val_loss: 0.1831 - val_accuracy: 0.9375\n",
            "Epoch 72/150\n",
            "28/28 - 0s - loss: 0.2685 - accuracy: 0.8975 - val_loss: 0.1876 - val_accuracy: 0.9286\n",
            "Epoch 73/150\n",
            "28/28 - 0s - loss: 0.2457 - accuracy: 0.9043 - val_loss: 0.1887 - val_accuracy: 0.9196\n",
            "Epoch 74/150\n",
            "28/28 - 0s - loss: 0.2545 - accuracy: 0.9089 - val_loss: 0.1764 - val_accuracy: 0.9375\n",
            "Epoch 75/150\n",
            "28/28 - 0s - loss: 0.3161 - accuracy: 0.8907 - val_loss: 0.1823 - val_accuracy: 0.9375\n",
            "Epoch 76/150\n",
            "28/28 - 0s - loss: 0.2507 - accuracy: 0.9112 - val_loss: 0.1804 - val_accuracy: 0.9286\n",
            "Epoch 77/150\n",
            "28/28 - 0s - loss: 0.3162 - accuracy: 0.8747 - val_loss: 0.1826 - val_accuracy: 0.9196\n",
            "Epoch 78/150\n",
            "28/28 - 0s - loss: 0.2398 - accuracy: 0.8998 - val_loss: 0.1716 - val_accuracy: 0.9286\n",
            "Epoch 79/150\n",
            "28/28 - 0s - loss: 0.2489 - accuracy: 0.9066 - val_loss: 0.1678 - val_accuracy: 0.9286\n",
            "Epoch 80/150\n",
            "28/28 - 0s - loss: 0.3036 - accuracy: 0.8861 - val_loss: 0.1701 - val_accuracy: 0.9464\n",
            "Epoch 81/150\n",
            "28/28 - 0s - loss: 0.2573 - accuracy: 0.9021 - val_loss: 0.1724 - val_accuracy: 0.9375\n",
            "Epoch 82/150\n",
            "28/28 - 0s - loss: 0.2435 - accuracy: 0.9066 - val_loss: 0.1750 - val_accuracy: 0.9107\n",
            "Epoch 83/150\n",
            "28/28 - 0s - loss: 0.3011 - accuracy: 0.8998 - val_loss: 0.1726 - val_accuracy: 0.9375\n",
            "Epoch 84/150\n",
            "28/28 - 0s - loss: 0.2507 - accuracy: 0.8975 - val_loss: 0.1787 - val_accuracy: 0.9286\n",
            "Epoch 85/150\n",
            "28/28 - 0s - loss: 0.2229 - accuracy: 0.9226 - val_loss: 0.1841 - val_accuracy: 0.9107\n",
            "Epoch 86/150\n",
            "28/28 - 0s - loss: 0.2391 - accuracy: 0.9043 - val_loss: 0.1787 - val_accuracy: 0.9107\n",
            "Epoch 87/150\n",
            "28/28 - 0s - loss: 0.2358 - accuracy: 0.8998 - val_loss: 0.1773 - val_accuracy: 0.9107\n",
            "Epoch 88/150\n",
            "28/28 - 0s - loss: 0.2363 - accuracy: 0.9107 - val_loss: 0.1752 - val_accuracy: 0.9286\n",
            "Epoch 89/150\n",
            "28/28 - 0s - loss: 0.2340 - accuracy: 0.8952 - val_loss: 0.1716 - val_accuracy: 0.9196\n",
            "Epoch 90/150\n",
            "28/28 - 0s - loss: 0.2536 - accuracy: 0.9226 - val_loss: 0.1701 - val_accuracy: 0.9464\n",
            "Epoch 91/150\n",
            "28/28 - 0s - loss: 0.2320 - accuracy: 0.9089 - val_loss: 0.1785 - val_accuracy: 0.9286\n",
            "Epoch 92/150\n",
            "28/28 - 0s - loss: 0.2482 - accuracy: 0.9157 - val_loss: 0.1685 - val_accuracy: 0.9464\n",
            "Epoch 93/150\n",
            "28/28 - 0s - loss: 0.1918 - accuracy: 0.9248 - val_loss: 0.1658 - val_accuracy: 0.9464\n",
            "Epoch 94/150\n",
            "28/28 - 0s - loss: 0.2370 - accuracy: 0.9112 - val_loss: 0.1729 - val_accuracy: 0.9196\n",
            "Epoch 95/150\n",
            "28/28 - 0s - loss: 0.2462 - accuracy: 0.8907 - val_loss: 0.1796 - val_accuracy: 0.9286\n",
            "Epoch 96/150\n",
            "28/28 - 0s - loss: 0.2325 - accuracy: 0.9089 - val_loss: 0.1762 - val_accuracy: 0.9286\n",
            "Epoch 97/150\n",
            "28/28 - 0s - loss: 0.2003 - accuracy: 0.9271 - val_loss: 0.1640 - val_accuracy: 0.9464\n",
            "Epoch 98/150\n",
            "28/28 - 0s - loss: 0.2317 - accuracy: 0.9134 - val_loss: 0.1672 - val_accuracy: 0.9464\n",
            "Epoch 99/150\n",
            "28/28 - 0s - loss: 0.2006 - accuracy: 0.9157 - val_loss: 0.1765 - val_accuracy: 0.9286\n",
            "Epoch 100/150\n",
            "28/28 - 0s - loss: 0.2183 - accuracy: 0.9066 - val_loss: 0.1768 - val_accuracy: 0.9286\n",
            "Epoch 101/150\n",
            "28/28 - 0s - loss: 0.2282 - accuracy: 0.9043 - val_loss: 0.1771 - val_accuracy: 0.9286\n",
            "Epoch 102/150\n",
            "28/28 - 0s - loss: 0.1786 - accuracy: 0.9226 - val_loss: 0.1771 - val_accuracy: 0.9286\n",
            "Epoch 103/150\n",
            "28/28 - 0s - loss: 0.2173 - accuracy: 0.9157 - val_loss: 0.1552 - val_accuracy: 0.9375\n",
            "Epoch 104/150\n",
            "28/28 - 0s - loss: 0.2110 - accuracy: 0.9180 - val_loss: 0.1722 - val_accuracy: 0.9375\n",
            "Epoch 105/150\n",
            "28/28 - 0s - loss: 0.2010 - accuracy: 0.9134 - val_loss: 0.1716 - val_accuracy: 0.9375\n",
            "Epoch 106/150\n",
            "28/28 - 0s - loss: 0.2175 - accuracy: 0.9043 - val_loss: 0.1724 - val_accuracy: 0.9375\n",
            "Epoch 107/150\n",
            "28/28 - 0s - loss: 0.1953 - accuracy: 0.9112 - val_loss: 0.1708 - val_accuracy: 0.9375\n",
            "Epoch 108/150\n",
            "28/28 - 0s - loss: 0.1972 - accuracy: 0.9226 - val_loss: 0.1608 - val_accuracy: 0.9464\n",
            "Epoch 109/150\n",
            "28/28 - 0s - loss: 0.2246 - accuracy: 0.9043 - val_loss: 0.1608 - val_accuracy: 0.9464\n",
            "Epoch 110/150\n",
            "28/28 - 0s - loss: 0.2165 - accuracy: 0.9089 - val_loss: 0.1711 - val_accuracy: 0.9375\n",
            "Epoch 111/150\n",
            "28/28 - 0s - loss: 0.1867 - accuracy: 0.9180 - val_loss: 0.1713 - val_accuracy: 0.9286\n",
            "Epoch 112/150\n",
            "28/28 - 0s - loss: 0.2170 - accuracy: 0.9089 - val_loss: 0.1563 - val_accuracy: 0.9375\n",
            "Epoch 113/150\n",
            "28/28 - 0s - loss: 0.1964 - accuracy: 0.9134 - val_loss: 0.1732 - val_accuracy: 0.9286\n",
            "Epoch 114/150\n",
            "28/28 - 0s - loss: 0.2058 - accuracy: 0.9112 - val_loss: 0.1772 - val_accuracy: 0.9286\n",
            "Epoch 115/150\n",
            "28/28 - 0s - loss: 0.2012 - accuracy: 0.9180 - val_loss: 0.1762 - val_accuracy: 0.9286\n",
            "Epoch 116/150\n",
            "28/28 - 0s - loss: 0.2034 - accuracy: 0.9248 - val_loss: 0.1896 - val_accuracy: 0.9196\n",
            "Epoch 117/150\n",
            "28/28 - 0s - loss: 0.2239 - accuracy: 0.9174 - val_loss: 0.1816 - val_accuracy: 0.9286\n",
            "Epoch 118/150\n",
            "28/28 - 0s - loss: 0.1958 - accuracy: 0.9226 - val_loss: 0.1791 - val_accuracy: 0.9286\n",
            "Epoch 119/150\n",
            "28/28 - 0s - loss: 0.2190 - accuracy: 0.9112 - val_loss: 0.1747 - val_accuracy: 0.9286\n",
            "Epoch 120/150\n",
            "28/28 - 0s - loss: 0.2078 - accuracy: 0.9271 - val_loss: 0.1749 - val_accuracy: 0.9375\n",
            "Epoch 121/150\n",
            "28/28 - 0s - loss: 0.2185 - accuracy: 0.9089 - val_loss: 0.1641 - val_accuracy: 0.9375\n",
            "Epoch 122/150\n",
            "28/28 - 0s - loss: 0.2090 - accuracy: 0.9066 - val_loss: 0.1704 - val_accuracy: 0.9375\n",
            "Epoch 123/150\n",
            "28/28 - 0s - loss: 0.2016 - accuracy: 0.9294 - val_loss: 0.1777 - val_accuracy: 0.9196\n",
            "Epoch 124/150\n",
            "28/28 - 0s - loss: 0.1944 - accuracy: 0.9248 - val_loss: 0.1705 - val_accuracy: 0.9375\n",
            "Epoch 125/150\n",
            "28/28 - 0s - loss: 0.1941 - accuracy: 0.9180 - val_loss: 0.1727 - val_accuracy: 0.9196\n",
            "Epoch 126/150\n",
            "28/28 - 0s - loss: 0.2022 - accuracy: 0.9294 - val_loss: 0.1686 - val_accuracy: 0.9196\n",
            "Epoch 127/150\n",
            "28/28 - 0s - loss: 0.2093 - accuracy: 0.9180 - val_loss: 0.1749 - val_accuracy: 0.9286\n",
            "Epoch 128/150\n",
            "28/28 - 0s - loss: 0.1920 - accuracy: 0.9226 - val_loss: 0.1693 - val_accuracy: 0.9286\n",
            "Epoch 129/150\n",
            "28/28 - 0s - loss: 0.2171 - accuracy: 0.8998 - val_loss: 0.1757 - val_accuracy: 0.9375\n",
            "Epoch 130/150\n",
            "28/28 - 0s - loss: 0.1838 - accuracy: 0.9294 - val_loss: 0.1650 - val_accuracy: 0.9375\n",
            "Epoch 131/150\n",
            "28/28 - 0s - loss: 0.2454 - accuracy: 0.9066 - val_loss: 0.1704 - val_accuracy: 0.9375\n",
            "Epoch 132/150\n",
            "28/28 - 0s - loss: 0.1785 - accuracy: 0.9362 - val_loss: 0.1678 - val_accuracy: 0.9286\n",
            "Epoch 133/150\n",
            "28/28 - 0s - loss: 0.2219 - accuracy: 0.9134 - val_loss: 0.1669 - val_accuracy: 0.9286\n",
            "Epoch 134/150\n",
            "28/28 - 0s - loss: 0.1845 - accuracy: 0.9203 - val_loss: 0.1749 - val_accuracy: 0.9286\n",
            "Epoch 135/150\n",
            "28/28 - 0s - loss: 0.2023 - accuracy: 0.9203 - val_loss: 0.1735 - val_accuracy: 0.9286\n",
            "Epoch 136/150\n",
            "28/28 - 0s - loss: 0.1973 - accuracy: 0.9180 - val_loss: 0.1755 - val_accuracy: 0.9375\n",
            "Epoch 137/150\n",
            "28/28 - 0s - loss: 0.2190 - accuracy: 0.9112 - val_loss: 0.1759 - val_accuracy: 0.9286\n",
            "Epoch 138/150\n",
            "28/28 - 0s - loss: 0.1851 - accuracy: 0.9271 - val_loss: 0.1693 - val_accuracy: 0.9286\n",
            "Epoch 139/150\n",
            "28/28 - 0s - loss: 0.1762 - accuracy: 0.9203 - val_loss: 0.1710 - val_accuracy: 0.9375\n",
            "Epoch 140/150\n",
            "28/28 - 0s - loss: 0.1988 - accuracy: 0.9134 - val_loss: 0.1850 - val_accuracy: 0.9196\n",
            "Epoch 141/150\n",
            "28/28 - 0s - loss: 0.1904 - accuracy: 0.9248 - val_loss: 0.1689 - val_accuracy: 0.9286\n",
            "Epoch 142/150\n",
            "28/28 - 0s - loss: 0.2429 - accuracy: 0.9066 - val_loss: 0.1753 - val_accuracy: 0.9286\n",
            "Epoch 143/150\n",
            "28/28 - 0s - loss: 0.1899 - accuracy: 0.9248 - val_loss: 0.1742 - val_accuracy: 0.9196\n",
            "Epoch 144/150\n",
            "28/28 - 0s - loss: 0.2011 - accuracy: 0.9203 - val_loss: 0.1737 - val_accuracy: 0.9286\n",
            "Epoch 145/150\n",
            "28/28 - 0s - loss: 0.1727 - accuracy: 0.9294 - val_loss: 0.1730 - val_accuracy: 0.9375\n",
            "Epoch 146/150\n",
            "28/28 - 0s - loss: 0.2044 - accuracy: 0.9129 - val_loss: 0.1770 - val_accuracy: 0.9286\n",
            "Epoch 147/150\n",
            "28/28 - 0s - loss: 0.2018 - accuracy: 0.9157 - val_loss: 0.1783 - val_accuracy: 0.9286\n",
            "Epoch 148/150\n",
            "28/28 - 0s - loss: 0.1803 - accuracy: 0.9226 - val_loss: 0.1774 - val_accuracy: 0.9286\n",
            "Epoch 149/150\n",
            "28/28 - 0s - loss: 0.2256 - accuracy: 0.8975 - val_loss: 0.1762 - val_accuracy: 0.9286\n",
            "Epoch 150/150\n",
            "28/28 - 0s - loss: 0.1988 - accuracy: 0.9248 - val_loss: 0.1802 - val_accuracy: 0.9286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VYI19E1ZiS2",
        "colab_type": "code",
        "outputId": "07d11b1a-6e98-4e6b-8fc8-099d9e76367f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERMbcBlTAoE5",
        "colab_type": "text"
      },
      "source": [
        "###Show loss and accuaracy per epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnBEioJ7XMPz",
        "colab_type": "code",
        "outputId": "32a81a1d-349b-4c16-a4cc-e500f20667e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(150)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUbcv-JYAvJB",
        "colab_type": "text"
      },
      "source": [
        "###Predict values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQHvN7bupzYp",
        "colab_type": "code",
        "outputId": "4fd3f1fb-580e-4935-ea0f-ce149290d28f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "example = df.iloc[[100]]\n",
        "print(f\"Label: {example['diagnosis']}\")\n",
        "data = (example[my_features]).to_numpy()\n",
        "data = tf.convert_to_tensor(data)\n",
        "print(data)\n",
        "model.predict(data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1    1\n",
            "Name: diagnosis, dtype: int64\n",
            "tf.Tensor(\n",
            "[[1.860e-01 1.588e+02 7.017e-02 2.499e+01 1.329e+02 1.956e+03 2.057e+01\n",
            "  1.326e+03 8.690e-02 2.416e-01 7.864e-02 1.866e-01]], shape=(1, 12), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.2748868e-06, 9.9999774e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StNIVwB5aQ8h",
        "colab_type": "text"
      },
      "source": [
        "### Use test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAtQONUcg2lK",
        "colab_type": "code",
        "outputId": "f7968c1d-4bd0-4c7e-8e87-6941c3749d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(len(tf.keras.backend.get_value(test_features)))\n",
        "for test_feature, test_label in zip(test_features, test_labels):\n",
        "  true_label = tf.keras.backend.get_value(test_label)\n",
        "  print(f'Label: {true_label}', end=\"\")\n",
        "\n",
        "  test_feature = tf.expand_dims(test_feature, 0)\n",
        "  predicted = model.predict([[test_feature]])[0]\n",
        "  \n",
        "  if predicted[0] > predicted[1]:\n",
        "    if true_label == 0.0:\n",
        "      print(predicted, \"\\U0000274E\" + \"\\n\")\n",
        "    else:\n",
        "      print(predicted, \"\\U0000274C\" + \"\\n\")\n",
        "  else:\n",
        "    if true_label == 1.0:\n",
        "      print(predicted, \"\\U00002705\" + \"\\n\")\n",
        "    else:\n",
        "      print(predicted, \"\\U0000274C\" + \"\\n\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57\n",
            "Label: 0.0[0.9951515 0.0048484] ❎\n",
            "\n",
            "Label: 0.0[0.85257906 0.14742097] ❎\n",
            "\n",
            "Label: 0.0[0.82908475 0.17091523] ❎\n",
            "\n",
            "Label: 0.0[0.9547129  0.04528709] ❎\n",
            "\n",
            "Label: 1.0[0.09020605 0.909794  ] ✅\n",
            "\n",
            "Label: 1.0[2.6684577e-06 9.9999738e-01] ✅\n",
            "\n",
            "Label: 0.0[0.97588646 0.02411349] ❎\n",
            "\n",
            "Label: 0.0[0.77612174 0.22387823] ❎\n",
            "\n",
            "Label: 1.0[0.34076104 0.659239  ] ✅\n",
            "\n",
            "Label: 0.0[0.99568427 0.0043157 ] ❎\n",
            "\n",
            "Label: 1.0[0.23347689 0.7665231 ] ✅\n",
            "\n",
            "Label: 0.0[0.8443728 0.1556272] ❎\n",
            "\n",
            "Label: 0.0[0.87876076 0.1212393 ] ❎\n",
            "\n",
            "Label: 0.0[0.84569794 0.1543021 ] ❎\n",
            "\n",
            "Label: 1.0[4.8056695e-06 9.9999523e-01] ✅\n",
            "\n",
            "Label: 1.0[0.13953006 0.86046994] ✅\n",
            "\n",
            "Label: 0.0[0.9860314  0.01396856] ❎\n",
            "\n",
            "Label: 0.0[0.9812143 0.0187857] ❎\n",
            "\n",
            "Label: 1.0[2.8943852e-05 9.9997103e-01] ✅\n",
            "\n",
            "Label: 0.0[0.8880851  0.11191487] ❎\n",
            "\n",
            "Label: 0.0[0.9582748  0.04172526] ❎\n",
            "\n",
            "Label: 0.0[0.9362856  0.06371434] ❎\n",
            "\n",
            "Label: 0.0[0.86623967 0.13376029] ❎\n",
            "\n",
            "Label: 0.0[0.6538577 0.3461423] ❎\n",
            "\n",
            "Label: 0.0[0.99484706 0.00515289] ❎\n",
            "\n",
            "Label: 0.0[0.9663212  0.03367883] ❎\n",
            "\n",
            "Label: 0.0[0.8930301  0.10696989] ❎\n",
            "\n",
            "Label: 0.0[0.9190064  0.08099356] ❎\n",
            "\n",
            "Label: 1.0[0.00118609 0.998814  ] ✅\n",
            "\n",
            "Label: 0.0[0.9712246  0.02877533] ❎\n",
            "\n",
            "Label: 0.0[0.7995657  0.20043431] ❎\n",
            "\n",
            "Label: 1.0[0.00319249 0.9968076 ] ✅\n",
            "\n",
            "Label: 0.0[0.97993714 0.02006279] ❎\n",
            "\n",
            "Label: 0.0[0.82202387 0.17797615] ❎\n",
            "\n",
            "Label: 0.0[0.9956204  0.00437959] ❎\n",
            "\n",
            "Label: 0.0[0.8696999  0.13030006] ❎\n",
            "\n",
            "Label: 1.0[1.1554002e-16 1.0000000e+00] ✅\n",
            "\n",
            "Label: 0.0[0.9600141 0.0399859] ❎\n",
            "\n",
            "Label: 0.0[0.99172604 0.00827391] ❎\n",
            "\n",
            "Label: 1.0[2.738676e-04 9.997261e-01] ✅\n",
            "\n",
            "Label: 1.0[0.48789442 0.51210564] ✅\n",
            "\n",
            "Label: 1.0[4.0002342e-04 9.9959999e-01] ✅\n",
            "\n",
            "Label: 1.0[0.02250424 0.9774958 ] ✅\n",
            "\n",
            "Label: 0.0[0.982002   0.01799792] ❎\n",
            "\n",
            "Label: 0.0[0.86842746 0.13157253] ❎\n",
            "\n",
            "Label: 0.0[0.7349315  0.26506844] ❎\n",
            "\n",
            "Label: 0.0[0.80344033 0.19655965] ❎\n",
            "\n",
            "Label: 1.0[0.15071335 0.8492866 ] ✅\n",
            "\n",
            "Label: 0.0[0.9888609  0.01113905] ❎\n",
            "\n",
            "Label: 1.0[6.765675e-06 9.999932e-01] ✅\n",
            "\n",
            "Label: 1.0[0.00116132 0.9988387 ] ✅\n",
            "\n",
            "Label: 0.0[0.91481715 0.08518282] ❎\n",
            "\n",
            "Label: 0.0[0.8279937  0.17200632] ❎\n",
            "\n",
            "Label: 1.0[0.00517077 0.99482924] ✅\n",
            "\n",
            "Label: 0.0[0.8637226  0.13627735] ❎\n",
            "\n",
            "Label: 0.0[0.86856025 0.13143975] ❎\n",
            "\n",
            "Label: 0.0[0.97437716 0.02562281] ❎\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq5PFENCetjg",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vohvQk8ZW2ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db7B8W23XBap",
        "colab_type": "code",
        "outputId": "759896d8-fb58-456b-d3cf-634f05c778e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5  Proyecto-CFGS  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xx6BIrEfA6f",
        "colab_type": "text"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD6j2J8SXCin",
        "colab_type": "code",
        "outputId": "25fa246a-5f5e-41b5-b8ce-ae74472338e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded = tf.keras.models.load_model('./model.h5')\n",
        "reloaded.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0SGgodQfDjC",
        "colab_type": "text"
      },
      "source": [
        "Check both models will predict the same value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yacss5PrX_Tz",
        "colab_type": "code",
        "outputId": "503fdf60-9c42-4c64-d6de-ec296d2f6edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "example = df.iloc[[100]]\n",
        "print(f\"Label: {example['diagnosis']}\")\n",
        "data = (example[my_features]).to_numpy()\n",
        "data = tf.convert_to_tensor(data)\n",
        "print(data)\n",
        "print(model.predict(data))\n",
        "print(reloaded.predict(data))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 1    1\n",
            "Name: diagnosis, dtype: int64\n",
            "tf.Tensor(\n",
            "[[1.860e-01 1.588e+02 7.017e-02 2.499e+01 1.329e+02 1.956e+03 2.057e+01\n",
            "  1.326e+03 8.690e-02 2.416e-01 7.864e-02 1.866e-01]], shape=(1, 12), dtype=float64)\n",
            "[[2.2748868e-06 9.9999774e-01]]\n",
            "[[2.2748868e-06 9.9999774e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLvcy0A_fbZX",
        "colab_type": "text"
      },
      "source": [
        "Make the parameters untrainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMQ0nlO7YC3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSOiV0HwYSn4",
        "colab_type": "code",
        "outputId": "df488021-0e59-4d17-cfb8-bb6580267665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,814\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNSGKE3hYnRL",
        "colab_type": "text"
      },
      "source": [
        "Load model into Tensorflow mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoqYEL7kYWcy",
        "colab_type": "code",
        "outputId": "b66e0a31-113c-4d54-ef1c-7275f25b04db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "tf.saved_model.save(model, './modelTF')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ./modelTF/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2S-on1AYvPn",
        "colab_type": "code",
        "outputId": "d070864b-2495-499a-9727-b1bca6cc85dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5  modelTF  Proyecto-CFGS  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwrUxdwKY3W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded_tf = tf.saved_model.load('./modelTF')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWXOKymrY_0I",
        "colab_type": "code",
        "outputId": "547fdc5d-713f-42be-e6a3-409cbe57664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "reloaded_tf"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7fbec7acccc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ito0Nf0wbB5v",
        "colab_type": "text"
      },
      "source": [
        "When saved with Tensorflow, the returned object does not have the Keras functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759oPHdOZCeb",
        "colab_type": "code",
        "outputId": "3fd20d50-afe7-4135-e272-cca728106963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded = tf.keras.models.load_model('./modelTF')\n",
        "reloaded.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-vGbqgLf4pR",
        "colab_type": "text"
      },
      "source": [
        "Download the model to the local disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUdy-ax8b9Wf",
        "colab_type": "code",
        "outputId": "28d64c87-e13b-4047-8da3-3515166f5e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!zip -r model.zip ./modelTF\n",
        "!ls"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: modelTF/ (stored 0%)\n",
            "  adding: modelTF/saved_model.pb (deflated 89%)\n",
            "  adding: modelTF/assets/ (stored 0%)\n",
            "  adding: modelTF/variables/ (stored 0%)\n",
            "  adding: modelTF/variables/variables.index (deflated 65%)\n",
            "  adding: modelTF/variables/variables.data-00000-of-00001 (deflated 20%)\n",
            "model.h5  modelTF  model.zip  Proyecto-CFGS  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRh5LRmycGS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('./model.zip')\n",
        "except ImportError:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}