{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparseCategoricalCrossentropy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObI14i4s4n2UJz/I+WkuYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericalcaraz/Proyecto-CFGS/blob/master/SparseCategoricalCrossentropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESN8bzEL-h-g",
        "colab_type": "text"
      },
      "source": [
        "#Breast Cancer Neuronal Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8XBHaRs-WLk",
        "colab_type": "text"
      },
      "source": [
        "##Import all frameworks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVjo59QMStbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgDSHqhl-uW-",
        "colab_type": "text"
      },
      "source": [
        "##Upload breast cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBIgsL-0tesI",
        "colab_type": "code",
        "outputId": "8240b8a9-22bd-4120-c1c4-dc45fb16c223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "!git clone https://github.com/ericalcaraz/Proyecto-CFGS.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Proyecto-CFGS'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 15 (delta 5), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (15/15), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNiVN_FGtuQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Proyecto-CFGS/data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRNKTfZy-2nv",
        "colab_type": "text"
      },
      "source": [
        "##Modify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqawCEF_GRAp",
        "colab_type": "code",
        "outputId": "4da4ca71-bc55-47e4-d653-03869d73dcae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPTJPJzIGwh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapdict = {'M':1,'B':0}\n",
        "df['diagnosis'] = df['diagnosis'].map(mapdict)\n",
        "df = df.drop(columns=['Unnamed: 32'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOORgIWG3wV",
        "colab_type": "code",
        "outputId": "11477d32-f90a-4ceb-f1a9-394554b1015e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>0</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0      842302          1  ...          0.4601                  0.11890\n",
              "1      842517          1  ...          0.2750                  0.08902\n",
              "2    84300903          1  ...          0.3613                  0.08758\n",
              "3    84348301          1  ...          0.6638                  0.17300\n",
              "4    84358402          1  ...          0.2364                  0.07678\n",
              "..        ...        ...  ...             ...                      ...\n",
              "564    926424          1  ...          0.2060                  0.07115\n",
              "565    926682          1  ...          0.2572                  0.06637\n",
              "566    926954          1  ...          0.2218                  0.07820\n",
              "567    927241          1  ...          0.4087                  0.12400\n",
              "568     92751          0  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd8LH4LEGUP6",
        "colab_type": "code",
        "outputId": "b25f862d-75b8-40e5-d7e2-081b4cc80973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>0.372583</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>0.483918</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id   diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.690000e+02  569.000000  ...      569.000000               569.000000\n",
              "mean   3.037183e+07    0.372583  ...        0.290076                 0.083946\n",
              "std    1.250206e+08    0.483918  ...        0.061867                 0.018061\n",
              "min    8.670000e+03    0.000000  ...        0.156500                 0.055040\n",
              "25%    8.692180e+05    0.000000  ...        0.250400                 0.071460\n",
              "50%    9.060240e+05    0.000000  ...        0.282200                 0.080040\n",
              "75%    8.813129e+06    1.000000  ...        0.317900                 0.092080\n",
              "max    9.113205e+08    1.000000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omDLWgfcGSQS",
        "colab_type": "code",
        "outputId": "5cc3f969-f2ee-4b19-b341-88c73197175c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "df.corr()['diagnosis'].sort_values(ascending=[False])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis                  1.000000\n",
              "concave points_worst       0.793566\n",
              "perimeter_worst            0.782914\n",
              "concave points_mean        0.776614\n",
              "radius_worst               0.776454\n",
              "perimeter_mean             0.742636\n",
              "area_worst                 0.733825\n",
              "radius_mean                0.730029\n",
              "area_mean                  0.708984\n",
              "concavity_mean             0.696360\n",
              "concavity_worst            0.659610\n",
              "compactness_mean           0.596534\n",
              "compactness_worst          0.590998\n",
              "radius_se                  0.567134\n",
              "perimeter_se               0.556141\n",
              "area_se                    0.548236\n",
              "texture_worst              0.456903\n",
              "smoothness_worst           0.421465\n",
              "symmetry_worst             0.416294\n",
              "texture_mean               0.415185\n",
              "concave points_se          0.408042\n",
              "smoothness_mean            0.358560\n",
              "symmetry_mean              0.330499\n",
              "fractal_dimension_worst    0.323872\n",
              "compactness_se             0.292999\n",
              "concavity_se               0.253730\n",
              "fractal_dimension_se       0.077972\n",
              "id                         0.039769\n",
              "symmetry_se               -0.006522\n",
              "texture_se                -0.008303\n",
              "fractal_dimension_mean    -0.012838\n",
              "smoothness_se             -0.067016\n",
              "Name: diagnosis, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU5cJ1X4_Icc",
        "colab_type": "text"
      },
      "source": [
        "##Extract the data by **Features** and **Labels** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx_NI-PjTC_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1)\n",
        "labels = df['diagnosis']\n",
        "my_features = ['concave points_worst',\n",
        "               'perimeter_worst',\n",
        "               'concave points_mean',\n",
        "               'radius_worst',\n",
        "               'perimeter_mean',\n",
        "               'area_worst',\n",
        "               'radius_mean',\n",
        "               'area_mean',\n",
        "               'concavity_mean',\n",
        "               'concavity_worst',\n",
        "               'compactness_mean',\n",
        "               'compactness_worst'\n",
        "               ]\n",
        "features = df[my_features]\n",
        "labels = labels.to_numpy()\n",
        "features = features.to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfy7-7oHUq8I",
        "colab_type": "code",
        "outputId": "9ec07915-4a43-4316-85f7-90b5af0b9975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(type(labels))\n",
        "print(type(features))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZtRmMMVEA9",
        "colab_type": "code",
        "outputId": "5fa2f0da-ac17-4a6b-9995-21e1102308cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print('Labels')\n",
        "print(labels.shape, end=' ')\n",
        "print(labels.ndim)\n",
        "\n",
        "print('\\nFeatures:')\n",
        "print(features.shape, end=' ')\n",
        "print(features.ndim)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels\n",
            "(569,) 1\n",
            "\n",
            "Features:\n",
            "(569, 12) 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPMK5fBJ_PiU",
        "colab_type": "text"
      },
      "source": [
        "###Split the data between train, validation and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61qphebkCKqa",
        "colab_type": "text"
      },
      "source": [
        "Should try split more the data with train, validation and test data to check if the model is overfited."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdLnMS1LngbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Features & Targets Train\n",
        "train_features = features[:455]\n",
        "train_labels = labels[:455]\n",
        "\n",
        "#Features & Targets Validation\n",
        "validation_features = features[455:]\n",
        "validation_labels = labels[455:]\n",
        "\n",
        "# Test data\n",
        "test_features = train_features[:57]\n",
        "test_labels = train_labels[:57]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViiHvgJTgce7",
        "colab_type": "code",
        "outputId": "494b5bec-5a9f-4763-9c8e-f7855cc9f42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "print('Train')\n",
        "print('Features: ', train_features.shape, end=' Labels: ')\n",
        "print(train_labels.shape)\n",
        "print('Validation')\n",
        "print('Features: ', validation_features.shape, end=' Labels: ')\n",
        "print(validation_labels.shape)\n",
        "print('Test')\n",
        "print('Features: ', test_features.shape, end=' Labels: ')\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Features:  (455, 12) Labels: (455,)\n",
            "Validation\n",
            "Features:  (114, 12) Labels: (114,)\n",
            "Test\n",
            "Features:  (57, 12) Labels: (57,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib9tJFsLcEma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = tf.convert_to_tensor(train_features, np.float64)\n",
        "train_labels = tf.convert_to_tensor(train_labels, np.float64)\n",
        "\n",
        "validation_features = tf.convert_to_tensor(validation_features, np.float64)\n",
        "validation_labels = tf.convert_to_tensor(validation_labels, np.float64)\n",
        "\n",
        "test_features = tf.convert_to_tensor(test_features, np.float64)\n",
        "test_labels = tf.convert_to_tensor(test_labels, np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqtO8GfTAN4D",
        "colab_type": "text"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTrjfobpZOxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_model(epochs, batch_size, lr):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(12, activation='relu', input_shape=[12]),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(2, activation='softmax'),\n",
        "  ])\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  trained = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    steps_per_epoch=len(train_features)//batch_size,\n",
        "    validation_steps=len(validation_features)//batch_size,\n",
        "    validation_data=(validation_features, validation_labels)\n",
        "  )\n",
        "  return trained, model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7DAJObTAgLB",
        "colab_type": "text"
      },
      "source": [
        "###Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q20syxnPZMaF",
        "colab_type": "code",
        "outputId": "a8bd9edf-2deb-4648-8589-8faafee7c7b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history, model = my_model(epochs=150, batch_size=16, lr=0.00085)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "28/28 - 0s - loss: 41.6723 - accuracy: 0.4710 - val_loss: 29.0516 - val_accuracy: 0.5982\n",
            "Epoch 2/150\n",
            "28/28 - 0s - loss: 28.8075 - accuracy: 0.4487 - val_loss: 13.5333 - val_accuracy: 0.5982\n",
            "Epoch 3/150\n",
            "28/28 - 0s - loss: 20.3994 - accuracy: 0.5376 - val_loss: 0.2259 - val_accuracy: 0.9107\n",
            "Epoch 4/150\n",
            "28/28 - 0s - loss: 16.8046 - accuracy: 0.5148 - val_loss: 2.8079 - val_accuracy: 0.5982\n",
            "Epoch 5/150\n",
            "28/28 - 0s - loss: 13.4809 - accuracy: 0.5080 - val_loss: 0.2108 - val_accuracy: 0.9107\n",
            "Epoch 6/150\n",
            "28/28 - 0s - loss: 9.1566 - accuracy: 0.5854 - val_loss: 0.3624 - val_accuracy: 0.8839\n",
            "Epoch 7/150\n",
            "28/28 - 0s - loss: 8.2015 - accuracy: 0.5672 - val_loss: 0.3720 - val_accuracy: 0.9107\n",
            "Epoch 8/150\n",
            "28/28 - 0s - loss: 6.4662 - accuracy: 0.6150 - val_loss: 0.3945 - val_accuracy: 0.8839\n",
            "Epoch 9/150\n",
            "28/28 - 0s - loss: 7.3241 - accuracy: 0.5672 - val_loss: 0.2382 - val_accuracy: 0.9286\n",
            "Epoch 10/150\n",
            "28/28 - 0s - loss: 4.7038 - accuracy: 0.6424 - val_loss: 0.2690 - val_accuracy: 0.9375\n",
            "Epoch 11/150\n",
            "28/28 - 0s - loss: 5.1100 - accuracy: 0.6378 - val_loss: 0.2388 - val_accuracy: 0.9464\n",
            "Epoch 12/150\n",
            "28/28 - 0s - loss: 4.5149 - accuracy: 0.6310 - val_loss: 0.2792 - val_accuracy: 0.9286\n",
            "Epoch 13/150\n",
            "28/28 - 0s - loss: 3.6107 - accuracy: 0.6219 - val_loss: 0.2383 - val_accuracy: 0.9464\n",
            "Epoch 14/150\n",
            "28/28 - 0s - loss: 3.2174 - accuracy: 0.6355 - val_loss: 0.2073 - val_accuracy: 0.9375\n",
            "Epoch 15/150\n",
            "28/28 - 0s - loss: 2.4715 - accuracy: 0.6902 - val_loss: 0.2226 - val_accuracy: 0.9286\n",
            "Epoch 16/150\n",
            "28/28 - 0s - loss: 2.6508 - accuracy: 0.6902 - val_loss: 0.1903 - val_accuracy: 0.9286\n",
            "Epoch 17/150\n",
            "28/28 - 0s - loss: 2.2023 - accuracy: 0.7084 - val_loss: 0.1783 - val_accuracy: 0.9375\n",
            "Epoch 18/150\n",
            "28/28 - 0s - loss: 1.8937 - accuracy: 0.7175 - val_loss: 0.1835 - val_accuracy: 0.9375\n",
            "Epoch 19/150\n",
            "28/28 - 0s - loss: 1.8005 - accuracy: 0.7175 - val_loss: 0.2030 - val_accuracy: 0.9286\n",
            "Epoch 20/150\n",
            "28/28 - 0s - loss: 1.4820 - accuracy: 0.7403 - val_loss: 0.1669 - val_accuracy: 0.9464\n",
            "Epoch 21/150\n",
            "28/28 - 0s - loss: 1.5847 - accuracy: 0.7540 - val_loss: 0.2064 - val_accuracy: 0.9286\n",
            "Epoch 22/150\n",
            "28/28 - 0s - loss: 1.3290 - accuracy: 0.7084 - val_loss: 0.1727 - val_accuracy: 0.9286\n",
            "Epoch 23/150\n",
            "28/28 - 0s - loss: 1.1645 - accuracy: 0.7130 - val_loss: 0.1636 - val_accuracy: 0.9375\n",
            "Epoch 24/150\n",
            "28/28 - 0s - loss: 1.1035 - accuracy: 0.7472 - val_loss: 0.1598 - val_accuracy: 0.9554\n",
            "Epoch 25/150\n",
            "28/28 - 0s - loss: 0.9890 - accuracy: 0.7677 - val_loss: 0.1738 - val_accuracy: 0.9286\n",
            "Epoch 26/150\n",
            "28/28 - 0s - loss: 0.9768 - accuracy: 0.7654 - val_loss: 0.1718 - val_accuracy: 0.9286\n",
            "Epoch 27/150\n",
            "28/28 - 0s - loss: 0.9284 - accuracy: 0.7677 - val_loss: 0.1616 - val_accuracy: 0.9464\n",
            "Epoch 28/150\n",
            "28/28 - 0s - loss: 0.6763 - accuracy: 0.8178 - val_loss: 0.1627 - val_accuracy: 0.9375\n",
            "Epoch 29/150\n",
            "28/28 - 0s - loss: 0.7075 - accuracy: 0.7790 - val_loss: 0.1632 - val_accuracy: 0.9464\n",
            "Epoch 30/150\n",
            "28/28 - 0s - loss: 0.6896 - accuracy: 0.7589 - val_loss: 0.1654 - val_accuracy: 0.9375\n",
            "Epoch 31/150\n",
            "28/28 - 0s - loss: 0.5948 - accuracy: 0.8064 - val_loss: 0.1728 - val_accuracy: 0.9375\n",
            "Epoch 32/150\n",
            "28/28 - 0s - loss: 0.4041 - accuracy: 0.8519 - val_loss: 0.1778 - val_accuracy: 0.9196\n",
            "Epoch 33/150\n",
            "28/28 - 0s - loss: 0.5355 - accuracy: 0.8246 - val_loss: 0.1725 - val_accuracy: 0.9375\n",
            "Epoch 34/150\n",
            "28/28 - 0s - loss: 0.4953 - accuracy: 0.8223 - val_loss: 0.1709 - val_accuracy: 0.9464\n",
            "Epoch 35/150\n",
            "28/28 - 0s - loss: 0.5047 - accuracy: 0.8155 - val_loss: 0.1770 - val_accuracy: 0.9375\n",
            "Epoch 36/150\n",
            "28/28 - 0s - loss: 0.3997 - accuracy: 0.8428 - val_loss: 0.1822 - val_accuracy: 0.9286\n",
            "Epoch 37/150\n",
            "28/28 - 0s - loss: 0.4050 - accuracy: 0.8383 - val_loss: 0.1814 - val_accuracy: 0.9375\n",
            "Epoch 38/150\n",
            "28/28 - 0s - loss: 0.4323 - accuracy: 0.8702 - val_loss: 0.1921 - val_accuracy: 0.9196\n",
            "Epoch 39/150\n",
            "28/28 - 0s - loss: 0.3938 - accuracy: 0.8588 - val_loss: 0.2016 - val_accuracy: 0.9286\n",
            "Epoch 40/150\n",
            "28/28 - 0s - loss: 0.3327 - accuracy: 0.8793 - val_loss: 0.2033 - val_accuracy: 0.9196\n",
            "Epoch 41/150\n",
            "28/28 - 0s - loss: 0.3464 - accuracy: 0.9021 - val_loss: 0.2027 - val_accuracy: 0.9286\n",
            "Epoch 42/150\n",
            "28/28 - 0s - loss: 0.3351 - accuracy: 0.8861 - val_loss: 0.1957 - val_accuracy: 0.9286\n",
            "Epoch 43/150\n",
            "28/28 - 0s - loss: 0.3056 - accuracy: 0.8793 - val_loss: 0.1913 - val_accuracy: 0.9286\n",
            "Epoch 44/150\n",
            "28/28 - 0s - loss: 0.2990 - accuracy: 0.9066 - val_loss: 0.1930 - val_accuracy: 0.9286\n",
            "Epoch 45/150\n",
            "28/28 - 0s - loss: 0.2828 - accuracy: 0.8907 - val_loss: 0.1911 - val_accuracy: 0.9286\n",
            "Epoch 46/150\n",
            "28/28 - 0s - loss: 0.2755 - accuracy: 0.9134 - val_loss: 0.1864 - val_accuracy: 0.9286\n",
            "Epoch 47/150\n",
            "28/28 - 0s - loss: 0.2395 - accuracy: 0.9021 - val_loss: 0.1880 - val_accuracy: 0.9286\n",
            "Epoch 48/150\n",
            "28/28 - 0s - loss: 0.3163 - accuracy: 0.8724 - val_loss: 0.1943 - val_accuracy: 0.9375\n",
            "Epoch 49/150\n",
            "28/28 - 0s - loss: 0.2959 - accuracy: 0.9043 - val_loss: 0.1958 - val_accuracy: 0.9375\n",
            "Epoch 50/150\n",
            "28/28 - 0s - loss: 0.2850 - accuracy: 0.9043 - val_loss: 0.1941 - val_accuracy: 0.9286\n",
            "Epoch 51/150\n",
            "28/28 - 0s - loss: 0.2308 - accuracy: 0.9226 - val_loss: 0.1942 - val_accuracy: 0.9196\n",
            "Epoch 52/150\n",
            "28/28 - 0s - loss: 0.2822 - accuracy: 0.8952 - val_loss: 0.1943 - val_accuracy: 0.9286\n",
            "Epoch 53/150\n",
            "28/28 - 0s - loss: 0.2697 - accuracy: 0.9021 - val_loss: 0.1931 - val_accuracy: 0.9375\n",
            "Epoch 54/150\n",
            "28/28 - 0s - loss: 0.2440 - accuracy: 0.9112 - val_loss: 0.1927 - val_accuracy: 0.9286\n",
            "Epoch 55/150\n",
            "28/28 - 0s - loss: 0.2623 - accuracy: 0.9112 - val_loss: 0.1904 - val_accuracy: 0.9286\n",
            "Epoch 56/150\n",
            "28/28 - 0s - loss: 0.2345 - accuracy: 0.9043 - val_loss: 0.1919 - val_accuracy: 0.9196\n",
            "Epoch 57/150\n",
            "28/28 - 0s - loss: 0.2102 - accuracy: 0.9248 - val_loss: 0.1832 - val_accuracy: 0.9286\n",
            "Epoch 58/150\n",
            "28/28 - 0s - loss: 0.2420 - accuracy: 0.9066 - val_loss: 0.1813 - val_accuracy: 0.9286\n",
            "Epoch 59/150\n",
            "28/28 - 0s - loss: 0.2334 - accuracy: 0.9174 - val_loss: 0.1783 - val_accuracy: 0.9286\n",
            "Epoch 60/150\n",
            "28/28 - 0s - loss: 0.2512 - accuracy: 0.9180 - val_loss: 0.1775 - val_accuracy: 0.9286\n",
            "Epoch 61/150\n",
            "28/28 - 0s - loss: 0.2134 - accuracy: 0.9134 - val_loss: 0.1752 - val_accuracy: 0.9196\n",
            "Epoch 62/150\n",
            "28/28 - 0s - loss: 0.2533 - accuracy: 0.8998 - val_loss: 0.1778 - val_accuracy: 0.9286\n",
            "Epoch 63/150\n",
            "28/28 - 0s - loss: 0.2139 - accuracy: 0.9248 - val_loss: 0.1812 - val_accuracy: 0.9286\n",
            "Epoch 64/150\n",
            "28/28 - 0s - loss: 0.2061 - accuracy: 0.9248 - val_loss: 0.1794 - val_accuracy: 0.9196\n",
            "Epoch 65/150\n",
            "28/28 - 0s - loss: 0.2079 - accuracy: 0.9180 - val_loss: 0.1869 - val_accuracy: 0.9286\n",
            "Epoch 66/150\n",
            "28/28 - 0s - loss: 0.1999 - accuracy: 0.9203 - val_loss: 0.1830 - val_accuracy: 0.9286\n",
            "Epoch 67/150\n",
            "28/28 - 0s - loss: 0.2460 - accuracy: 0.9089 - val_loss: 0.1856 - val_accuracy: 0.9196\n",
            "Epoch 68/150\n",
            "28/28 - 0s - loss: 0.1993 - accuracy: 0.9339 - val_loss: 0.1795 - val_accuracy: 0.9375\n",
            "Epoch 69/150\n",
            "28/28 - 0s - loss: 0.2005 - accuracy: 0.9317 - val_loss: 0.1752 - val_accuracy: 0.9375\n",
            "Epoch 70/150\n",
            "28/28 - 0s - loss: 0.2947 - accuracy: 0.8884 - val_loss: 0.1748 - val_accuracy: 0.9375\n",
            "Epoch 71/150\n",
            "28/28 - 0s - loss: 0.2191 - accuracy: 0.9248 - val_loss: 0.1768 - val_accuracy: 0.9375\n",
            "Epoch 72/150\n",
            "28/28 - 0s - loss: 0.1921 - accuracy: 0.9339 - val_loss: 0.1745 - val_accuracy: 0.9286\n",
            "Epoch 73/150\n",
            "28/28 - 0s - loss: 0.2061 - accuracy: 0.9226 - val_loss: 0.1687 - val_accuracy: 0.9286\n",
            "Epoch 74/150\n",
            "28/28 - 0s - loss: 0.2484 - accuracy: 0.9066 - val_loss: 0.1796 - val_accuracy: 0.9286\n",
            "Epoch 75/150\n",
            "28/28 - 0s - loss: 0.2492 - accuracy: 0.9180 - val_loss: 0.1767 - val_accuracy: 0.9286\n",
            "Epoch 76/150\n",
            "28/28 - 0s - loss: 0.1807 - accuracy: 0.9385 - val_loss: 0.1775 - val_accuracy: 0.9196\n",
            "Epoch 77/150\n",
            "28/28 - 0s - loss: 0.2085 - accuracy: 0.9248 - val_loss: 0.1784 - val_accuracy: 0.9196\n",
            "Epoch 78/150\n",
            "28/28 - 0s - loss: 0.2294 - accuracy: 0.9203 - val_loss: 0.1774 - val_accuracy: 0.9196\n",
            "Epoch 79/150\n",
            "28/28 - 0s - loss: 0.1985 - accuracy: 0.9362 - val_loss: 0.1720 - val_accuracy: 0.9286\n",
            "Epoch 80/150\n",
            "28/28 - 0s - loss: 0.2096 - accuracy: 0.9248 - val_loss: 0.1721 - val_accuracy: 0.9286\n",
            "Epoch 81/150\n",
            "28/28 - 0s - loss: 0.2239 - accuracy: 0.9180 - val_loss: 0.1671 - val_accuracy: 0.9375\n",
            "Epoch 82/150\n",
            "28/28 - 0s - loss: 0.2040 - accuracy: 0.9180 - val_loss: 0.1647 - val_accuracy: 0.9286\n",
            "Epoch 83/150\n",
            "28/28 - 0s - loss: 0.1835 - accuracy: 0.9203 - val_loss: 0.1712 - val_accuracy: 0.9196\n",
            "Epoch 84/150\n",
            "28/28 - 0s - loss: 0.2313 - accuracy: 0.9271 - val_loss: 0.1728 - val_accuracy: 0.9375\n",
            "Epoch 85/150\n",
            "28/28 - 0s - loss: 0.2001 - accuracy: 0.9089 - val_loss: 0.1677 - val_accuracy: 0.9286\n",
            "Epoch 86/150\n",
            "28/28 - 0s - loss: 0.2249 - accuracy: 0.9317 - val_loss: 0.1661 - val_accuracy: 0.9286\n",
            "Epoch 87/150\n",
            "28/28 - 0s - loss: 0.1926 - accuracy: 0.9271 - val_loss: 0.1659 - val_accuracy: 0.9286\n",
            "Epoch 88/150\n",
            "28/28 - 0s - loss: 0.2092 - accuracy: 0.9152 - val_loss: 0.1698 - val_accuracy: 0.9286\n",
            "Epoch 89/150\n",
            "28/28 - 0s - loss: 0.2206 - accuracy: 0.9112 - val_loss: 0.1653 - val_accuracy: 0.9286\n",
            "Epoch 90/150\n",
            "28/28 - 0s - loss: 0.2291 - accuracy: 0.9203 - val_loss: 0.1797 - val_accuracy: 0.9286\n",
            "Epoch 91/150\n",
            "28/28 - 0s - loss: 0.2309 - accuracy: 0.9089 - val_loss: 0.1770 - val_accuracy: 0.9286\n",
            "Epoch 92/150\n",
            "28/28 - 0s - loss: 0.2362 - accuracy: 0.9157 - val_loss: 0.1693 - val_accuracy: 0.9286\n",
            "Epoch 93/150\n",
            "28/28 - 0s - loss: 0.2021 - accuracy: 0.9271 - val_loss: 0.1624 - val_accuracy: 0.9286\n",
            "Epoch 94/150\n",
            "28/28 - 0s - loss: 0.2229 - accuracy: 0.9180 - val_loss: 0.1625 - val_accuracy: 0.9375\n",
            "Epoch 95/150\n",
            "28/28 - 0s - loss: 0.2127 - accuracy: 0.9066 - val_loss: 0.1562 - val_accuracy: 0.9375\n",
            "Epoch 96/150\n",
            "28/28 - 0s - loss: 0.1960 - accuracy: 0.9180 - val_loss: 0.1647 - val_accuracy: 0.9286\n",
            "Epoch 97/150\n",
            "28/28 - 0s - loss: 0.1948 - accuracy: 0.9134 - val_loss: 0.1772 - val_accuracy: 0.9375\n",
            "Epoch 98/150\n",
            "28/28 - 0s - loss: 0.2443 - accuracy: 0.8975 - val_loss: 0.1667 - val_accuracy: 0.9286\n",
            "Epoch 99/150\n",
            "28/28 - 0s - loss: 0.2362 - accuracy: 0.9043 - val_loss: 0.1705 - val_accuracy: 0.9286\n",
            "Epoch 100/150\n",
            "28/28 - 0s - loss: 0.2159 - accuracy: 0.9248 - val_loss: 0.1688 - val_accuracy: 0.9286\n",
            "Epoch 101/150\n",
            "28/28 - 0s - loss: 0.1796 - accuracy: 0.9248 - val_loss: 0.1726 - val_accuracy: 0.9375\n",
            "Epoch 102/150\n",
            "28/28 - 0s - loss: 0.1909 - accuracy: 0.9385 - val_loss: 0.1675 - val_accuracy: 0.9286\n",
            "Epoch 103/150\n",
            "28/28 - 0s - loss: 0.2094 - accuracy: 0.9089 - val_loss: 0.1708 - val_accuracy: 0.9375\n",
            "Epoch 104/150\n",
            "28/28 - 0s - loss: 0.1889 - accuracy: 0.9226 - val_loss: 0.1782 - val_accuracy: 0.9196\n",
            "Epoch 105/150\n",
            "28/28 - 0s - loss: 0.2322 - accuracy: 0.9203 - val_loss: 0.1688 - val_accuracy: 0.9286\n",
            "Epoch 106/150\n",
            "28/28 - 0s - loss: 0.2248 - accuracy: 0.9203 - val_loss: 0.1688 - val_accuracy: 0.9286\n",
            "Epoch 107/150\n",
            "28/28 - 0s - loss: 0.1917 - accuracy: 0.9339 - val_loss: 0.1656 - val_accuracy: 0.9464\n",
            "Epoch 108/150\n",
            "28/28 - 0s - loss: 0.2172 - accuracy: 0.9112 - val_loss: 0.1615 - val_accuracy: 0.9375\n",
            "Epoch 109/150\n",
            "28/28 - 0s - loss: 0.2244 - accuracy: 0.9089 - val_loss: 0.1718 - val_accuracy: 0.9375\n",
            "Epoch 110/150\n",
            "28/28 - 0s - loss: 0.2005 - accuracy: 0.9271 - val_loss: 0.1691 - val_accuracy: 0.9196\n",
            "Epoch 111/150\n",
            "28/28 - 0s - loss: 0.2293 - accuracy: 0.9043 - val_loss: 0.1748 - val_accuracy: 0.9286\n",
            "Epoch 112/150\n",
            "28/28 - 0s - loss: 0.1718 - accuracy: 0.9317 - val_loss: 0.1848 - val_accuracy: 0.9196\n",
            "Epoch 113/150\n",
            "28/28 - 0s - loss: 0.2449 - accuracy: 0.9134 - val_loss: 0.1759 - val_accuracy: 0.9286\n",
            "Epoch 114/150\n",
            "28/28 - 0s - loss: 0.1870 - accuracy: 0.9339 - val_loss: 0.1688 - val_accuracy: 0.9286\n",
            "Epoch 115/150\n",
            "28/28 - 0s - loss: 0.2155 - accuracy: 0.9180 - val_loss: 0.1649 - val_accuracy: 0.9286\n",
            "Epoch 116/150\n",
            "28/28 - 0s - loss: 0.1965 - accuracy: 0.9089 - val_loss: 0.1741 - val_accuracy: 0.9286\n",
            "Epoch 117/150\n",
            "28/28 - 0s - loss: 0.2058 - accuracy: 0.9219 - val_loss: 0.1609 - val_accuracy: 0.9375\n",
            "Epoch 118/150\n",
            "28/28 - 0s - loss: 0.2081 - accuracy: 0.9180 - val_loss: 0.1697 - val_accuracy: 0.9286\n",
            "Epoch 119/150\n",
            "28/28 - 0s - loss: 0.1837 - accuracy: 0.9408 - val_loss: 0.1675 - val_accuracy: 0.9286\n",
            "Epoch 120/150\n",
            "28/28 - 0s - loss: 0.1944 - accuracy: 0.9248 - val_loss: 0.1599 - val_accuracy: 0.9375\n",
            "Epoch 121/150\n",
            "28/28 - 0s - loss: 0.1874 - accuracy: 0.9180 - val_loss: 0.1631 - val_accuracy: 0.9286\n",
            "Epoch 122/150\n",
            "28/28 - 0s - loss: 0.2099 - accuracy: 0.9203 - val_loss: 0.1643 - val_accuracy: 0.9375\n",
            "Epoch 123/150\n",
            "28/28 - 0s - loss: 0.1656 - accuracy: 0.9317 - val_loss: 0.1657 - val_accuracy: 0.9286\n",
            "Epoch 124/150\n",
            "28/28 - 0s - loss: 0.2500 - accuracy: 0.8907 - val_loss: 0.1600 - val_accuracy: 0.9375\n",
            "Epoch 125/150\n",
            "28/28 - 0s - loss: 0.2055 - accuracy: 0.9248 - val_loss: 0.1595 - val_accuracy: 0.9375\n",
            "Epoch 126/150\n",
            "28/28 - 0s - loss: 0.1712 - accuracy: 0.9294 - val_loss: 0.1695 - val_accuracy: 0.9286\n",
            "Epoch 127/150\n",
            "28/28 - 0s - loss: 0.2143 - accuracy: 0.9066 - val_loss: 0.1700 - val_accuracy: 0.9286\n",
            "Epoch 128/150\n",
            "28/28 - 0s - loss: 0.2076 - accuracy: 0.9294 - val_loss: 0.1655 - val_accuracy: 0.9375\n",
            "Epoch 129/150\n",
            "28/28 - 0s - loss: 0.1867 - accuracy: 0.9271 - val_loss: 0.1604 - val_accuracy: 0.9464\n",
            "Epoch 130/150\n",
            "28/28 - 0s - loss: 0.2064 - accuracy: 0.9134 - val_loss: 0.1636 - val_accuracy: 0.9375\n",
            "Epoch 131/150\n",
            "28/28 - 0s - loss: 0.1865 - accuracy: 0.9317 - val_loss: 0.1687 - val_accuracy: 0.9286\n",
            "Epoch 132/150\n",
            "28/28 - 0s - loss: 0.2084 - accuracy: 0.9066 - val_loss: 0.1626 - val_accuracy: 0.9286\n",
            "Epoch 133/150\n",
            "28/28 - 0s - loss: 0.2353 - accuracy: 0.9066 - val_loss: 0.1818 - val_accuracy: 0.9286\n",
            "Epoch 134/150\n",
            "28/28 - 0s - loss: 0.1615 - accuracy: 0.9408 - val_loss: 0.1648 - val_accuracy: 0.9375\n",
            "Epoch 135/150\n",
            "28/28 - 0s - loss: 0.2254 - accuracy: 0.9112 - val_loss: 0.1661 - val_accuracy: 0.9375\n",
            "Epoch 136/150\n",
            "28/28 - 0s - loss: 0.1892 - accuracy: 0.9226 - val_loss: 0.1759 - val_accuracy: 0.9286\n",
            "Epoch 137/150\n",
            "28/28 - 0s - loss: 0.2086 - accuracy: 0.9134 - val_loss: 0.1755 - val_accuracy: 0.9196\n",
            "Epoch 138/150\n",
            "28/28 - 0s - loss: 0.1834 - accuracy: 0.9271 - val_loss: 0.1782 - val_accuracy: 0.9196\n",
            "Epoch 139/150\n",
            "28/28 - 0s - loss: 0.1775 - accuracy: 0.9271 - val_loss: 0.1694 - val_accuracy: 0.9286\n",
            "Epoch 140/150\n",
            "28/28 - 0s - loss: 0.2053 - accuracy: 0.9112 - val_loss: 0.1861 - val_accuracy: 0.9196\n",
            "Epoch 141/150\n",
            "28/28 - 0s - loss: 0.1897 - accuracy: 0.9248 - val_loss: 0.1813 - val_accuracy: 0.9286\n",
            "Epoch 142/150\n",
            "28/28 - 0s - loss: 0.1924 - accuracy: 0.9248 - val_loss: 0.1716 - val_accuracy: 0.9286\n",
            "Epoch 143/150\n",
            "28/28 - 0s - loss: 0.1899 - accuracy: 0.9271 - val_loss: 0.1672 - val_accuracy: 0.9286\n",
            "Epoch 144/150\n",
            "28/28 - 0s - loss: 0.2020 - accuracy: 0.9203 - val_loss: 0.1605 - val_accuracy: 0.9286\n",
            "Epoch 145/150\n",
            "28/28 - 0s - loss: 0.2064 - accuracy: 0.9157 - val_loss: 0.1605 - val_accuracy: 0.9286\n",
            "Epoch 146/150\n",
            "28/28 - 0s - loss: 0.2089 - accuracy: 0.9219 - val_loss: 0.1611 - val_accuracy: 0.9375\n",
            "Epoch 147/150\n",
            "28/28 - 0s - loss: 0.1785 - accuracy: 0.9248 - val_loss: 0.1541 - val_accuracy: 0.9464\n",
            "Epoch 148/150\n",
            "28/28 - 0s - loss: 0.1782 - accuracy: 0.9180 - val_loss: 0.1647 - val_accuracy: 0.9375\n",
            "Epoch 149/150\n",
            "28/28 - 0s - loss: 0.2435 - accuracy: 0.9134 - val_loss: 0.1677 - val_accuracy: 0.9286\n",
            "Epoch 150/150\n",
            "28/28 - 0s - loss: 0.2114 - accuracy: 0.9134 - val_loss: 0.1599 - val_accuracy: 0.9464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VYI19E1ZiS2",
        "colab_type": "code",
        "outputId": "69d4d80b-a7d5-4720-dc6d-61a22b86dc60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERMbcBlTAoE5",
        "colab_type": "text"
      },
      "source": [
        "###Show loss and accuaracy per epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnBEioJ7XMPz",
        "colab_type": "code",
        "outputId": "a4bd06b9-8407-4552-97ad-4158027a340e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(150)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUbcv-JYAvJB",
        "colab_type": "text"
      },
      "source": [
        "###Predict values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQHvN7bupzYp",
        "colab_type": "code",
        "outputId": "6af8ff12-6fa5-432d-bc09-9d14d4f452a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "example = df.iloc[[100]]\n",
        "print(f\"Label: {example['diagnosis']}\")\n",
        "data = (example[my_features]).to_numpy()\n",
        "data = tf.convert_to_tensor(data)\n",
        "print(data)\n",
        "model.predict(data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 446    1\n",
            "Name: diagnosis, dtype: int64\n",
            "tf.Tensor(\n",
            "[[1.970e-01 1.454e+02 8.293e-02 2.153e+01 1.173e+02 1.437e+03 1.775e+01\n",
            "  9.816e+02 1.698e-01 6.399e-01 1.314e-01 3.762e-01]], shape=(1, 12), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1579695e-04, 9.9938416e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StNIVwB5aQ8h",
        "colab_type": "text"
      },
      "source": [
        "### Use test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAtQONUcg2lK",
        "colab_type": "code",
        "outputId": "fbad9136-ca7b-4b57-cf70-e4119ce18d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(len(tf.keras.backend.get_value(test_features)))\n",
        "for test_feature, test_label in zip(test_features, test_labels):\n",
        "  true_label = tf.keras.backend.get_value(test_label)\n",
        "  print(f'Label: {true_label}', end=\"\")\n",
        "\n",
        "  test_feature = tf.expand_dims(test_feature, 0)\n",
        "  predicted = model.predict([[test_feature]])[0]\n",
        "  \n",
        "  if predicted[0] > predicted[1]:\n",
        "    if true_label == 0.0:\n",
        "      print(predicted, \"\\U0000274E\" + \"\\n\")\n",
        "    else:\n",
        "      print(predicted, \"\\U0000274C\" + \"\\n\")\n",
        "  else:\n",
        "    if true_label == 1.0:\n",
        "      print(predicted, \"\\U00002705\" + \"\\n\")\n",
        "    else:\n",
        "      print(predicted, \"\\U0000274C\" + \"\\n\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.97100854 0.02899142] ❎\n",
            "\n",
            "Label: 0.0[0.98493814 0.01506187] ❎\n",
            "\n",
            "Label: 0.0[0.97530156 0.0246984 ] ❎\n",
            "\n",
            "Label: 1.0[4.491726e-08 1.000000e+00] ✅\n",
            "\n",
            "Label: 1.0[0.00963823 0.9903618 ] ✅\n",
            "\n",
            "Label: 0.0[0.9905487  0.00945138] ❎\n",
            "\n",
            "Label: 0.0[0.9947648  0.00523516] ❎\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.99338865 0.00661128] ❎\n",
            "\n",
            "Label: 0.0[0.9968444  0.00315565] ❎\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 1.0[0.6413786 0.3586214] ❌\n",
            "\n",
            "Label: 0.0[0.9535736  0.04642637] ❎\n",
            "\n",
            "Label: 0.0[0.83973515 0.16026492] ❎\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.8128163  0.18718368] ❎\n",
            "\n",
            "Label: 0.0[0.9906509  0.00934905] ❎\n",
            "\n",
            "Label: 0.0[0.99700695 0.0029931 ] ❎\n",
            "\n",
            "Label: 0.0[0.5960368 0.4039632] ❎\n",
            "\n",
            "Label: 1.0[0.3451084  0.65489167] ✅\n",
            "\n",
            "Label: 0.0[0.99772865 0.00227139] ❎\n",
            "\n",
            "Label: 0.0[0.9765037  0.02349628] ❎\n",
            "\n",
            "Label: 0.0[0.86363405 0.13636592] ❎\n",
            "\n",
            "Label: 1.0[3.825514e-17 1.000000e+00] ✅\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.877938 0.122062] ❎\n",
            "\n",
            "Label: 0.0[0.98422617 0.01577381] ❎\n",
            "\n",
            "Label: 0.0[0.75827783 0.24172212] ❎\n",
            "\n",
            "Label: 0.0[0.99822706 0.00177295] ❎\n",
            "\n",
            "Label: 0.0[0.9955123 0.0044877] ❎\n",
            "\n",
            "Label: 0.0[0.9842695  0.01573054] ❎\n",
            "\n",
            "Label: 0.0[0.97898895 0.02101103] ❎\n",
            "\n",
            "Label: 0.0[0.9861936  0.01380646] ❎\n",
            "\n",
            "Label: 1.0[6.6766626e-07 9.9999928e-01] ✅\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.7334825  0.26651752] ❎\n",
            "\n",
            "Label: 1.0[0.8170454  0.18295464] ❌\n",
            "\n",
            "Label: 0.0[0.9791559  0.02084407] ❎\n",
            "\n",
            "Label: 0.0[0.68489236 0.3151077 ] ❎\n",
            "\n",
            "Label: 1.0[0.24546136 0.7545387 ] ✅\n",
            "\n",
            "Label: 0.0[0.74541724 0.25458273] ❎\n",
            "\n",
            "Label: 1.0[0.08531369 0.91468626] ✅\n",
            "\n",
            "Label: 1.0[0.06030053 0.9396995 ] ✅\n",
            "\n",
            "Label: 0.0[0.6780649 0.3219351] ❎\n",
            "\n",
            "Label: 0.0[0.92260605 0.07739396] ❎\n",
            "\n",
            "Label: 0.0[0.96305436 0.03694566] ❎\n",
            "\n",
            "Label: 0.0[0.99162465 0.00837533] ❎\n",
            "\n",
            "Label: 1.0[1.16161245e-05 9.99988437e-01] ✅\n",
            "\n",
            "Label: 1.0[0.3322152 0.6677848] ✅\n",
            "\n",
            "Label: 0.0[0.9876546  0.01234539] ❎\n",
            "\n",
            "Label: 0.0[0.8554646  0.14453539] ❎\n",
            "\n",
            "Label: 0.0[0.89293385 0.10706612] ❎\n",
            "\n",
            "Label: 1.0[7.9852016e-13 1.0000000e+00] ✅\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq5PFENCetjg",
        "colab_type": "text"
      },
      "source": [
        "## Save trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vohvQk8ZW2ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db7B8W23XBap",
        "colab_type": "code",
        "outputId": "eef8214a-4880-4bb5-f00c-86b373cf816c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5  Proyecto-CFGS  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xx6BIrEfA6f",
        "colab_type": "text"
      },
      "source": [
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD6j2J8SXCin",
        "colab_type": "code",
        "outputId": "c5353cb2-4b4c-42a5-f08d-092402bc5a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded = tf.keras.models.load_model('./model.h5')\n",
        "reloaded.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0SGgodQfDjC",
        "colab_type": "text"
      },
      "source": [
        "Check both models will predict the same value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yacss5PrX_Tz",
        "colab_type": "code",
        "outputId": "9e623d72-25bd-4278-94a0-dda65e5db566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "example = df.iloc[[100]]\n",
        "print(f\"Label: {example['diagnosis']}\")\n",
        "data = (example[my_features]).to_numpy()\n",
        "data = tf.convert_to_tensor(data)\n",
        "print(data)\n",
        "print(model.predict(data))\n",
        "print(reloaded.predict(data))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 446    1\n",
            "Name: diagnosis, dtype: int64\n",
            "tf.Tensor(\n",
            "[[1.970e-01 1.454e+02 8.293e-02 2.153e+01 1.173e+02 1.437e+03 1.775e+01\n",
            "  9.816e+02 1.698e-01 6.399e-01 1.314e-01 3.762e-01]], shape=(1, 12), dtype=float64)\n",
            "[[6.1579695e-04 9.9938416e-01]]\n",
            "[[6.1579695e-04 9.9938416e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLvcy0A_fbZX",
        "colab_type": "text"
      },
      "source": [
        "Make the parameters untrainable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMQ0nlO7YC3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSOiV0HwYSn4",
        "colab_type": "code",
        "outputId": "8213c4de-b8ed-4231-a9d2-af4332f0a686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,814\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNSGKE3hYnRL",
        "colab_type": "text"
      },
      "source": [
        "Load model into Tensorflow mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoqYEL7kYWcy",
        "colab_type": "code",
        "outputId": "670e9a40-d597-4ddf-8736-f91088d43640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "tf.saved_model.save(model, './modelTF')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ./modelTF/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2S-on1AYvPn",
        "colab_type": "code",
        "outputId": "d4097a4c-6579-4f4d-bd04-5c8ffeea5d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5  modelTF  Proyecto-CFGS  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwrUxdwKY3W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded_tf = tf.saved_model.load('./modelTF')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWXOKymrY_0I",
        "colab_type": "code",
        "outputId": "08d809ee-f780-4094-b14a-4f7e03847d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "reloaded_tf"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7f202dcfbeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ito0Nf0wbB5v",
        "colab_type": "text"
      },
      "source": [
        "When saved with Tensorflow, the returned object does not have the Keras functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759oPHdOZCeb",
        "colab_type": "code",
        "outputId": "92e1ec41-6edb-4895-a5f7-75c2891b2bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded = tf.keras.models.load_model('./modelTF')\n",
        "reloaded.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-vGbqgLf4pR",
        "colab_type": "text"
      },
      "source": [
        "Download the model to the local disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUdy-ax8b9Wf",
        "colab_type": "code",
        "outputId": "f43b3b4f-b548-41ef-d6bf-11379aae84ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!zip -r model.zip ./modelTF\n",
        "!ls"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: modelTF/ (stored 0%)\n",
            "  adding: modelTF/saved_model.pb (deflated 89%)\n",
            "  adding: modelTF/assets/ (stored 0%)\n",
            "  adding: modelTF/variables/ (stored 0%)\n",
            "  adding: modelTF/variables/variables.index (deflated 65%)\n",
            "  adding: modelTF/variables/variables.data-00000-of-00001 (deflated 23%)\n",
            "model.h5  modelTF  model.zip  Proyecto-CFGS  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRh5LRmycGS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('./model.zip')\n",
        "except ImportError:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}