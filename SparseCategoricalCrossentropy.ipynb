{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparseCategoricalCrossentropy.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNqzncDkAyCrX8oUSM6Ds/R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericalcaraz/Proyecto-CFGS/blob/master/SparseCategoricalCrossentropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESN8bzEL-h-g",
        "colab_type": "text"
      },
      "source": [
        "#Breast Cancer Neuronal Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8XBHaRs-WLk",
        "colab_type": "text"
      },
      "source": [
        "##Import all frameworks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVjo59QMStbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgDSHqhl-uW-",
        "colab_type": "text"
      },
      "source": [
        "##Upload breast cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBIgsL-0tesI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ericalcaraz/Proyecto-CFGS.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNiVN_FGtuQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Proyecto-CFGS/data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRNKTfZy-2nv",
        "colab_type": "text"
      },
      "source": [
        "##Modify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqawCEF_GRAp",
        "colab_type": "code",
        "outputId": "485671e7-dd17-4bc9-89ac-96bc0e944e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPTJPJzIGwh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapdict = {'M':1,'B':0}\n",
        "df['diagnosis'] = df['diagnosis'].map(mapdict)\n",
        "df = df.drop(columns=['Unnamed: 32'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmOORgIWG3wV",
        "colab_type": "code",
        "outputId": "44c9caba-1f20-4a25-8a3d-d3a3731c2d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>1</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>1</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>1</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>1</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>1</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>0</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0      842302          1  ...          0.4601                  0.11890\n",
              "1      842517          1  ...          0.2750                  0.08902\n",
              "2    84300903          1  ...          0.3613                  0.08758\n",
              "3    84348301          1  ...          0.6638                  0.17300\n",
              "4    84358402          1  ...          0.2364                  0.07678\n",
              "..        ...        ...  ...             ...                      ...\n",
              "564    926424          1  ...          0.2060                  0.07115\n",
              "565    926682          1  ...          0.2572                  0.06637\n",
              "566    926954          1  ...          0.2218                  0.07820\n",
              "567    927241          1  ...          0.4087                  0.12400\n",
              "568     92751          0  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wd8LH4LEGUP6",
        "colab_type": "code",
        "outputId": "ced4a073-c7a8-4d82-ec47-361379a5e01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.690000e+02</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.037183e+07</td>\n",
              "      <td>0.372583</td>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>0.405172</td>\n",
              "      <td>1.216853</td>\n",
              "      <td>2.866059</td>\n",
              "      <td>40.337079</td>\n",
              "      <td>0.007041</td>\n",
              "      <td>0.025478</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0.011796</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>0.003795</td>\n",
              "      <td>16.269190</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.250206e+08</td>\n",
              "      <td>0.483918</td>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.277313</td>\n",
              "      <td>0.551648</td>\n",
              "      <td>2.021855</td>\n",
              "      <td>45.491006</td>\n",
              "      <td>0.003003</td>\n",
              "      <td>0.017908</td>\n",
              "      <td>0.030186</td>\n",
              "      <td>0.006170</td>\n",
              "      <td>0.008266</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.833242</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.930000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692180e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.833900</td>\n",
              "      <td>1.606000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005169</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.015090</td>\n",
              "      <td>0.007638</td>\n",
              "      <td>0.015160</td>\n",
              "      <td>0.002248</td>\n",
              "      <td>13.010000</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.060240e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>1.108000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>24.530000</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.020450</td>\n",
              "      <td>0.025890</td>\n",
              "      <td>0.010930</td>\n",
              "      <td>0.018730</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.813129e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.478900</td>\n",
              "      <td>1.474000</td>\n",
              "      <td>3.357000</td>\n",
              "      <td>45.190000</td>\n",
              "      <td>0.008146</td>\n",
              "      <td>0.032450</td>\n",
              "      <td>0.042050</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.004558</td>\n",
              "      <td>18.790000</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.040000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id   diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.690000e+02  569.000000  ...      569.000000               569.000000\n",
              "mean   3.037183e+07    0.372583  ...        0.290076                 0.083946\n",
              "std    1.250206e+08    0.483918  ...        0.061867                 0.018061\n",
              "min    8.670000e+03    0.000000  ...        0.156500                 0.055040\n",
              "25%    8.692180e+05    0.000000  ...        0.250400                 0.071460\n",
              "50%    9.060240e+05    0.000000  ...        0.282200                 0.080040\n",
              "75%    8.813129e+06    1.000000  ...        0.317900                 0.092080\n",
              "max    9.113205e+08    1.000000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omDLWgfcGSQS",
        "colab_type": "code",
        "outputId": "47990a03-6a0e-4766-fbfb-5aa326ab1339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "df.corr()['diagnosis'].sort_values(ascending=[False])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diagnosis                  1.000000\n",
              "concave points_worst       0.793566\n",
              "perimeter_worst            0.782914\n",
              "concave points_mean        0.776614\n",
              "radius_worst               0.776454\n",
              "perimeter_mean             0.742636\n",
              "area_worst                 0.733825\n",
              "radius_mean                0.730029\n",
              "area_mean                  0.708984\n",
              "concavity_mean             0.696360\n",
              "concavity_worst            0.659610\n",
              "compactness_mean           0.596534\n",
              "compactness_worst          0.590998\n",
              "radius_se                  0.567134\n",
              "perimeter_se               0.556141\n",
              "area_se                    0.548236\n",
              "texture_worst              0.456903\n",
              "smoothness_worst           0.421465\n",
              "symmetry_worst             0.416294\n",
              "texture_mean               0.415185\n",
              "concave points_se          0.408042\n",
              "smoothness_mean            0.358560\n",
              "symmetry_mean              0.330499\n",
              "fractal_dimension_worst    0.323872\n",
              "compactness_se             0.292999\n",
              "concavity_se               0.253730\n",
              "fractal_dimension_se       0.077972\n",
              "id                         0.039769\n",
              "symmetry_se               -0.006522\n",
              "texture_se                -0.008303\n",
              "fractal_dimension_mean    -0.012838\n",
              "smoothness_se             -0.067016\n",
              "Name: diagnosis, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU5cJ1X4_Icc",
        "colab_type": "text"
      },
      "source": [
        "##Extract the data by **Features** and **Labels** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx_NI-PjTC_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1)\n",
        "labels = df['diagnosis']\n",
        "my_features = ['concave points_worst',\n",
        "               'perimeter_worst',\n",
        "               'concave points_mean',\n",
        "               'radius_worst',\n",
        "               'perimeter_mean',\n",
        "               'area_worst',\n",
        "               'radius_mean',\n",
        "               'area_mean',\n",
        "               'concavity_mean',\n",
        "               'concavity_worst',\n",
        "               'compactness_mean',\n",
        "               'compactness_worst'\n",
        "               ]\n",
        "features = df[my_features]\n",
        "labels = labels.to_numpy()\n",
        "features = features.to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfy7-7oHUq8I",
        "colab_type": "code",
        "outputId": "131b6120-0cd1-4e75-8aff-9df8e93e64d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(type(labels))\n",
        "print(type(features))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaZtRmMMVEA9",
        "colab_type": "code",
        "outputId": "5f574d98-deb8-4624-d56e-1c8d27a15b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "print('Labels')\n",
        "print(labels.shape. end=' ')\n",
        "print(labels.ndim)\n",
        "\n",
        "print('\\nFeatures:')\n",
        "print(features.shape. end=' ')\n",
        "print(features.ndim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels\n",
            "(569,)\n",
            "1\n",
            "\n",
            "Features:\n",
            "(569, 12)\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPMK5fBJ_PiU",
        "colab_type": "text"
      },
      "source": [
        "###Split the data between train, validation and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61qphebkCKqa",
        "colab_type": "text"
      },
      "source": [
        "Should try split more the data with train, validation and test data to check if the model is overfited."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdLnMS1LngbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Features & Targets Train\n",
        "train_features = features[:455]\n",
        "train_labels = labels[:455]\n",
        "\n",
        "#Features & Targets Validation\n",
        "validation_features = features[455:]\n",
        "validation_labels = labels[455:]\n",
        "\n",
        "# Test data\n",
        "test_features = train_features[:57]\n",
        "test_labels = train_labels[:57]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViiHvgJTgce7",
        "colab_type": "code",
        "outputId": "ba3cf5dd-ca54-440e-8837-35c812709ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "print('Train')\n",
        "print('Features: ', train_features.shape, end=' Labels: ')\n",
        "print(train_labels.shape)\n",
        "print('Validation')\n",
        "print('Features: ', validation_features.shape, end=' Labels: ')\n",
        "print(validation_labels.shape)\n",
        "print('Test')\n",
        "print('Features: ', test_features.shape, end=' Labels: ')\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 12)\n",
            "(455,)\n",
            "(114, 12)\n",
            "(114,)\n",
            "(57, 12)\n",
            "(57,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib9tJFsLcEma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = tf.convert_to_tensor(train_features, np.float64)\n",
        "train_labels = tf.convert_to_tensor(train_labels, np.float64)\n",
        "\n",
        "validation_features = tf.convert_to_tensor(validation_features, np.float64)\n",
        "validation_labels = tf.convert_to_tensor(validation_labels, np.float64)\n",
        "\n",
        "test_features = tf.convert_to_tensor(test_features, np.float64)\n",
        "test_labels = tf.convert_to_tensor(test_labels, np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqtO8GfTAN4D",
        "colab_type": "text"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTrjfobpZOxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_model(epochs, batch_size, lr):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(12, activation='relu', input_shape=[12]),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(2, activation='softmax'),\n",
        "  ])\n",
        "  model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  trained = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    verbose=2,\n",
        "    steps_per_epoch=len(train_features)//batch_size,\n",
        "    validation_steps=len(validation_features)//batch_size,\n",
        "    validation_data=(validation_features, validation_labels)\n",
        "  )\n",
        "  return trained, model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7DAJObTAgLB",
        "colab_type": "text"
      },
      "source": [
        "###Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q20syxnPZMaF",
        "colab_type": "code",
        "outputId": "a8a24777-b08b-4474-c4a8-466f00164016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history, model = my_model(epochs=150, batch_size=16, lr=0.00085)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "28/28 - 0s - loss: 25.1367 - accuracy: 0.5871 - val_loss: 1.9537 - val_accuracy: 0.6161\n",
            "Epoch 2/150\n",
            "28/28 - 0s - loss: 19.2874 - accuracy: 0.5467 - val_loss: 7.9056 - val_accuracy: 0.7411\n",
            "Epoch 3/150\n",
            "28/28 - 0s - loss: 13.4941 - accuracy: 0.6560 - val_loss: 4.9971 - val_accuracy: 0.8304\n",
            "Epoch 4/150\n",
            "28/28 - 0s - loss: 10.0832 - accuracy: 0.6651 - val_loss: 3.9278 - val_accuracy: 0.8571\n",
            "Epoch 5/150\n",
            "28/28 - 0s - loss: 9.8699 - accuracy: 0.6241 - val_loss: 7.1818 - val_accuracy: 0.7768\n",
            "Epoch 6/150\n",
            "28/28 - 0s - loss: 8.9513 - accuracy: 0.6538 - val_loss: 2.1019 - val_accuracy: 0.8839\n",
            "Epoch 7/150\n",
            "28/28 - 0s - loss: 6.8709 - accuracy: 0.6743 - val_loss: 3.5714 - val_accuracy: 0.8661\n",
            "Epoch 8/150\n",
            "28/28 - 0s - loss: 5.4445 - accuracy: 0.7221 - val_loss: 3.6572 - val_accuracy: 0.8571\n",
            "Epoch 9/150\n",
            "28/28 - 0s - loss: 4.4844 - accuracy: 0.7130 - val_loss: 3.6331 - val_accuracy: 0.8571\n",
            "Epoch 10/150\n",
            "28/28 - 0s - loss: 3.9009 - accuracy: 0.7198 - val_loss: 3.6279 - val_accuracy: 0.8571\n",
            "Epoch 11/150\n",
            "28/28 - 0s - loss: 3.9426 - accuracy: 0.7335 - val_loss: 1.5525 - val_accuracy: 0.8839\n",
            "Epoch 12/150\n",
            "28/28 - 0s - loss: 3.2163 - accuracy: 0.7244 - val_loss: 1.9513 - val_accuracy: 0.8661\n",
            "Epoch 13/150\n",
            "28/28 - 0s - loss: 2.3668 - accuracy: 0.7312 - val_loss: 2.2853 - val_accuracy: 0.8571\n",
            "Epoch 14/150\n",
            "28/28 - 0s - loss: 2.2824 - accuracy: 0.7608 - val_loss: 1.7231 - val_accuracy: 0.8661\n",
            "Epoch 15/150\n",
            "28/28 - 0s - loss: 2.8969 - accuracy: 0.7175 - val_loss: 1.5848 - val_accuracy: 0.8661\n",
            "Epoch 16/150\n",
            "28/28 - 0s - loss: 1.8983 - accuracy: 0.7745 - val_loss: 1.3715 - val_accuracy: 0.8750\n",
            "Epoch 17/150\n",
            "28/28 - 0s - loss: 1.9754 - accuracy: 0.7312 - val_loss: 1.7333 - val_accuracy: 0.8571\n",
            "Epoch 18/150\n",
            "28/28 - 0s - loss: 1.4050 - accuracy: 0.7973 - val_loss: 1.1584 - val_accuracy: 0.8750\n",
            "Epoch 19/150\n",
            "28/28 - 0s - loss: 1.7109 - accuracy: 0.7494 - val_loss: 1.2373 - val_accuracy: 0.8750\n",
            "Epoch 20/150\n",
            "28/28 - 0s - loss: 1.5796 - accuracy: 0.7608 - val_loss: 0.9701 - val_accuracy: 0.8839\n",
            "Epoch 21/150\n",
            "28/28 - 0s - loss: 1.4956 - accuracy: 0.7882 - val_loss: 0.7665 - val_accuracy: 0.8839\n",
            "Epoch 22/150\n",
            "28/28 - 0s - loss: 1.4706 - accuracy: 0.7927 - val_loss: 0.7184 - val_accuracy: 0.8839\n",
            "Epoch 23/150\n",
            "28/28 - 0s - loss: 1.0748 - accuracy: 0.7836 - val_loss: 0.8268 - val_accuracy: 0.8750\n",
            "Epoch 24/150\n",
            "28/28 - 0s - loss: 1.2203 - accuracy: 0.7995 - val_loss: 0.7065 - val_accuracy: 0.8750\n",
            "Epoch 25/150\n",
            "28/28 - 0s - loss: 1.0062 - accuracy: 0.8064 - val_loss: 0.7794 - val_accuracy: 0.8661\n",
            "Epoch 26/150\n",
            "28/28 - 0s - loss: 0.7644 - accuracy: 0.8178 - val_loss: 0.5773 - val_accuracy: 0.8750\n",
            "Epoch 27/150\n",
            "28/28 - 0s - loss: 0.8926 - accuracy: 0.7973 - val_loss: 0.5716 - val_accuracy: 0.8839\n",
            "Epoch 28/150\n",
            "28/28 - 0s - loss: 0.7047 - accuracy: 0.8200 - val_loss: 0.5301 - val_accuracy: 0.8750\n",
            "Epoch 29/150\n",
            "28/28 - 0s - loss: 0.7153 - accuracy: 0.7950 - val_loss: 0.5473 - val_accuracy: 0.8750\n",
            "Epoch 30/150\n",
            "28/28 - 0s - loss: 0.5732 - accuracy: 0.8504 - val_loss: 0.4903 - val_accuracy: 0.8750\n",
            "Epoch 31/150\n",
            "28/28 - 0s - loss: 0.6891 - accuracy: 0.8178 - val_loss: 0.4509 - val_accuracy: 0.8750\n",
            "Epoch 32/150\n",
            "28/28 - 0s - loss: 0.7249 - accuracy: 0.8018 - val_loss: 0.4236 - val_accuracy: 0.8750\n",
            "Epoch 33/150\n",
            "28/28 - 0s - loss: 0.5287 - accuracy: 0.8337 - val_loss: 0.4318 - val_accuracy: 0.8750\n",
            "Epoch 34/150\n",
            "28/28 - 0s - loss: 0.5160 - accuracy: 0.8405 - val_loss: 0.4002 - val_accuracy: 0.8839\n",
            "Epoch 35/150\n",
            "28/28 - 0s - loss: 0.4832 - accuracy: 0.8451 - val_loss: 0.4168 - val_accuracy: 0.8750\n",
            "Epoch 36/150\n",
            "28/28 - 0s - loss: 0.4857 - accuracy: 0.8633 - val_loss: 0.4668 - val_accuracy: 0.8750\n",
            "Epoch 37/150\n",
            "28/28 - 0s - loss: 0.4523 - accuracy: 0.8793 - val_loss: 0.4042 - val_accuracy: 0.8750\n",
            "Epoch 38/150\n",
            "28/28 - 0s - loss: 0.4623 - accuracy: 0.8565 - val_loss: 0.4106 - val_accuracy: 0.8839\n",
            "Epoch 39/150\n",
            "28/28 - 0s - loss: 0.4678 - accuracy: 0.8565 - val_loss: 0.4076 - val_accuracy: 0.8750\n",
            "Epoch 40/150\n",
            "28/28 - 0s - loss: 0.3973 - accuracy: 0.8588 - val_loss: 0.3568 - val_accuracy: 0.8750\n",
            "Epoch 41/150\n",
            "28/28 - 0s - loss: 0.4981 - accuracy: 0.8405 - val_loss: 0.3340 - val_accuracy: 0.8750\n",
            "Epoch 42/150\n",
            "28/28 - 0s - loss: 0.3620 - accuracy: 0.8770 - val_loss: 0.3442 - val_accuracy: 0.8750\n",
            "Epoch 43/150\n",
            "28/28 - 0s - loss: 0.3481 - accuracy: 0.8793 - val_loss: 0.3317 - val_accuracy: 0.8750\n",
            "Epoch 44/150\n",
            "28/28 - 0s - loss: 0.4948 - accuracy: 0.8542 - val_loss: 0.3138 - val_accuracy: 0.8750\n",
            "Epoch 45/150\n",
            "28/28 - 0s - loss: 0.3849 - accuracy: 0.8633 - val_loss: 0.3135 - val_accuracy: 0.8750\n",
            "Epoch 46/150\n",
            "28/28 - 0s - loss: 0.3599 - accuracy: 0.8793 - val_loss: 0.3134 - val_accuracy: 0.8750\n",
            "Epoch 47/150\n",
            "28/28 - 0s - loss: 0.3695 - accuracy: 0.8884 - val_loss: 0.3017 - val_accuracy: 0.8750\n",
            "Epoch 48/150\n",
            "28/28 - 0s - loss: 0.3441 - accuracy: 0.8907 - val_loss: 0.3078 - val_accuracy: 0.8839\n",
            "Epoch 49/150\n",
            "28/28 - 0s - loss: 0.3226 - accuracy: 0.8815 - val_loss: 0.3124 - val_accuracy: 0.8839\n",
            "Epoch 50/150\n",
            "28/28 - 0s - loss: 0.3135 - accuracy: 0.8770 - val_loss: 0.3139 - val_accuracy: 0.8839\n",
            "Epoch 51/150\n",
            "28/28 - 0s - loss: 0.3421 - accuracy: 0.8793 - val_loss: 0.3081 - val_accuracy: 0.8839\n",
            "Epoch 52/150\n",
            "28/28 - 0s - loss: 0.2583 - accuracy: 0.9157 - val_loss: 0.3030 - val_accuracy: 0.8750\n",
            "Epoch 53/150\n",
            "28/28 - 0s - loss: 0.3019 - accuracy: 0.8975 - val_loss: 0.2935 - val_accuracy: 0.8661\n",
            "Epoch 54/150\n",
            "28/28 - 0s - loss: 0.2688 - accuracy: 0.9112 - val_loss: 0.3004 - val_accuracy: 0.8839\n",
            "Epoch 55/150\n",
            "28/28 - 0s - loss: 0.2944 - accuracy: 0.9043 - val_loss: 0.2889 - val_accuracy: 0.8661\n",
            "Epoch 56/150\n",
            "28/28 - 0s - loss: 0.2545 - accuracy: 0.9043 - val_loss: 0.2808 - val_accuracy: 0.8750\n",
            "Epoch 57/150\n",
            "28/28 - 0s - loss: 0.3032 - accuracy: 0.8907 - val_loss: 0.2853 - val_accuracy: 0.8839\n",
            "Epoch 58/150\n",
            "28/28 - 0s - loss: 0.2355 - accuracy: 0.9226 - val_loss: 0.2751 - val_accuracy: 0.8750\n",
            "Epoch 59/150\n",
            "28/28 - 0s - loss: 0.2920 - accuracy: 0.9040 - val_loss: 0.2559 - val_accuracy: 0.8839\n",
            "Epoch 60/150\n",
            "28/28 - 0s - loss: 0.2625 - accuracy: 0.8975 - val_loss: 0.2581 - val_accuracy: 0.8750\n",
            "Epoch 61/150\n",
            "28/28 - 0s - loss: 0.2741 - accuracy: 0.8861 - val_loss: 0.2509 - val_accuracy: 0.8839\n",
            "Epoch 62/150\n",
            "28/28 - 0s - loss: 0.2701 - accuracy: 0.8907 - val_loss: 0.2475 - val_accuracy: 0.8839\n",
            "Epoch 63/150\n",
            "28/28 - 0s - loss: 0.2610 - accuracy: 0.9066 - val_loss: 0.2444 - val_accuracy: 0.8929\n",
            "Epoch 64/150\n",
            "28/28 - 0s - loss: 0.2391 - accuracy: 0.9112 - val_loss: 0.2550 - val_accuracy: 0.8839\n",
            "Epoch 65/150\n",
            "28/28 - 0s - loss: 0.2317 - accuracy: 0.9180 - val_loss: 0.2398 - val_accuracy: 0.8929\n",
            "Epoch 66/150\n",
            "28/28 - 0s - loss: 0.2317 - accuracy: 0.9134 - val_loss: 0.2428 - val_accuracy: 0.8839\n",
            "Epoch 67/150\n",
            "28/28 - 0s - loss: 0.2918 - accuracy: 0.8838 - val_loss: 0.2361 - val_accuracy: 0.9107\n",
            "Epoch 68/150\n",
            "28/28 - 0s - loss: 0.2315 - accuracy: 0.9021 - val_loss: 0.2361 - val_accuracy: 0.9018\n",
            "Epoch 69/150\n",
            "28/28 - 0s - loss: 0.2379 - accuracy: 0.9021 - val_loss: 0.2279 - val_accuracy: 0.9018\n",
            "Epoch 70/150\n",
            "28/28 - 0s - loss: 0.2715 - accuracy: 0.8998 - val_loss: 0.2357 - val_accuracy: 0.9018\n",
            "Epoch 71/150\n",
            "28/28 - 0s - loss: 0.2310 - accuracy: 0.9180 - val_loss: 0.2346 - val_accuracy: 0.9018\n",
            "Epoch 72/150\n",
            "28/28 - 0s - loss: 0.2458 - accuracy: 0.9134 - val_loss: 0.2210 - val_accuracy: 0.9107\n",
            "Epoch 73/150\n",
            "28/28 - 0s - loss: 0.2655 - accuracy: 0.8952 - val_loss: 0.2285 - val_accuracy: 0.9018\n",
            "Epoch 74/150\n",
            "28/28 - 0s - loss: 0.2375 - accuracy: 0.9203 - val_loss: 0.2257 - val_accuracy: 0.9018\n",
            "Epoch 75/150\n",
            "28/28 - 0s - loss: 0.2443 - accuracy: 0.9043 - val_loss: 0.2294 - val_accuracy: 0.9018\n",
            "Epoch 76/150\n",
            "28/28 - 0s - loss: 0.2562 - accuracy: 0.8929 - val_loss: 0.2231 - val_accuracy: 0.9107\n",
            "Epoch 77/150\n",
            "28/28 - 0s - loss: 0.2729 - accuracy: 0.9066 - val_loss: 0.2227 - val_accuracy: 0.9107\n",
            "Epoch 78/150\n",
            "28/28 - 0s - loss: 0.2380 - accuracy: 0.9271 - val_loss: 0.2269 - val_accuracy: 0.9018\n",
            "Epoch 79/150\n",
            "28/28 - 0s - loss: 0.2353 - accuracy: 0.9066 - val_loss: 0.2218 - val_accuracy: 0.9107\n",
            "Epoch 80/150\n",
            "28/28 - 0s - loss: 0.2494 - accuracy: 0.9089 - val_loss: 0.2194 - val_accuracy: 0.9107\n",
            "Epoch 81/150\n",
            "28/28 - 0s - loss: 0.2552 - accuracy: 0.9021 - val_loss: 0.2198 - val_accuracy: 0.9107\n",
            "Epoch 82/150\n",
            "28/28 - 0s - loss: 0.2111 - accuracy: 0.9157 - val_loss: 0.2202 - val_accuracy: 0.9107\n",
            "Epoch 83/150\n",
            "28/28 - 0s - loss: 0.2826 - accuracy: 0.8929 - val_loss: 0.2316 - val_accuracy: 0.9018\n",
            "Epoch 84/150\n",
            "28/28 - 0s - loss: 0.2374 - accuracy: 0.9043 - val_loss: 0.2299 - val_accuracy: 0.9018\n",
            "Epoch 85/150\n",
            "28/28 - 0s - loss: 0.2548 - accuracy: 0.9021 - val_loss: 0.2230 - val_accuracy: 0.9107\n",
            "Epoch 86/150\n",
            "28/28 - 0s - loss: 0.2414 - accuracy: 0.9043 - val_loss: 0.2194 - val_accuracy: 0.9107\n",
            "Epoch 87/150\n",
            "28/28 - 0s - loss: 0.2601 - accuracy: 0.9066 - val_loss: 0.2258 - val_accuracy: 0.9107\n",
            "Epoch 88/150\n",
            "28/28 - 0s - loss: 0.2323 - accuracy: 0.9062 - val_loss: 0.2332 - val_accuracy: 0.9018\n",
            "Epoch 89/150\n",
            "28/28 - 0s - loss: 0.2577 - accuracy: 0.9089 - val_loss: 0.2172 - val_accuracy: 0.9107\n",
            "Epoch 90/150\n",
            "28/28 - 0s - loss: 0.2153 - accuracy: 0.9271 - val_loss: 0.2253 - val_accuracy: 0.9018\n",
            "Epoch 91/150\n",
            "28/28 - 0s - loss: 0.2340 - accuracy: 0.9021 - val_loss: 0.2174 - val_accuracy: 0.9107\n",
            "Epoch 92/150\n",
            "28/28 - 0s - loss: 0.2571 - accuracy: 0.8975 - val_loss: 0.2209 - val_accuracy: 0.9018\n",
            "Epoch 93/150\n",
            "28/28 - 0s - loss: 0.2158 - accuracy: 0.9089 - val_loss: 0.2147 - val_accuracy: 0.9107\n",
            "Epoch 94/150\n",
            "28/28 - 0s - loss: 0.2351 - accuracy: 0.9066 - val_loss: 0.2059 - val_accuracy: 0.9018\n",
            "Epoch 95/150\n",
            "28/28 - 0s - loss: 0.2370 - accuracy: 0.9157 - val_loss: 0.2211 - val_accuracy: 0.9107\n",
            "Epoch 96/150\n",
            "28/28 - 0s - loss: 0.2140 - accuracy: 0.9112 - val_loss: 0.2060 - val_accuracy: 0.9107\n",
            "Epoch 97/150\n",
            "28/28 - 0s - loss: 0.2567 - accuracy: 0.9112 - val_loss: 0.2185 - val_accuracy: 0.9107\n",
            "Epoch 98/150\n",
            "28/28 - 0s - loss: 0.2043 - accuracy: 0.9248 - val_loss: 0.2053 - val_accuracy: 0.9018\n",
            "Epoch 99/150\n",
            "28/28 - 0s - loss: 0.2177 - accuracy: 0.9021 - val_loss: 0.2117 - val_accuracy: 0.9107\n",
            "Epoch 100/150\n",
            "28/28 - 0s - loss: 0.2329 - accuracy: 0.9134 - val_loss: 0.2157 - val_accuracy: 0.9018\n",
            "Epoch 101/150\n",
            "28/28 - 0s - loss: 0.2537 - accuracy: 0.9157 - val_loss: 0.2297 - val_accuracy: 0.9018\n",
            "Epoch 102/150\n",
            "28/28 - 0s - loss: 0.2314 - accuracy: 0.9043 - val_loss: 0.2067 - val_accuracy: 0.9018\n",
            "Epoch 103/150\n",
            "28/28 - 0s - loss: 0.2480 - accuracy: 0.9043 - val_loss: 0.2069 - val_accuracy: 0.9018\n",
            "Epoch 104/150\n",
            "28/28 - 0s - loss: 0.2291 - accuracy: 0.9112 - val_loss: 0.2138 - val_accuracy: 0.9018\n",
            "Epoch 105/150\n",
            "28/28 - 0s - loss: 0.2504 - accuracy: 0.8907 - val_loss: 0.2023 - val_accuracy: 0.9107\n",
            "Epoch 106/150\n",
            "28/28 - 0s - loss: 0.2134 - accuracy: 0.9271 - val_loss: 0.2145 - val_accuracy: 0.9018\n",
            "Epoch 107/150\n",
            "28/28 - 0s - loss: 0.2274 - accuracy: 0.9134 - val_loss: 0.2026 - val_accuracy: 0.9018\n",
            "Epoch 108/150\n",
            "28/28 - 0s - loss: 0.2328 - accuracy: 0.9043 - val_loss: 0.2113 - val_accuracy: 0.9018\n",
            "Epoch 109/150\n",
            "28/28 - 0s - loss: 0.2287 - accuracy: 0.9066 - val_loss: 0.2100 - val_accuracy: 0.9018\n",
            "Epoch 110/150\n",
            "28/28 - 0s - loss: 0.2452 - accuracy: 0.8998 - val_loss: 0.2161 - val_accuracy: 0.9018\n",
            "Epoch 111/150\n",
            "28/28 - 0s - loss: 0.2020 - accuracy: 0.9248 - val_loss: 0.2306 - val_accuracy: 0.9107\n",
            "Epoch 112/150\n",
            "28/28 - 0s - loss: 0.2461 - accuracy: 0.8929 - val_loss: 0.2199 - val_accuracy: 0.9018\n",
            "Epoch 113/150\n",
            "28/28 - 0s - loss: 0.2488 - accuracy: 0.8998 - val_loss: 0.2220 - val_accuracy: 0.9018\n",
            "Epoch 114/150\n",
            "28/28 - 0s - loss: 0.2239 - accuracy: 0.9043 - val_loss: 0.2160 - val_accuracy: 0.9018\n",
            "Epoch 115/150\n",
            "28/28 - 0s - loss: 0.2334 - accuracy: 0.9021 - val_loss: 0.2115 - val_accuracy: 0.9107\n",
            "Epoch 116/150\n",
            "28/28 - 0s - loss: 0.2324 - accuracy: 0.9089 - val_loss: 0.2128 - val_accuracy: 0.9018\n",
            "Epoch 117/150\n",
            "28/28 - 0s - loss: 0.2288 - accuracy: 0.9174 - val_loss: 0.2137 - val_accuracy: 0.9018\n",
            "Epoch 118/150\n",
            "28/28 - 0s - loss: 0.2331 - accuracy: 0.9021 - val_loss: 0.2270 - val_accuracy: 0.9196\n",
            "Epoch 119/150\n",
            "28/28 - 0s - loss: 0.2335 - accuracy: 0.9043 - val_loss: 0.2141 - val_accuracy: 0.9018\n",
            "Epoch 120/150\n",
            "28/28 - 0s - loss: 0.2160 - accuracy: 0.9226 - val_loss: 0.2237 - val_accuracy: 0.9107\n",
            "Epoch 121/150\n",
            "28/28 - 0s - loss: 0.2374 - accuracy: 0.8929 - val_loss: 0.2110 - val_accuracy: 0.9018\n",
            "Epoch 122/150\n",
            "28/28 - 0s - loss: 0.2255 - accuracy: 0.9043 - val_loss: 0.2140 - val_accuracy: 0.9018\n",
            "Epoch 123/150\n",
            "28/28 - 0s - loss: 0.2146 - accuracy: 0.9043 - val_loss: 0.2159 - val_accuracy: 0.9018\n",
            "Epoch 124/150\n",
            "28/28 - 0s - loss: 0.2301 - accuracy: 0.9112 - val_loss: 0.2347 - val_accuracy: 0.9107\n",
            "Epoch 125/150\n",
            "28/28 - 0s - loss: 0.2182 - accuracy: 0.9112 - val_loss: 0.2255 - val_accuracy: 0.9018\n",
            "Epoch 126/150\n",
            "28/28 - 0s - loss: 0.2152 - accuracy: 0.9112 - val_loss: 0.2639 - val_accuracy: 0.9196\n",
            "Epoch 127/150\n",
            "28/28 - 0s - loss: 0.2063 - accuracy: 0.9112 - val_loss: 0.2179 - val_accuracy: 0.9018\n",
            "Epoch 128/150\n",
            "28/28 - 0s - loss: 0.2236 - accuracy: 0.9157 - val_loss: 0.2058 - val_accuracy: 0.9018\n",
            "Epoch 129/150\n",
            "28/28 - 0s - loss: 0.2229 - accuracy: 0.9134 - val_loss: 0.2268 - val_accuracy: 0.9196\n",
            "Epoch 130/150\n",
            "28/28 - 0s - loss: 0.2047 - accuracy: 0.9157 - val_loss: 0.2182 - val_accuracy: 0.9107\n",
            "Epoch 131/150\n",
            "28/28 - 0s - loss: 0.2031 - accuracy: 0.9226 - val_loss: 0.2131 - val_accuracy: 0.9018\n",
            "Epoch 132/150\n",
            "28/28 - 0s - loss: 0.2123 - accuracy: 0.9180 - val_loss: 0.2105 - val_accuracy: 0.9018\n",
            "Epoch 133/150\n",
            "28/28 - 0s - loss: 0.2029 - accuracy: 0.9203 - val_loss: 0.2533 - val_accuracy: 0.9107\n",
            "Epoch 134/150\n",
            "28/28 - 0s - loss: 0.2267 - accuracy: 0.8998 - val_loss: 0.2304 - val_accuracy: 0.8929\n",
            "Epoch 135/150\n",
            "28/28 - 0s - loss: 0.2242 - accuracy: 0.9134 - val_loss: 0.2521 - val_accuracy: 0.9107\n",
            "Epoch 136/150\n",
            "28/28 - 0s - loss: 0.2226 - accuracy: 0.9157 - val_loss: 0.2562 - val_accuracy: 0.9018\n",
            "Epoch 137/150\n",
            "28/28 - 0s - loss: 0.1925 - accuracy: 0.9248 - val_loss: 0.2575 - val_accuracy: 0.9196\n",
            "Epoch 138/150\n",
            "28/28 - 0s - loss: 0.2284 - accuracy: 0.9043 - val_loss: 0.2265 - val_accuracy: 0.9018\n",
            "Epoch 139/150\n",
            "28/28 - 0s - loss: 0.1763 - accuracy: 0.9431 - val_loss: 0.2318 - val_accuracy: 0.9107\n",
            "Epoch 140/150\n",
            "28/28 - 0s - loss: 0.2344 - accuracy: 0.9066 - val_loss: 0.2260 - val_accuracy: 0.9018\n",
            "Epoch 141/150\n",
            "28/28 - 0s - loss: 0.2147 - accuracy: 0.9203 - val_loss: 0.2253 - val_accuracy: 0.9018\n",
            "Epoch 142/150\n",
            "28/28 - 0s - loss: 0.2299 - accuracy: 0.9112 - val_loss: 0.2424 - val_accuracy: 0.9196\n",
            "Epoch 143/150\n",
            "28/28 - 0s - loss: 0.2103 - accuracy: 0.8975 - val_loss: 0.2226 - val_accuracy: 0.9107\n",
            "Epoch 144/150\n",
            "28/28 - 0s - loss: 0.2307 - accuracy: 0.9021 - val_loss: 0.2238 - val_accuracy: 0.9107\n",
            "Epoch 145/150\n",
            "28/28 - 0s - loss: 0.2091 - accuracy: 0.9157 - val_loss: 0.2488 - val_accuracy: 0.9107\n",
            "Epoch 146/150\n",
            "28/28 - 0s - loss: 0.2139 - accuracy: 0.9196 - val_loss: 0.1995 - val_accuracy: 0.9107\n",
            "Epoch 147/150\n",
            "28/28 - 0s - loss: 0.2196 - accuracy: 0.9203 - val_loss: 0.2150 - val_accuracy: 0.9286\n",
            "Epoch 148/150\n",
            "28/28 - 0s - loss: 0.2208 - accuracy: 0.9089 - val_loss: 0.2231 - val_accuracy: 0.9196\n",
            "Epoch 149/150\n",
            "28/28 - 0s - loss: 0.2033 - accuracy: 0.9248 - val_loss: 0.2309 - val_accuracy: 0.9018\n",
            "Epoch 150/150\n",
            "28/28 - 0s - loss: 0.2299 - accuracy: 0.9021 - val_loss: 0.2207 - val_accuracy: 0.9196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VYI19E1ZiS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERMbcBlTAoE5",
        "colab_type": "text"
      },
      "source": [
        "###Show loss and accuaracy per epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnBEioJ7XMPz",
        "colab_type": "code",
        "outputId": "e66e4229-bf4f-4798-a3eb-6b7727b380ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(150)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAHiCAYAAADI/ORpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydeZhcVbW331VDV/U8J505nZAQEhISEojMiTIpIBcEBVGJKCrOOF+vnyCKcL04XL2iouIEgoiCIJMyJoACCVPIPHc63el5Hmrc3x/7VHV1d3VXdaeTHrLe56mnqvbZZ599Tned31lrr722GGNQFEVRFGXs4hrtDiiKoiiKMjgq1oqiKIoyxlGxVhRFUZQxjoq1oiiKooxxVKwVRVEUZYyjYq0oiqIoY5yjSqxF5DERuXqk644mIrJXRM4+DO0+KyIfdT5fJSL/SKfuMI4zU0TaRcQ93L4qSrroPWBI7eo9YAwx5sXa+SPGXlER6Ur4ftVQ2jLGvNMY87uRrjsWEZGvicjaJOUlIhIUkePTbcsYc7cx5twR6levG4sxpsIYk2OMiYxE+0mOJyKyW0Q2H472lcOP3gOGh94DQESMiBwz0u2OBmNerJ0/Yo4xJgeoAC5KKLs7Vk9EPKPXyzHJXcCpIlLep/wKYKMx5q1R6NNocCYwCZgjIicdyQPr/+TIoPeAYaP3gAnEmBfrgRCRVSJSKSJfFZGDwG9EpFBE/i4idSLS5HyenrBPoltnjYg8LyK3OXX3iMg7h1m3XETWikibiDwpIj8VkbsG6Hc6ffy2iLzgtPcPESlJ2P5BEdknIg0i8l8DXR9jTCXwNPDBPps+BPw+VT/69HmNiDyf8P0cEdkqIi0i8n+AJGybKyJPO/2rF5G7RaTA2fYHYCbwsGMVfUVEZjtPvx6nzlQReUhEGkVkp4hcm9D2jSJyn4j83rk2m0RkxUDXwOFq4G/Ao87nxPNaJCL/dI5VIyJfd8rdIvJ1EdnlHGeDiMzo21enbt//kxdE5Ici0gDcONj1cPaZISJ/df4ODSLyfyKS4fRpcUK9SSLSKSKlKc73qEHvAXoPSPMekOx88p026pxr+Q0RcTnbjhGR55xzqxeRPznl4vy2a0WkVUQ2yhC8E4fKuBVrhzKgCJgFfAx7Pr9xvs8EuoD/G2T/lcA2oAT4HvBrEZFh1P0j8DJQDNxI/x9HIun08f3Ah7EWYQbwJQARWQj8zGl/qnO8pD8uh98l9kVEjgWWOv0d6rWKtVEC/BX4BvZa7AJOS6wC3OL07zhgBvaaYIz5IL0to+8lOcS9QKWz/2XAd0Xk7Qnb3+3UKQAeGqzPIpLltHG387pCRDKcbbnAk8DjzrGOAZ5ydv0CcCXwLiAPuAboHPTC9LAS2A1MBm4e7HqIHaP7O7APmA1MA+41xgSdc/xAQrtXAk8ZY+rS7MfRgt4D9B6Qss9J+AmQD8wBzsI+wHzY2fZt4B9AIfba/sQpPxfrqZvv7PteoGEYxx4exphx8wL2Amc7n1cBQcA/SP2lQFPC92eBjzqf1wA7E7ZlAQYoG0pd7D95GMhK2H4XcFea55Ssj99I+P5J4HHn8zexN/PYtmznGpw9QNtZQCtwqvP9ZuBvw7xWzzufPwT8O6GeYH9YHx2g3f8AXkv2N3S+z3aupQf7o44AuQnbbwF+63y+EXgyYdtCoGuQa/sBoM5p2w+0AJc4265M7Fef/bYBFycpj/d1kOtUkeLvHb8ewCmx/iWptxJ7UxPn+3rgvaP5+xsLL/QeoPeAod0DDHBMnzK3c80WJpR9HHjW+fx74A5gep/93g5sB94GuI70//54t6zrjDHdsS8ikiUiv3DcGq3AWqBABo4yPBj7YIyJWU45Q6w7FWhMKAPYP1CH0+zjwYTPnQl9mprYtjGmg0Ge7Jw+/Rn4kGMBXIX9RxzOtYrRtw8m8buITBaRe0XkgNPuXdin73SIXcu2hLJ9WIszRt9r45eBxyqvBu4zxoSd/5O/0OMKn4G1CJIx2LZU9Prbp7geM4B9xphw30aMMS9hz2+ViCzAWv4PDbNPExm9B+g9YLB7QDJKAK/TbrJjfAX7APKy42a/BsAY8zTWiv8pUCsid4hI3hCOe0iMd7Huu2TYF4FjgZXGmDysywISxlMOA9VAkeNyjTFjkPqH0sfqxLadYxan2Od3WHfNOUAu8PAh9qNvH4Te5/td7N9lsdPuB/q0Odgyb1XYa5mbUDYTOJCiT/0QO/b2duADInJQ7JjmZcC7HDfefqwLLBn7gblJyjuc98S/dVmfOn3Pb7DrsR+YOciN5ndO/Q8C9yeKkhJH7wF6Dxgq9UAI6/7vdwxjzEFjzLXGmKlYi/t2cSLKjTE/NsYsx1r084Evj2C/BmW8i3VfcrHjLs0iUgTccLgPaIzZh3VR3ig2MOgU4KLD1Mf7gQtF5HRn7PUmUv8N1wHNWLdObDz0UPrxCLBIRC51ROaz9BasXKAdaBGRafT/Z65hAJE0xuwHXgRuERG/iCwBPoJ9Mh8qH8S6rGJjdEuxP65KrAv878AUEfm8iPhEJFdEVjr7/gr4tojMc4JKlohIsbHjxQewDwBu54k7magnMtj1eBl747tVRLKdc04c+7sLuAR7s/v9MK7B0YjeA/pztN4DYmQ4bflFxO+U3Qfc7PzuZ2HjVO4CEJHLpSfQrgn7cBEVkZNEZKWIeLEP7t1A9BD6NSQmmlj/CMjEPjn9Gxs8dCS4Cjv+2AB8B/gTEBig7rD7aIzZBHwKGxxSjf1Hqkyxj8He6GfR+4Y/rH4YY+qBy4Fbsec7D3ghocq3gBOx48OPYANRErkF+IaINIvIl5Ic4krsGFYV8ABwgzHmyXT61oergdudp+T4C/g5cLXjZjsHe1M9COwAVjv7/gD7Y/4Hdrzv19hrBXAt9ubTACzC3lgGY8DrYey80ouwLu4K7N/yfQnb9wOvYm8W64Z+CY5K9B7Qf5+j9R4QYxP2oST2+jDwGazg7gaex17PO536JwEviUg7dujpc8aY3dhg019ir/k+7Ln/zyH0a0jEgleUEURsqP9WY8xhf6pXJjYicidQZYz5xmj3RUkfvQcoI81Es6xHBcc9MldEXCJyPnAx8OBo90sZ34jIbOBSrGWvjGH0HqAcbjTjz8hQhnX1FGNdUtcZY14b3S4p4xkR+TZwPXCLMWbPaPdHSYneA5TDirrBFUVRFGWMo25wRVEURRnjqFgriqIoyhhnzI1Zl5SUmNmzZ492NxRlzLNhw4Z6Y8yYXthDf8+Kkh6pfs9jTqxnz57N+vXrR7sbijLmEZF9qWuNLvp7VpT0SPV7Vje4oiiKooxxVKwVRVEUZYyjYq0oiqIoY5wxN2atKIqipCYUClFZWUl3ty7GNp7w+/1Mnz4dr9c7pP1UrBVFUcYhlZWV5ObmMnv2bOwqlcpYxxhDQ0MDlZWVlJeXD2lfdYMriqKMQ7q7uykuLlahHkeICMXFxcPyhqhYK4qijFNUqMcfw/2bpSXWInK+iGwTkZ0i8rUk22eJyFMi8qaIPJuwcDciEhGR153XQ8PqpaIoijKmaGhoYOnSpSxdupSysjKmTZsW/x4MBgfdd/369Xz2s59NeYxTTz11RPr67LPPcuGFF45IW6NFyjFrEXEDPwXOwa4m84qIPGSM2ZxQ7Tbg98aY34nI27GLi3/Q2dZljFk6wv1WFEVRRpHi4mJef/11AG688UZycnL40pe+FN8eDofxeJJLzIoVK1ixYkXKY7z44osj09kJQDqW9cnATmPMbmNMELgXu1ZrIguBp53PzyTZriiKokxw1qxZwyc+8QlWrlzJV77yFV5++WVOOeUUli1bxqmnnsq2bduA3pbujTfeyDXXXMOqVauYM2cOP/7xj+Pt5eTkxOuvWrWKyy67jAULFnDVVVcRWzHy0UcfZcGCBSxfvpzPfvazQ7Kg77nnHhYvXszxxx/PV7/6VQAikQhr1qzh+OOPZ/Hixfzwhz8E4Mc//jELFy5kyZIlXHHFFYd+sYZIOtHg04D9Cd8rgZV96rwBXAr8L3AJkCsixcaYBsAvIuuBMHCrMUYXZFcURRlBvvXwJjZXtY5omwun5nHDRYuGvF9lZSUvvvgibreb1tZW1q1bh8fj4cknn+TrX/86f/nLX/rts3XrVp555hna2to49thjue666/pNbXrttdfYtGkTU6dO5bTTTuOFF15gxYoVfPzjH2ft2rWUl5dz5ZVXpt3PqqoqvvrVr7JhwwYKCws599xzefDBB5kxYwYHDhzgrbfeAqC5uRmAW2+9lT179uDz+eJlR5KRCjD7EnCWiLwGnAUcACLOtlnGmBXA+4EficjcvjuLyMdEZL2IrK+rqxuhLimKoihHmssvvxy32w1AS0sLl19+OccffzzXX389mzZtSrrPBRdcgM/no6SkhEmTJlFTU9Ovzsknn8z06dNxuVwsXbqUvXv3snXrVubMmROfBjUUsX7llVdYtWoVpaWleDwerrrqKtauXcucOXPYvXs3n/nMZ3j88cfJy8sDYMmSJVx11VXcddddA7r3DyfpHPEAMCPh+3SnLI4xpgprWSMiOcB7jDHNzrYDzvtuEXkWWAbs6rP/HcAdACtWrDDDORFFUZSjleFYwIeL7Ozs+Of/9//+H6tXr+aBBx5g7969rFq1Kuk+Pp8v/tntdhMOh4dVZyQoLCzkjTfe4IknnuDnP/859913H3feeSePPPIIa9eu5eGHH+bmm29m48aNR1S007GsXwHmiUi5iGQAVwC9orpFpEREYm39J3CnU14oIr5YHeA0IDEwTVEURZmgtLS0MG3aNAB++9vfjnj7xx57LLt372bv3r0A/OlPf0p735NPPpnnnnuO+vp6IpEI99xzD2eddRb19fVEo1He85738J3vfIdXX32VaDTK/v37Wb16Nf/93/9NS0sL7e3tI34+g5HyscAYExaRTwNPAG7gTmPMJhG5CVhvjHkIWAXcIiIGWAt8ytn9OOAXIhLFPhjc2ieKXFEURZmgfOUrX+Hqq6/mO9/5DhdccMGIt5+Zmcntt9/O+eefT3Z2NieddNKAdZ966immT4/PKubPf/4zt956K6tXr8YYwwUXXMDFF1/MG2+8wYc//GGi0SgAt9xyC5FIhA984AO0tLRgjOGzn/0sBQUFI34+gyGxiLqxwooVK4yuf6soqRGRDU48yJhFf8+Hjy1btnDccceNdjdGnfb2dnJycjDG8KlPfYp58+Zx/fXXj3a3BiXZ3y7V71kzmCmK0gsRmSEiz4jIZhHZJCKfc8pvFJEDCUmO3nWox+oORWjpCh16p5Wjll/+8pcsXbqURYsW0dLSwsc//vHR7tJhQcVaUQ4T+xs7WXzjE+yqO7JjWyNAGPiiMWYh8DbgUyKy0Nn2Q2PMUuf16KEe6Ka/b+Yd33/2UJtRjmKuv/56Xn/9dTZv3szdd99NVlbWaHfpsKBirSiHif2NnbR1h9nX0DHaXRkSxphqY8yrzuc2YAs238KI43EJkejYGopTlLGIirWiHCa6wzbVQHcoOso9GT4iMhs73fIlp+jTzhoAd4pI4aG27xIhrGKtKClRsVaUw0TAEenuUCRFzbGJkzPhL8DnjTGtwM+AucBSoBr4/gD7pZ3kyO0SoirWipISFWtFOUwEwtFe7+MJEfFihfpuY8xfAYwxNcaYiDEmCvwSu25AP4wxdxhjVhhjVpSWlg56HI9LLWtFSQcVa0U5TATibvDxZVmLXXD318AWY8wPEsqnJFS7BHjrUI/lcgnRMTZ9VEmP1atX88QTT/Qq+9GPfsR111034D6rVq0iNpXvXe96V9Ic2zfeeCO33XbboMd+8MEH2by5J2XHN7/5TZ588smhdD8pY3kpTRVrRTlMxCzqcThmfRp2idu395mm9T0R2SgibwKrgUOezKoBZuOXK6+8knvvvbdX2b333pt2fu5HH3102IlF+or1TTfdxNlnnz2stsYLKtaKcpiIWdTjzbI2xjxvjBFjzJLEaVrGmA8aYxY75e82xlQf6rFcIkQNjLXkTEpqLrvsMh555BGCwSAAe/fupaqqijPOOIPrrruOFStWsGjRIm644Yak+8+ePZv6+noAbr75ZubPn8/pp58eX0YT7Bzqk046iRNOOIH3vOc9dHZ28uKLL/LQQw/x5S9/maVLl7Jr1y7WrFnD/fffD9hMZcuWLWPx4sVcc801BAKB+PFuuOEGTjzxRBYvXszWrVvTPtexsJTmkV86RFGOEmIBZuNxzPpI4XEJAJGoweOWUe7NOOaxr8HBjSPbZtlieOetA24uKiri5JNP5rHHHuPiiy/m3nvv5b3vfS8iws0330xRURGRSIR3vOMdvPnmmyxZsiRpOxs2bODee+/l9ddfJxwOc+KJJ7J8+XIALr30Uq699loAvvGNb/DrX/+az3zmM7z73e/mwgsv5LLLLuvVVnd3N2vWrOGpp55i/vz5fOhDH+JnP/sZn//85wEoKSnh1Vdf5fbbb+e2227jV7/6VcrLMFaW0lTLWlEOEz1u8PFlWR9JXI5Ya5DZ+CTRFZ7oAr/vvvs48cQTWbZsGZs2berlsu7LunXruOSSS8jKyiIvL493v/vd8W1vvfUWZ5xxBosXL+buu+8ecInNGNu2baO8vJz58+cDcPXVV7N27dr49ksvvRSA5cuXxxf/SMVYWUpTLWtFOUzEAsxi70p/Ypa1BpkdIoNYwIeTiy++mOuvv55XX32Vzs5Oli9fzp49e7jtttt45ZVXKCwsZM2aNXR3dw+r/TVr1vDggw9ywgkn8Nvf/pZnn332kPobW2ZzJJbYPNJLaaplrSiHiXEcYHbEcKtlPa7Jyclh9erVXHPNNXGrurW1lezsbPLz86mpqeGxxx4btI0zzzyTBx98kK6uLtra2nj44Yfj29ra2pgyZQqhUIi77747Xp6bm0tbW1u/to499lj27t3Lzp07AfjDH/7AWWeddUjnOFaW0lTLWlEOEzH3t1rWA+MSx7JWsR63XHnllVxyySVxd/gJJ5zAsmXLWLBgATNmzOC0004bdP8TTzyR973vfZxwwglMmjSp1zKX3/72t1m5ciWlpaWsXLkyLtBXXHEF1157LT/+8Y/jgWUAfr+f3/zmN1x++eWEw2FOOukkPvGJTwzpfMbqUpq6RKaiHCY+d+9r/O31Kt6+YBJ3rhl4nd3hMhGWyPz9v/byzb9tYsM3zqY4x3fkOjYB0CUyxy+6RKaijCHSTjfa1QTP/jdEDm0MbTwSs6x1rrWiDI6KtTIkAuHIsN263aEI4cjIjd+2B8Jjen5u2hnMtv8Dnv0uHDj6PErxqVtj+O+oKGMBFWtlSHzhT2/whT+9Max9L739RX705I4R6Ud7IMzKm5/ksbcOjkh7h4PudOdZdzXZ98Y9h7lHY4/41K2IirWiDIaKtTIkdtd3sKd+eOsz765vZ19j54j0o7kzSEcwwraD/SNCxwppW9Zxsd59mHs09tCpW4fGWPYsKckZ7t9MxVoZEm3dIdoCoSHv1x2K0B2K0hEYfFzWGMN1d23gma21Kdqz1mp9e6Dftq8/sJEHXqscch9HijvW7uK2J7alP3Wr28ly1LSHbz28iT++VHGYezh20Klbw8fv99PQ0KCCPY4wxtDQ0IDf7x/yvjp1SxkSrV2huOtyqPsBKcW6PRDmsbcOMqMoi9ULJg1YL2a1JhPrR96sJhCKcsmy6f22HQkefK2KcDRKTH9SjvEnWNYP11Rz4swu3r9y5uHt5BhBp24Nn+nTp1NZWUmqNcOVsYXf7+81NSxdVKwnELvq2nlpd+Nhu9FHo4b2QBgRwRiDSPqi3RwT6+DgYl3fbhcFaOsevF6PZR3sVW6MoSMQTjvF53Pb6xDgzPmDr7ucSCRq+OkzO7ny5JmU5vaebmSMYX9jJ9k+D16PvT6BVJa1I9amcTdNnUHaUzzQTCQ8alkPG6/XS3l5+Wh3QzlCqBt8AnH/hkq+/sBGQiMYcZ1IRzBM1Fix6gwOLSK8JW5ZD75fXZu1lFMJVsAR41j9eHk4Sjhq6EpTrH/4z+385OmhBb29UdnMD/65nXte7u+ubuoM0RYI09odij9QdKdpWUtXE9nRtqNKrF0unbqlKOmgYj2B6HIENOZyPlRqWrvZnxAQlmjttnYP7RjNnem5wWNu7fYU7XcP4AaPtd+V5sNES1doyA8eW6ttUNu6HXXUtnWzu64nneC+Bht81xmM0On0JRSx1nZVc1fS9qKdTUTddgxrltTSnsKrMJHQADNFSQ8V6wlEzPXbMkJifeNDm/jcva/FvycKdCo3dV9a0hyzjot1SsvaWq2dwUivNmPCO6hlHWiHv18PXc00dwYHFvb2WnjkixB2Hgh2PQP/+ilbqlsBeLWimZNvfoq3f/+5+C4VjZ2c73qZy9zP0RGMEBve//Q9r3H73ffBM7f0OsTzO+ppbqxlQ8gOXcyWg1zY+SD89WODnv9EQVfdUpT0ULGeQHSlKdaDRY8mbqtvD3CwpWe1nF6W9RAfCOJiHYwMGkxU77i1U45ZJ7iWE63rmMgPOmZd+Qqsv5Po3hdo6QoNLOy7noZXfgU1dr1aXrsLnr6ZrdUtZGW4k7pu9zV0crX7H3zU/SgAeZleAHbXtrOw4R/w3K3Q3Rqv/+OntpNn2tkatWI9SZqZH95u+3gUELesVawVZVBUrCcQMQuxeRAhvfKOf3PT35OvLfvk5hpWfOdJmjtt0FZ7IEJjZ08AV6JAD9myTmhnMKu3Lk3LOnE6VKJYx93gAxyjoT3AGzts8pFAWwNRw8Bu8FiUduJ7qIO6g5W8+4SpZGe4Achw9/yM9jV0UiDtFIh1jec7Yt0WCJMRckS6aU+8L1v3HcAjUSpNKRFc5Es7uaYN4y8c9PwnCm5Ry1pR0kHFegIRE6iBrN5AOMLLexv5+5vVSa3rbTVtNHQEeWFnAwCdwTDdoWj8IeBQxqwTrf3BXOF1bbEHhVRi3SOwsX3AWu4w8Jj1717cy5/WWUu5u61h0Lp0Nfd+d+ZDlwQrWTw9n99eczJXnDSDYCQa709FYwf50kE+duw6z++NNxcriyU/eXJLDXlOWTO5tJpsCuggX9oJ+0ZmpZ6xjlsta0VJCxXrccZ3H93Cc9uTz6tMNWa9o6adSNRQ1xZgW03/zF+x/dbtsO3HRDVmXScKdGuCcP9y7W7uW79/0H4nWvt9hfielyu4/Vm7/mxPgJnN+13R0MlHf7c+bu3HSEzhORTLeld9BwVYqzfU3ghAMBJNnrM8waL+nye20tZkr8tsVw3HTcnjpNlFLJyaB9gHmWjUsKe+k0LpIFOC+AjGLWuAfMfajqUV/efmGo7Jtf01mYU0mWxrldNBKCM/af8nGpoURVHSQ8V6nPH7f+3l8QHyYcfHrDuTi/XWhNSc67bX99seE8R1O+oxxsRFtamj/9zntgThvvulfTz0etWg/U58gOjrdr7n5Qr+7+mdBMPRuPCGo4ZAOMrNj27myS01vLa/udc+vS3r9Mes99Z3xEUz0tEYL08q7o5YB9ob+MVzu+P1F/oaWDjFinSu36YqaOsO8fCbVbS2t5OJHefPp6OXWMceEmKW9Y7adlY4eV+82UW0km33kQ4Cntyk/Z9ouHQhD0VJCxXrcYQxhu5QlJauYNLtMXfuQJb1lupW/F4Xc0qzWbujv3Ue2+9Acxc7a9vj48KNjli3doXIcLvIcLto7eoR7vr2IG0p3NYtXSG8bntj7mtZVzR20hmM8GpFE3VtATK9diz4ue11PLGpBqBXoBvYMesMt4vCLG9SyzoUMf3mmxtj2FvfQYHjejadCWKdzBXuiPXBg9VEopG4y/odZR34nT7G3NwNHUH+54ltnFzW85MqkPZ4gJn97rjBm/YCNpiuLMNO5/LnFdNsciiUNvLpoMuT178/E5D4qlu6kIeiDIqK9Tgi6IjPQGIcE9eBtm892Mqxk3M5aVYRW6r7u8GbO0NxS/CVvU3x8qa4GzxMXqaXXL8nbll3BSO0B8Ip50W3dIYoy7dziRPHrFu6QvE52I+/dZBAOMqs4iwA/ry+Ep/HhUugup9YR/B5XEzO8/cS8kSrva91XdcWoCMYiQd/0d2SdL+eBqw131hfwyRvAJdYQZlJTbxKriPWL+1uoLKpi48s7wkM621Zm57jNu6mMximIxih1GPnsWcXlNJMNjOlDpcYOl1HiWUtalkrSjqoWI8jYmLc3BkiGI5yoE+SjcGmbhlj2FLdxoKyPHL8HrqSpP1s6QoxuyQboFcCj7hl3R0iz+8hL9MbH7NOd150S1eIqfmZQE8QGEBFgxUrt0t4+A3rSi93+rCzto1pBZmU5vo42GL70xWMUNPaTSAcxed1M7Moi4qExC2J/ejr2o6tFhYTTXegOWnd2tZuXtxVT1erHSrobKnnzBlOZt6MHCRhday8TFu+u862PTOzx8ovkPa4WGcSIIMwnfih9QANTfZBodBl+55fVEqzyYn3re0oEWuPWwPMFCUdNDf4OCKQIMb3vlLBdx/dwiv/dXbcuhts6taB5i4aO4IsnJpHXVuAyeFKzH0fQi75BXgz4+2eVurmkwd/wMu1X4rv291SC3d+ki9V1/GbrKvBGK7Z83v4uZ/iYIRHMjp4oPsdwNkQDsKfPgBtzhj2rNMw77iB74S+x+uZn2GK61+Uv/U8LPg6PPAJamd/ng+6/8HHcp6ntStEV4aPN4t+yGT340gLbJt1FR2BcNyy/tGT23n59de5KeMu1ns+yaziLJ7bXkc0anC5hI5AmK957uH16Fy6g6t7LsCjXyFglgCFcXd2RrCFNe7HMQidwVPjVR//+VfY1JLBsZ56MgW8oVbOmuGFKmDqMti7DjobIauISXse5DPu53il9gp+4f0BJR2Xxtspl2ou2vwF7uS9FGW6wMCb0Tm8zbWZknvO45GMIMfs7QC3j9KiQvaQHd+3jaNDrHXqlqKkh1rW44i4m7szxJ76DrpD0fh6zsaYQaduvbDTWomnzC0mM8PNStmMbP4b1GyK12npCrFUdnCeez1ldS/Ey/NrN0DFi5SHdnBW+F+sivyLKcEKyJ9Bu7+MSdLMhTxnraOGnbDjCXBnQKgb1v+GrsJQU/EAACAASURBVP2v807Xy5wSWc973c8yb8/dULketv4d966neY97LdM8rUyfPoMVru2ck7WTD7if5ErXU5Tl+SnL91PTasX61YomFnW8xOL25znBtYuZRVkEwlFqnSCzzu4g17gf5VL3uh5rOdgJL/+Cot0P43ULRS4r1r5wCx9wP8n73U/FH3SC4SjndjzMp3LXxestLopy/lxnwY5pJ9p3Z6503pZ7eZ/nWTwNWzjPvZ7cHQ/Gr9u57g1Mr32WU1ybmJVl+/dw5G0EF1xCW9YMqkwJgcnL4MwvMSXfT4vJie/bnCDcExm3phtVlLRQsR5HxJZabAuEqW21N/8tjlgnTmVK5gZfu6OeyXk+5k3KISvDTRaOu9Zx6QbDUTqDEaZFqwHI7uxZpMLfvg+A/TKVadFqpkar2RSdwWn7ruU3M2/hH5EVzJIau6JWzEX8rv+BUz4JkQBdO2w6zmnRama5avCHW+jY8zIA9RVbKHfV4jruIvI//BdAyO3YywypZZbUUpaXwZT8TKpbujHGsLW6jVlix4xnUcPMYitqsZzcvo5qMiTCLKnpEWsnoCurfR8zirLi8539kXbnODV0Be01211dR5k0Mi24BzH2mmaGW/HEXOZTHbF2pl+5m/dSQDsZQevWdh18M37djhdbZ7bUMN1vr/duM4V9q3/CP0/4EdeGvkjXe+6Cs77ClHw/zaZHoJuiR5dYhzXATFEGRcV6HJGYtWuXs3hELE91LJjK65Z+Yh2JGl7YWc/px5QiImR63WQ504tiohPbZ1LYinVx0Lqx/V4XeV37IbOItziGyeEqJoer2GvKONDcxaMbq9lrJlMo7XS01MctTorm2BfQ9tYTAMyM7GUKNgI7vP0pAKZ3bSWfdlvX64e8aWRXv4RPwvgkxFx/G2X5ftq6w2yvaactEI6L9XQOMqvIBqPFxq1zuux875lSS1fAuQ5OnwqDVRxfmoGfAM1SgAuDT8L4JUS01Z73/l1bAHBHnYeZ7FIbFR6bcz11Wc91C3UhrQfIkW5KxQlWC3cDQpsrD7/Y489y1TDVZ693s8mhri0Qn25WlJ1hz6Uwi8vPWBz/mzUcZWKtAWaKMjgq1uOIxHzYu51gqZhYx6zISbl+OoORXtOWNlW10NwZ4sz5JQBkZrjJlt6WdUysiwKVAMzEzuWeXphFUeAAFJWzO1JKfqiW/FAtFcZOEN7X0EmFmQxAsHaXbc9fAJmFrGuw467T2qy16Tv4ajyiOrduAwDLZbvtR1F5/N1T9XK877OkhilOFPkz22rjZQDTTDXTCjNxu4Rnt9fxXw9sJNfxCGRKMC7AsXMsNC2sKLDXbb+U9bq2nmYr6M2VW3tf9KI5EAlCqzMGnzsFcqfaNpv2xavNlJ4IcTIL6PT0JDWZJTVM9toAuRaTTV17gPr2AIVZXrwJqUpPWXRM/HN9KJOjAbcukakoaaFiPY4IJFjWQcftve1gG9GoiY+5xqZHJVrXMSt88TQrIFkZngTLOibWNuI7t9NaprOkFjBML8ykLFxFuKCcneFJuIjiwjB59kIWOdm79jpiHWlwxLpoDm3dIb7wWB1B48YrzkNGtCdS22Xs5/g2xwqnqBxJqDclUk1ZniPWW2sRonGxnhKuxut2MbXAzyNvVnP3SxVktOyN7+t2BJiE6O1lnl0A7IlM6nVtM1qt8Abrd/Uqp9B5iGjaA95s8GTYvjbu7tWuvV4OmYUEEuZJL8io44QSK0bN5FDfHqS+LUhprq/3sTLttK9O/LSEhKOBWICZirWiDI6K9Tii77zhaQWZdAYj/PSZnXE3cEzYEsW6scN+Ls624pCV4SZbHLFuSnSDG7LaK+h2ZZIlAUppZna+l8mmjo7sGexzRBngyvPOiot1jdtaqZH6PXQe3IkpLOeOtbup64wQLZhld8joCZ7qFmcKF/6ekymc7bxbcQziIWTcFAYqmeJM+XplbyOTaMYvIdqNn9JwFRjDrKIel/FMqaXLad/Tsg9jDHUVWwm5rbt8dsBa8rvCpQCExUvIuPG17eOPL1Xgbd5LwJVg1cYeIhp3x8WUotn2usVc/sAsScgql1kYTxdqMrLJCTcx09WAcXkJuf3UO5Z1SU5ysW535aZMMjNR0AAzRUkPFetxRKIbHOD848vwuITv/3M7P3vWWoQxl3FsbjTYdKFul8RTY/oTx6w76iDQRnNniEk044p0U5G7HLCBUcdlNeEWQ7Vrai+xpmgOxzkpNycVF1FjCmjctxFfxwHWtxXwq3V7uHDJFPyTHNdu+Zn2cJLNHu9cADZ6T7DbcqfGp4/FxLFaJlNJKZntFUzO91GSk0HUwLum2YeSf0UX4Tfd0F7L8lmFzJ+cQ67fwyw5yC7/YkLGjb9tLy/uaqDr4A6eDy8AIKf+DaDHG9CeOZ1KU0qgZidff2AjZZFqOnLnQI5zrjH3fOOeBLGeA+01cPCt+OWYlegG9xfgyy0GwMw6w5ZVvYpkFlKS47dj1snE2m8X7+h056VMMjNR0AAzRUmPtMRaRM4XkW0islNEvpZk+ywReUpE3hSRZ0VkesK2q0Vkh/O6eiQ7f7SRGGAGcHJ5EW996zzK8vzsc5KLHO+4urcl5AFv7AxSmOWN52HOynCTTU/Wr4pdm2jqDMUFp6rkNADmeeuY7bh3N3UX00AeEW8O+PIgqzgu1rOLs9lrypjbvgG3GO7d6SUcjfLl847tsUyPeQcAtd6pVMoUAHbkrrTbYnUSPh/0TOWgeyrSuBufx82LX3sHb9xwLl9YYQOynosusfWb9nD9OfN5/HNnctzkXGZJLS05s6k0JWS17+f5bVVMk3o2RmbS5CpEql615+yIdc6UeeyXMgqDBwA4pbCVohkLevoUc4MHWiGzoHd/dz0dF9g86SLgdVzfmYVMnzIVANe8s23ZgVchs4CSHJ+1rNuSiLUnA7zZdLtzUyaZmSioZa0o6ZEyKYqIuIGfAucAlcArIvKQMSZxUeTbgN8bY34nIm8HbgE+KCJFwA3ACsAAG5x9m1CGTKCPZV2S48PvdTMpz8fGAzYaeW5pDvmZXjZVtcbrNXUEKczKiH/PynCTJQG6vQX4Q83k/elSLsLLZRnWGm8pO4XwThf/5foNvvU24cq/m/KAINGC2bjdLhDhuLI8vG5hwZQ8KrZPYqXLBmftM5O46m2zmFWc3SN2M1ZCRg5Nvuns7rLjxfWlb4Pm261bOYZjyTb7piHGQM3DcNt8MoAMwAQ7CBk3/4outPX/+F7w+HEBv+4OkSUBArmzqDg4mdPrnubjdS/hFsMBymjLnEFhR5PTRyvWnpK5VO92c1r0DV72fRJvazMUXg5uH1S9DrkJgWgxsY6dU/tBmLMadj8DQGfhQnx1r1gLPKvI1nEeUsBAZiElrgx21rXTEYwwKa+PWANkFRE0+XQEBl7zeyKhq24pSnqkk8HsZGCnMWY3gIjcC1wMJIr1QuALzudngFhmiPOAfxpjGp19/wmcD9xz6F0/+uhrWZc6lllJjo+YYZKZ4WbhlDw2V/XkvW7sCFKY3SPWmc486z3+hTzZNYm5Wd3xFbfef/bbIH8eN4avZmVmFauPLeWnr4V5scYuXMHZ3wInRWR+lpeHPn06M4qyeN/T5xPEiycrn+9cu4ZjyhyX8eLL7XSmSYvgov+lYn8mv17bRK1bKJw0D477CUw5oeekfLlw4Y9YVnISEgnBlmIwPectwM2vuNhlprJu2rWcUdbjLq6pbef+PW34p53H37f78RfMZlddO4tmTeaj53yK4o53wO5HMIXl/HLGeUTr/hdX+Rk88sbzhNqD5Pjc/MeJM2Hp+22f55wF+dNh1X9CWzUsucIeqGwxnPFFm8Vs6VWY3c8iGCRnEpz6f3Z6lzcTsoqtFX7uzdCwA469gJI3fDyzzS6isnxWTx7xOOd9F39XLt/OXpjeP8U4R6PBFSU90hHraUDiYsWVwMo+dd4ALgX+F7gEyBWR4gH2nTbs3h7lxALMirIzaOwIUpJrBbgkp7cQL5qaxx/+vY9wJIrH7aKpM8ickp4Ar9g866pIJt8Pv5ffXHoSn/ztKwC8f9UFFGyv467IObyWl8d5/3EaP1v/GDR3UZDlxXvs2b36FHOF7/HO5b+Cszljcgnvm1bcUyG7GE7/vP28+DIWTWqjdu1afh15F7cVZFlh7MuKDxOP1Z67rN/mR998EoIBNpR/jDPOnh8vb6to4lu3v8j38sp407OYT7UtpT4c4KF3nsa86QXATFh0LgIsB5i1BoBa/wG+0fwRlk8r5D8u6Ek7yuRF9n1Vn5Eflxve8c3416AnB1+4DW9OUe/zOfla+37qp+NFpbut9yHH52HpjIL+577w3cwH5vffMiHRaHBFSY+RCjD7EnCWiLwGnAUcANL244nIx0RkvYisr6vrv3SjYgnE51L7yM5wk5Vhn7USxz4zvW4WTcsjEI7G52I3doR6WdZZGR6ypZumsHVxTy3I5I/XruQnV1phjC0+ke3zkOFxxdvvN8aaQI7P9iUW4DYQx0zKiUesp6o7ELFAOZ/H3at8yfQCvnL+sZy9cDKZXjf17QF8Hld87emBiC13WTbM/rizrcs7K78kZd3YNXzbnOJec6yPVtSyVpT0SOducQCYkfB9ulMWxxhTZYy51BizDPgvp6w5nX2duncYY1YYY1aUlpYO8RSOHgLhKD6Pi/xMLyUJc3QT5+tmet0snGKDzDZVtWCMobkzSFF2z7rKbpeQRTf1QSt6+ZleTp1bwkUn2KCoAkes+wpwogXflxxHQMvyB0/mISKcMa/EqTs8cYytEe339v73dbuET646hqLsDDIzrAAfW5aLJ4UoZjl1p+QNrz8eR6wlNk49CLG/WyxBzdGOiOASFWtFSUU6Yv0KME9EykUkA7gCeCixgoiUiEisrf8E7nQ+PwGcKyKFIlIInOuUKcOgOxTB73Vz7qIyLloyNV6eaPH6PC7mlmbjErtsY1sgTDhqegWYEY2SLQGaw7asIKtHyKG3ZQ09olqaO7CY5aZpWQO876QZnH5MCTMKs1LWTXosf0ys3QPWyXS2HVc2uFUNPWI93IeH+JQufxK3dh9OnFnAilmFnLeoLGXdowW3SzTdqKKkIOWYtTEmLCKfxoqsG7jTGLNJRG4C1htjHgJWAbeIiAHWAp9y9m0UkW9jBR/gpliwmTJ0ukPWsv7I6eW9ymNi7fe6cLkEF8KkXD8HW7ppcuZbFyW4wQnZaV4dxkeGx9VP9GKWa3bM4hySZZ1a8FbMLuKuj/YNe0ifHjf4wM+asXNaMCX1UpOZGbEHjWGm+IyJdWaSgLE+TC/M4v7rTk1Z72jC7RJdz1pRUpDWetbGmEeBR/uUfTPh8/3A/QPseyc9lrZyCHSHI0mtyVIn0CwzYVtZvp+Drd3x5CiJY9YE7Vh2J/64yzsRt0soL8lmZnFWvC1Ib8y6bJiu5KGQNxTLOsV4ta1rRX/YlnXMok5DrJX+uEV06paipCAtsVbGBoFQtN84LfSIaC+xzvOzs66dJmdKVlGiGzxoc4V3GH/c5d2Xxz53RjwAKibApYOKtW1nuEFjQyEvnoltMMvabkvPDZ6+VyApQ7Cslf64XaJj1oqSAg1HHUcMZFnnZ3rxugV/Rh/LuqWbxo4QC2Uvi/58OrTXwp/XwJM3Ao5lnZVcrP1edzxSd3phbws7GYVZXnJ8ngHFfySJB5h5Bras8zK9TCvIJH+A8+tbN8PtYlLfhTXSJcuZqpZGgJnSHxVrRUmNWtbjiO5QJOk4rYhQkuPrZVlPyffTHghT0djJStcWPK37oeo12P4ERGwikQ4GtqwTOWl2Ib/80ApOP2bgCOaPnTWHdy2ZgsjhXy0qPmY9iGX9pXOPpTXN/NpXnzKLM+aVDH8q1QlXQO5kyJmUuq7SD7fLpQFmipICFesxijGGGx7axMryYi5YYnNpd4eicaHqS0mODRaLEbOCN1e1cqbLWb6x4t/x4DKATuNjcubAQWMxRIRzFk4etM6kXD+TBokWH0liY9Z951knMqMo/Ujz4hwfxYO4+FOSVQTHv2f4+x/luF0Q0YU8FGVQVKzHKE9tqeX3/9pHVXN3XKwD4SglAwjUx8+ag9Bj1cYim1/YWc/HfPUQBnY91WufzjQt67HGGfNKWHPqbOZPTh3prYx93KJTtxQlFSrWY5BI1HDr4zYtZUVjR7w8EIoM6Pq9MGHeNfQEenWFIszNqrViXf1Grzod+AYcsx7LFOf4uPHdi0a7G8oI4XbrmLWipEIDzMYgO2rb2FnbTmmuj4rGToxjdXSHIoMGVSUSW9HJTYTC0MGkdToHiQZXlCOFW1SsFSUVKtZjkNja1GfNL6U7FKWuLQBYN/hg05US8XnclORkMNvThCsagiwnOCyrJ0gs3QAzRTmcaAYzRUmNivUYpMIR61gO7X2N9nss3Wi6zCnN4Z3TuuyX2LrKU5ZAVgkGoZuMtKY2KcrhxO0SDTBTlBRMPLE+1Cd0Y6C9zs5J7hwgM6oxqY+TbHuafdvX2EGe38OSKZmU0MLBqgpor8Ubbhs4xWZin5z3X7z/BD690BHruY5YF5ZDUTlhdyYgalkro45O3VKU1Ewssb4xH+65sn/5I1+Ce5Ksm5yM538Itx0Dt82D75XDW3/tX+eXb4dnvjtwGw274DuT4eDGnrKDb9my+p0pu7CvoZNZxdnMeuBi1vuv46J/nAW3zeP1jI8yt+N1W2nj/XDb/Picaf7yUfs6uNEep2EXhX/7EP5nbgRvFsw+3dYrmQcl8wlm2JW5emU2U5RRwO3SVbcUJRUTS6wBtj/Wv6x+G9RuTm//Axsgbxpc8H3w+KHq1d7bwwGbXGT/SwO3UfUaRAJQuT6h3fW2rOq1lF2oaOxkTqEH18GNrHOdxH2Trydwtn04mNq1zVaq2QTtNT3W//6X7asy4TgHNsDsM+D990H+NPjQ3+DED8Hb/x9yxd18//ITmFU8vJWvFGWkcLtcKtaKkoKJJ9bJCHZAV1N6dRv3QNkSOOmjUDjbfk+kaR9g+pf3amN37/eBypIQjkQ50NTF4uxmwLAxfzV/jJ5D29KP0myyKeyutBVj59PVZB8gWvbbV52d8sWBV6GrEeadC+Vn2LI5qyAjG/KmkDVrOe9ZPv2IZBxTlMFw63rWipKSo0esu1sgGhm8njHQtAeK5tjvRXOSiLXzvbXSimQyYvs07Rm8LAlVzd2Eo4b53noAMifPY3N1K82dIfaayeQnE+vmCsDY1+7nbPmup3vOQVHGMJobXFFSc/SINcYK9mC019h0nEXOetGF5dYSTgx+iVnGJuqIZBLiVrQV5ob2AB0Hd/Te5mCM4Z+ba2jpsmPP+5wkKDOwc6PnH7eYYDjKuh11VJjJ5HXutzsminVim3Vber8X9V77WlHGGirWipKao0isSe0Kj4leTOCKyiHcBW0JSUUSLe2BXNqJYm0Mv31hz4Bu8Ec2VnPt79fz63W2vKrZRm+XBA+AL48TF8wjw+3izhf2sNdMJqurygaVDSTWfSmcPfg5K8ooo/OsFSU1E1Osw8He3+Ni3Tz4fjEhTnSDQx939m7Indq7fiKBduiotXVCHdBeS2fTQbIlQDR3CnTUQaANsON03//HdgBcznKUjR3Wws7qqICicjJ9Hk4qL2R/YxdSWI6YiLXou51z6W62/cjIhYwcWxbrX+4UO0atKGMYDTBTlNRMTLHuThDlSMhGRwN0p2FZixvyZ9jvMQs70XJt2gMzTrLCmMyijQn7MW+P75vRutcefuZZTpmt88LOevbU2weJQDhqd+8M4ve6cDftsW54YNV8u/TiOaef0rN/7MEjZlkXlff0N3bsQnWBK2MfDTBTlNRMTLFOdHcHOxLK+1jWkXBPWdtBOPgmFMwEt5MoJH8muDxQ+YqdIhUJ22jwojlWGGvesvOaE1971tl9jznbvu97numtdrpWy1RHrPeug4MbiVS/yXGyj+NkHzlNW+DgRnwNm1npP2CtZ8ey/+Aps3jo06exYOEJdv/67RBo7TnXpj2OWM/pfWwNLlPGAWpZK0pqJuaqWwOKdR/L+qWf2yQoX9gMPz7Ruq3nndez3e2Bormw4bewZy188AGIhqwIlhwLb90PPz+9//FdHig/y87Tfvo7XAV0Gy+1pW9jissDT3wdgNXA6tgyytvs64uJ7ZTMB8DvdbNkeoENdPNm9Z6r3VFnHyCOuwjcPvD+0x7bnQGTFgzpsinKaKBJURQlNRNHrBMDVBIt6MHEuuo16Ky3YhfqgBUfgTO/3LvOlffA2v+BN+6BGiexSmE5nP9OWPQfyfuSNxWyiuAj/4DmCr745zfY2lXAV8m1Za1VADyztZZ7X9lPrt/LMaXZfGLVXG59fCt+j4vPn7fYzotORMQeOzFRS80m+wBRWA7Hv8e+sorg4+ugcFbKy6Yoo40GmClKaiaOWCfOoe5lWbcnL4ee8eXY2PPs0yFvSu86xXOtW/mNe3rPXc4ptdbsYEw5gcjkJTzQ5SJqoD0QhvnLYdpyAHbU7eKJ6FaOzc2lJsPHJ45byeN/z2FxWQHMX5a8zaJy2Pp3+1nc0LCzp0++HCi11rha1cp4Qd3gipKaiTNmbQYS60Es677TqTILk7cdG/vd9ZR1NedOSV4vCa1dIWL3ofbucK9t3SEbVFaUnWGFHGjqDFE02EpYifOmEy1nnU+tjFM0wExRUjNxxHpAyzom1tLbPd7V1FMvZmEPKNYJUeFF5eBK/7I1dvZMI2sL9BXrCB6XXfmqMxAhHInS0hWiMHuQxTUSg8Zi0d5uX890LUUZZ6hlrSipmThinWhZJ07dCjlinTO5t4gnS24ykFhnFvZsG+J0qKaOHrHua1kHwlH8XjdZPjftgTDNThazosHEOvH48Uxrs4f0AKEoYwkNMFOU1EycO3wqyzp/Wh+xTrLIRmbBwO3HRHKI06EaE8U6EOq1rTsUwe91kePz0BEMx4W9cLBlK3tZ1rOH1SdFGUvoetaKkpqJI9Ym2vM5qVhP712emJWsucIGa/nyBm4/ntVsiJZ1Z6JY9x+z9nncZPs8dATCcWEf1LLOnw4uL/jyIaukd98UZRyilrWipGbiiHWqaPA8R6yNgbptUPES5JTZecvRsLWqB1suMjFf+BCIpQ8ty/PT1jfALBzB53WRneEmFDHUtNlMa4Na1i63DSzLLOhxzWtwmTKO8eiYtaKkZOJM3Uocs+6o7/kc7LCWaO5kOx+5qwnuWGVX15r7divcoc6Bx6tjlC2xyU5KjxtSt5o6g/g8Lkpzff0s60Aoit+xrAH2N3YCKSzrWF8663uiwcsWD6lPijKWcImuuqUoqZh4lnV2KbRU2pzgYMU6IxsKHGHbs9aK85lfhsvuBL8zTp1KrI+7CD6/0Y59D4HGjiBF2Rnk+j1JAswcy9oR68omK9YFg03dAnj3T+B9d8Gk4+ALW2Dm24bUJ0UZDBGZISLPiMhmEdkkIp9zyotE5J8issN5T/GjSQ91gytKaiaOWMcs6+J59nNsrelgh110I3GuNMCc1b2jvP2DBJeBdZHnDX16VHNnkMKsDHJ8niRj1hFrWWfExLqL7Aw3fq978EZ9OeDPt5+H0SdFSUEY+KIxZiHwNuBTIrIQ+BrwlDFmHvCU8/2Q0albipKaiSPWMcu65Bj7HgsgC7Zbyzo2rrszloXM+Z6ZpmU9TBo7ghRme8nxe/qNWdupWy6yfVacd9d1UJLrS9aMohwxjDHVxphXnc9twBZgGnAx8Dun2u+AAfLtDg23C40GV5QUTByxjkWDFztiHZtHHey0Yu3LtS7y1krwZNrgMugR6cMk1i1dIQoyM8gdyLL2uslx3OAHmruYWZR1WPqhKMNBRGYDy4CXgMnGmGpn00Fg8kgcI2ZZGxVsRRmQiSPWMcs6d6qN8I6LtTNmDb2nX8WSiBxmy7qlK0ReprWs2wPhXjckO3XLRVZGT5yfirUyVhCRHOAvwOeNMa2J24z9R06qriLyMRFZLyLr6+rqUh7H7czCUE+4ogzMxBHr2Ji1y20TmMQSnQTb7Zg19CQ2ScwCFresU4xZD6dLxljLOstLjs9LJGri+cChv2UNMKtYxVoZfUTEixXqu40xf3WKa0RkirN9ClCbbF9jzB3GmBXGmBWlpaUpj+VxW7HWcWtFGZgJNHXLEUGX21rO9Tvs94Es6xiH0Q3eFYoQihjyM73xiO+27hDv/9W/Obm8KJ5uNDZmDTCzKHvE+6EoQ0FEBPg1sMUY84OETQ8BVwO3Ou9/G4njuUTFWlFSMf7FOhKCyvU9giyOWO/4J7z+RzsfOS7WSRKbHEaxbu6008cKMr3xCO8HXjvAaxXNvFbRjM/j6jV1C9QNrowJTgM+CGwUkdedsq9jRfo+EfkIsA9470gczONyxFrHrBVlQMa/WG95CO6/Bq64x353uWHKUogE4MHrbFn+DPs+ZalNbDL1xJ79i+fZsqK5I961FmdhjvxML163HXH40ZPW4p9Tms3uug58Hjc+jwu3yyaGmKlucGWUMcY8DwyUzu8dI308V0ysIyrWijIQ41+sOxvte8CJfxE3LL4MZp5iM5YhUDDTbiudD/95ALz+nv3LjoevV4Fn5KdMxSzr/Ewvx0zK4fRjSghGojS0B6hvt3nA/V4XIkJ2hpsMj6vX+LWiHA04Q9ZqWSvKIIx/ZYjl/g7bvNrxKO+BMo0lCnWMwyDUkGBZZ3mZlOfnro+uBOC7j27hjrU2AM7vse7xHJ+HsvwkfVOUCY7b8TqFo9EUNRXl6GUCiLWzqlbEWd1KUmT/OoK0JrjBE0n8HhvLXjg1n3mTc45c5xRljBCfuqVarSgDkpZYi8j5wP8CbuBXxphb+2yfic1oVODU+Zox5lEnocIWYJtT9d/GmE+MTNcdYmIds6xl7MxGa+6yDxAFfVbRShRrn8f291dXrzhyHVOUMYQGmClKalKKtYi4uf9tAgAAIABJREFUgZ8C5wCVwCsi8pAxZnNCtW8A9xljfubkEH4UmO1s22WMWTqy3U4g5gaPxNzgY8eybukK4XbZ8ehEklnWinK0ogFmipKadMzQk4GdxpjdxpggcC82R3AiBshzPucDVSPXxRTELevRcYMHw1FuengzjR3BftuaO0MUZHqRPutk9xbrseMJUJTRQC1rRUlNOkoxDdif8L3SKUvkRuADIlKJtao/k7CtXEReE5HnROSMQ+lsUoJ2WcnRsqx31LZx5wt7eH5nfb9tLV2hfuPV0HsJTLWslaOduGWtg9aKMiAjZdZdCfzWGDMdeBfwBxFxAdXATGPMMuALwB9FJK/vzkPNJdyLeDT46FjWIcd11x2K9NvW0hUiP8na1MnGrBXlaCVuWatWK8qApKMUB4AZCd+nO2WJfAS4D8AY8y/AD5QYYwLGmAanfAOwC5jf9wBDzSXci3g0eJ+pW0eIkHOHGVCsk1nWmT0BZ2pZK0c7sXSjOnVLUQYmHWV7BZgnIuUikgFcgc0RnEgFTmYjETkOK9Z1IlLqBKghInOAecDukeo8kCQa/Ehb1kMX61y/h9gwto5ZK0c7bpdO3VKUVKSMBjfGhEXk08AT2GlZdxpjNonITcB6Y8xDwBeBX4rI9dhgszXGGCMiZwI3iUgIiAKfMMY0jugZ9J1nfYTHrGNu8K5g/ztNLMCsLy6XkOf30tIVwudRy1o5utEAM0VJTVrzrI0xj2IDxxLLvpnweTM2+X/f/f6CXWbv8NE3g9mRtqzDVqS7+ljWLV0hWrtDlOQkz46Wn+mItVrWylGOBpgpSmrGv1KMumWd3A3+r10NGAMr5xQn3S/mHtcxa+VoRwPMFCU141usw0FnsQ5GLYNZKJo8GnzdjjqyM9wsm1mQdL/Y9C2/usGVoxwNMFOU1IxvsQ519HweLct6ADf48zvrOWVuSXxpzL7kZXoRAa97oJUIFeXowOPWADNFScX4FutggliPcjR4V7BHrCsaOtnX0MmZ80sG3K8g04vf4+6X3UxRjjbUslaU1IzvVbcSxXqUMpjF3OCJlvUblc0ALJ9VOOB+l6+YwdxSXWVLUeJTtzQaXFEGZJyLdXvP59HKYOa4wQOhHqtgS3UrHpdwzKSBxXjpjAKWzkg+nq0oRxOxALOwLuShKAMycdzgo2VZR/qPWW892MYxk3J0DrWipEHMDa6WtaIMzAQSaycq/EhHgycR6y3VrSwoyz2i/VCU8UoswEynbinKwEwcsQ6PlmXde+pWc2eQ6pZujpvSb70SRVGSoAFmipKaiSPWkdFadat3UpQt1W0ALFCxVpS08GiAmaKkZOKJ9WiNWTtTt7bXWLE+Tt3gipIWbg0wU5SUTByxHrV51j1Tt4wxNHfasfPiAXKCK4rSG526pSipGf9Tt9wZYExP2tFRsqyjxgp3VyhChscVvwEpijI4ccs6qmKtKAMx/i3rjGxwJTxzjFI0OFjrujsUIVMX51CUtIlP3VKxVpQBGd9iHe4Gj79HrMUFRzh9ZyhhnK07FKErqGKtKEPBo5a1oqRkfIt1NGKFOub6PsLj1dDHsg5G6ApFyMxQsVaUdOlZz1rFWlEGYnyLtYlYoY5Z1kd4vBp6i3V32Iq1rlGtKOmjU7cUJTXjW6yjYWtNx93goyHWPTeYrmBszHp8X1ZFOZJogJmipGZ8q0pfN/goW9ZdsTFrdYMrStrEp26pWCvKgIxzsQ47bvDYmPWRP51QJIrPY48bCEXtmLW6wRUlbdyilrWipGKci3WfMetREWtDrt8LOJa1jlkrypBwuQQRtawVZTDGt1ibmBt8dAPM8vz2+F3BCN06dUtRhoxbRC1rRRmE8S3WYyTALDezt2WtY9aKMjRcLiGi0eCKMiDjO93oKAaY1f7/9u48vM66zv//83227E2Tpi1daYGWUqjpRkHZRbQoQ1FBwVFBRlBGZcCZcVBHURzmy3d0fl76HWUGFVEvhUFnYMpYQXZQQCgISjcobaF7mzbNnpzt8/vjvs/JSXJymj25k9fjunLlnPtsnxt6533e78/W2E5TR5JEKk1NeQzwF0VRn7VIv0VCpjK4SAHjIFiPTmZ924Ob2bC70S+De5l1azxFeyJNkYK1SL+oDC5SWLDL4D0WRRn+08l8+z/UHOdQS5xkylEcDRMOWXbHLWXWIv0TDiuzFikk2MF6hPus61viLPnaQ/zu9TqaO5K0xpPEU2likRAl0TCHW7xtOrUoikj/KLMWKSzgZfDkiI4G31bXTEs8xdYDTTS3J2mNp4iEjFjYqCyJsq+xHUADzET6KRwyLTcqUkCwU8Bsn/XIbOSxr8HLnJvakzR3JL3bHUki4RDVZTH2HPGCteZZi/RPOGQkUwrWIr0ZB8F65DLrvQ1tADS2J2hq9/qnnYNoOERVWSz7uPqsRfonZJq6JVJIsIN19wFmw7yC2b4GL3NubOvMrAFiYaOqNJrd1ENlcJH+iYRNW2SKFBDsYN19gNlwZ9Z+n/SBpnZy/65EwyGqSmPZ+8qsRfonbArWIoUEfICZXwZ3Ke/+sPdZe8E60zedkemzzlCftUj/aICZSGHjIFiHwY1MZp0N1n7fdEY0bJQX52TWKoOL9IsGmIkUFuxg7boF62HMrFNpx36/DN7UnuzyWCwSolplcJEBU2YtUpj6rPvoUHMHybQjHLIej3mjwaPZ+wrWIv0TDmlRFJFCgh+sczfyGMbR4Hv9Evi8KaU9HouErEuftcrgIv0TDmmAmUghAQ/WIzfPOhOsTzymosdj3cvgRZFg/2cVGWkaDS5SWLCjygjuurWtrhmAk2dW9ngsGg4x2Q/WJdEwZj1L5SLSu5Aya5GCgh2se+y6NXzBetPeJmZNLmF2VUn2WGWJ108dDYeIRUJUFEVUAhcZgIiCtUhBwQ7W2QFmw782+Oa9jZw0o4KKYu+LQSwSoqrUC9aRsJdJV5XFNLhMZADCIS03KlJIn4K1ma02sy1mttXMbsrz+Fwze9zM/mhmfzKz9+Y89kX/dVvM7D1D2fhsn3UmSA/TftbtiRTb6lo4acYkJhV7AbqiKEJpzA/cYe9zq8piFGt7TJF+C4e0n7VIIUedZ21mYeB7wAXALuAFM1vrnNuY87R/BO51zt1uZouBdcA8//blwMnATOARM1voXGbJsUFwrrMMnm3s8GS1Ww80k0o7Fh0ziQo/WJcXRygv8v7zRf1gPXtyCQebFKxF+kv7WYsU1pdFUVYBW51z2wDM7B5gDZAbrB0wyb9dCezxb68B7nHOdQDbzWyr/37PDrrlLu39DkUAf0DXMPVZb9rbCMBJMyqyfdLlRRHKirzbUb8Mfsuak7ObeYhI32nqlkhhfQnWs4CdOfd3Aad1e87XgN+a2eeAMuBdOa99rttrZ3X/ADO7FrgWYO7cuX1pt9dfDd7c6sxCJcOUWW/e10RxNMSxU8poS3hFAS9Yd82sp5QXDcvni4x3CtYihQ1VzfYK4C7n3GzgvcDPzPq+Qolz7g7n3Ern3MqpU6f27UWZYJ27KMowZdb7GtuZObmEcMgoi4UJGVQURyiLdQ3WIjIwGmAmUlhfosxuYE7O/dn+sVx/BdwL4Jx7FigGavr42oFJ+93euYuiDCKzvuOpN9hR15L3sfqWeHbREzOjojjaLbPWvGqRwVBmLVJYX4L1C8ACM5tvZjG8AWNruz3nLeB8ADM7CS9YH/Sfd7mZFZnZfGAB8PyQtDybWefOsx5YhtsWT/HP6zbzv3/ak/fxwy1xqnKWE/3g8tmct2ga5dk+a2XWIoOhFcxECjtqlHHOJYHPAg8Bm/BGfW8ws1vM7GL/aX8LXGNmrwB3A1c5zwa8jHsj8CDwmSEZCQ5dB5gNMrOOp9L+7/x/LOpb412WE/3qXyxmzdJZPfqsRWRgNHVLpLA+bZHpnFuHNx0r99hXc25vBM7o5bW3ArcOoo355Q4wy1ShB9hnncwE62S6x2POOepbEl0y64z5NWVUFEeYVBLsnUZFRpt23RIpLLhRJrfPOmOAu25lym/dg3UilaYjmSaeSmdXK8t1weLpvPSVC5RZiwyS9rMWKSy4USZfn/UAy+AJP1gnUp3Bur4lzopvPMzPn3sTIG9mbWYK1CJDQJm1SGHBzaxdbmY9uEVR8pXBf7e1jsb2JI9tPgDQpc9aRIaWRoOLFBbcYJ0pg1sYMltSDrAMnll1LDezfvr1gwD8eXcDkD+zFpGhodHgIoUFOFjnlMEzQXqgmXXaC9IdfrB2zvG71+sAaI17XwqqFaxFho0ya5HCgtvhOoSLoiRTXQeYvXGwhT0N7dn9qkFlcJHhpGAtUliAg3W+RVEGmll3LYNv2dcEwOqTjwG8PySZfaxFZOhpuVGRwoIbrN1QZtZdB5i1xL0vAqfM8jYSqyqNEgppSVGR4RIOGc6hhVFEehHcYJ07wCy7kcfgBphlgnVrhxesF83IBGuVwEWGU9gfJKrsWiS/4AfrIZhnnRlglimDt/iDyhZOr8BMI8FlYjGzO83sgJm9mnPsa2a228xe9n/eO5SfGfY3w1G/tUh+AQ7WQ99n3eFn1m3xFCGDScURZlaWUFOuYC0Tyl3A6jzHv+2cW+r/rMvz+IBlM2sFa5G8gjtqqst+1kM0GjzV2WddFotgZnzn8qVMzrPUqMh45Zx7yszmjeRnhkMqg4sUEtzMussAs0yf9eAGmGXK4G3xFCUx771WzqvmhGkVg2uryPjwWTP7k18mr+rtSWZ2rZmtN7P1Bw8e7NMbZ4N1LzvfiUx0wQ3W+QaYDXJt8M7R4Kns9pciAsDtwPHAUmAv8K+9PdE5d4dzbqVzbuXUqVP79ObKrEUKC36w7tJnPbDT6T51q7UjSUl0YIFfZDxyzu13zqWcc2ngB8CqoXz/bLBWn7VIXgEO1kO361bnoije79Z4irIiBWuRDDObkXP3/cCrvT13IDTATKSw4NZ68y2KMuA+627zrONJJmtutUxQZnY3cC5QY2a7gJuBc81sKeCAHcCnhvIzlVmLFBbcYJ3bZ100yftd0uuYl4Iy86zjqTTOOVriKWZOVmYtE5Nz7oo8h380nJ+pYC1SWPCDdSgM5VPhM89D9fwBvVUiZwRqIuVoi6cojQX3P41I0GiAmUhh46PPGqDmhH6XwR/euJ9P/Pj57AAz8LLrlnhSfdYiI0iZtUhh4yBYDzwDfumteh7fcjC7chlAIpmmtaNznrWIDL+IgrVIQcEN1rkDzAYok1G3+muBA7QmUsRTacpUBhcZMSGNBhcpKLjBOneA2QB1TtVKZo8daY0DUKrMWmTEqAwuUljwg/UAp2tBzi5bHZ2ZdUNrAkADzERGUCZYJxWsRfIKcLDuNsBsADqDdWdmXe8Haw0wExk5mWCd1mhwkbyCG6yHpM/a+8PQklsGb/PK4FpuVGTkqAwuUlhwg3Umsx5En3U8zwCzI9nMWmVwkZGi5UZFCgtwsPanWw0is85XBs8MMNPULZGREwkrWIsUEuBgPfg+62TOxh0Z2cxaA8xERoymbokUFuxgbSHwL/KB6CyD5/ZZZ0aDK7MWGSnqsxYpLLjB2qUGVQKHzsy6OU8ZXMFaZORo6pZIYcEN1unkoAaXQWefdXsiTXHU+0+hAWYiI09Tt0QKC3CwTg84s37rUCtt8RSJnG/xmUVQjrQlCBkURYL7n0YkaLQ2uEhhwY1I6SSE+t985xwX/b+nueuZHSRyNvDIlL2PtMYpK4pgg+gLF5H+0QAzkcKCG6wH2GcdT6VpbE9yuKUjWwaHzmCdSDmmTyoesmaKyNFF/C/eCtYi+QU3WA+wz7rNn6YVT6a7DGYpyZmqNaNSwVpkJGWKZArWIvkFOFgPLLPOzKmOp9LEc8vgOcuLHqPMWmRERcPen6JEOn2UZ4pMTBM2WHck0iRz/jAURUPZEanKrEVGViZYZ6ZTikhXAQ7WAxtg1p7wg3Uqnd3PGrw+s6i/5OExlSVD00YR6ZPMcqO540hEpFNwg/UAB5i15vRZ5/5hiIaNmP/tXpm1yMjKXHtxBWuRvIIbrAc4wCyztGhHt2AdCYeI+XOrj1GwFhlRKoOLFNanYG1mq81si5ltNbOb8jz+bTN72f95zcyO5DyWynls7ZC1fIB91p2jwVPdyuDKrEVGSzhkhExlcJHeHDXamVkY+B5wAbALeMHM1jrnNmae45y7Mef5nwOW5bxFm3Nu6dA12ZdODajPus3vs25PpLtME4mEjFgkRFEkRGVJdMiaKSJ9Ew2HVAYX6UVfot0qYKtzbptzLg7cA6wp8PwrgLuHonEFDbLPOnenLfDK4NFwiBmVxVq9TGQUxMIhEkmVwUXy6UuwngXszLm/yz/Wg5kdC8wHHss5XGxm683sOTO7pJfXXes/Z/3Bgwf71vJBLorS0pHqcjwaNoqjYfVXi4ySaCSkMrhIL4Z6a6nLgV8553Ij4bHOud1mdhzwmJn92Tn3Ru6LnHN3AHcArFy5sm9frdPJQWXWTe2JLscjoRA3XbiI4qi2xhQZDdGwKViL9KIv0W43MCfn/mz/WD6XA5/JPeCc2+3/3mZmT+D1Z7/R86X9NMBdtzJ91i3xnpn1GSfUDLpZIjIwkZD6rEV605cy+AvAAjObb2YxvIDcY1S3mS0CqoBnc45VmVmRf7sGOAPY2P21AzLARVHa/L7q7msQZ1YvE5HREYuEuszQEJFOR01NnXNJM/ss8BAQBu50zm0ws1uA9c65TOC+HLjHuS67x58E/IeZpfG+GNyWO4p8UAY5wKy7SDi4U85FxoNo2EgqsxbJq0/Rzjm3DljX7dhXu93/Wp7XPQMsGUT7ejfQRVES+YN1VJm1yKiKhjXATKQ3wU0nB7goSnu3zDqzj7Uya5HR5c2zVhlcJJ/gRqh0CkIDWW60a7AuK/ICfmYTDxEZHd48a2XWIvkEN1i7AQbrbmXwcj9Ya4CZyOiKRjR1S6Q3wQ3WA14UpevKZWVFKoOLjAWRkPqsRXoT3Ajl0gPKrNu6ZdZlMb8MrsxaZFSpz1qkd8EN1ukU2EDmWaeypW/oLIMrsxYZXbGIpm6J9Ca4Ecq5Ae5nneqyq1apBpiJjAmauiXSuwAH6/5n1s452hIpJpd2ButsZj2A1dBEZOh4wVplcJF8ghuhXLrfy412JNM4R7dg7WXnGg0uMrq0n7VI74IbrAfQZ52ZYz25JJY9VhpTGVxkLIhp1y2RXgU3WLt0n/usb/31Rq6/+4+0+tO2KvOVwTXATGRURbUoikivghuh+tFnvf7Nen63tY42P7OuygnW2RXMVAYXGVUR9VmL9Cq4wTrd93nWdc0dHG6Jc7CpA6DLaHAtiiIyNsTCRiKdpuvGfSICQQ7W/SiD1zXFAfj9G3UAzKkqzT522vwpXLpiNifPnDT0bRSRPouGQzjXc695EenjFpljkkuBHb103dKRzK5a9tCG/YRDximzKrOP15TH+NZltcPWTBHpm2jEyx0SKUek/0soiIxrwc6s+1AGz5S+AbYeaOa4mjIqiju/o2jKlsjYEPW7ojR9S6Sn4AbrPk7dqmvu6HJ/0YxJFPlf22PhENaH7FxEhl/Mnz6p6VsiPQU3WPexzzoTrEui3nNPmlFBzC+3RTS3WmTMyGTWCtYiPQU4WPctsz7Y7A0uq53j9VOfdMwkwiEjHLLsHwcRGX2ZGRmJpAaYiXQXzGiVmdrRhz7ruqYOzGD53CoATprhjfouioS0apnIGJK5HtVnLdJTMEeDp/09qfuUWXdQVRrjY28/lnlTyjimshiAWCSkzFpkDIn512MyrWAt0l0wo5XzL+ZegvWu+lb+v99uIZ121DV1UFMeY0ZlCR86dU72ObGwgrXIWBJVGVykV8HMrF3hzPof73+VJ7Yc5JwTp1HX3EFNeVGP5xRFQxpgJjKGZOZZqwwu0lMwU8tMGbyXPutif2rWniNt1DXHmVrRM1jHwqFs2U1ERl9UU7dEehXQzLpwGXzGZK9feld9G/sa25k+qbjHc2KRMIrVImNHTFO3RHoV0GCdKYPnz6wrir2NOp55o454Ms3C6RU9nlMUCfVltVIRGSGaZy3Su4AG68JTtzIX+3PbDgHeQijdTSqJancfkTEkM4YkrgFmIj0EM1gfZepW3N/APpFyRELGCdPKezzn1ktOGbbmiUj/aeqWSO+CGayP0medCdYAx08tz64FnmtOdWmPYyIyelQGF+ldMIdYHWXqVu7FvihPCVxExp7sFpkqg4v0ENBg7QfjXvqsczPrzPKiIjK2ablRkd4Fswx+lD7rjlSaKWUxZlWVcN6J00awYSIyUJq6JdK7YAbrbJ91L6PBk2mmVhSx9rNnjmCjRGQw1Gct0rtgl8F7G2CWSmf3rBaRYIhkVzBTn7VId8GMaEdZbjSRSmspUZGAiYaUWYv0JpgRLZtZ51+CLJ5Ma0ctkYAJhYxIyBSsRfIIZkQ7ynKj8aTK4CJBFA2HVAYXySOYEe1oU7dSTpm1SABFw9Zl6qWIeIIZ0Y663GiKImXWIgNiZnea2QEzezXnWLWZPWxmr/u/q4bjs2ORkMrgInkEM6IdZeqWRoOLDMpdwOpux24CHnXOLQAe9e8PuWg4pMxaJI8+RTQzW21mW8xsq5n1uEjN7Ntm9rL/85qZHcl57Er/2/jrZnblkLT6KFO3EkmXXQ1JRPrHOfcUcLjb4TXAT/zbPwEuGY7Pnjm5hD/vbhiOtxYJtKMGazMLA98DLgQWA1eY2eLc5zjnbnTOLXXOLQX+H/Df/murgZuB04BVwM1DUj7L9llrnrXICJnunNvr394HTO/tiWZ2rZmtN7P1Bw8e7NeHXLJ0Jpv3NbFxT+Mgmioy/vQloq0Ctjrntjnn4sA9eN+ye3MFcLd/+z3Aw865w865euBhepbX+q8PW2TGwvlL5CIyOM7bCL7XIdvOuTuccyudcyunTp3ar/e+6G0ziYaN+/64a7DNFBlX+hKsZwE7c+7v8o/1YGbHAvOBx/r72n7pQ591NKIyuMgQ2m9mMwD83weG40OqymKcvWAqj2walrcXCayhrhVfDvzKucxE6L7pd9mswBaZzjniyTRFmrolMpTWApkxJ1cC/zNcHzS/poz9je3D9fYigdSXiLYbmJNzf7Z/LJ/L6SyB9/m1/S6bFZhnnVlQQX3WIgNjZncDzwInmtkuM/sr4DbgAjN7HXiXf39YVJfHaI2naIv36zu/yLjWl123XgAWmNl8vEB7OfCR7k8ys0VAFd5FnvEQ8M85g8reDXxxUC2Ggn3WmTmaWhRFZGCcc1f08tD5I/H5NWVFABxq6WB2rHQkPlJkzDtqRHPOJYHP4gXeTcC9zrkNZnaLmV2c89TLgXv8wSeZ1x4GvoEX8F8AbvGPDU6BPuvMHE1l1iLBNKU8BsCh5vgot0Rk7OjTftbOuXXAum7Hvtrt/td6ee2dwJ0DbF8vDep96lY8pWAtEmRTyjszaxHxBDOiFSiDZzJrlcFFgmlKmZdZ1ymzFskKZkQrVAb3M2utDS4STJky+OEWBWuRjGBGtAJTtzTATCTYSmMRSqJhDjWrDC6SEcyIVmDqVnaAmYK1SGBNKY9pgJlIjmBGtD70WWuAmUhwTSmLUacyuEhWMCNaZnZYgT5rlcFFgmtKeRGHNRpcJCuYES3bZ91z/W9l1iLBN6VMZXCRXMGMaH3os9ZocJHgmlJexKHmODlrLIlMaMGMaAWXG/UubpXBRYJrSlmMeCpNU0dytJsiMiYEM6Jly+D5+qy9x1QGFwmuypIoAI1tiVFuicjYEMyI1pepWwrWIoFVHPOu7fZEepRbIjI2BDOiFZq6lS2D9xx8JiLBUOx/2W5PaJtMEQhqsC40dSszwCzc8zERCYaSbGatYC0CgQ3WmrolMp6VRL1g3aZgLQIENlj33mfduTa4yuAiQVWcCdZxBWsRCGqwPspyoyGDiKZuiQRWJli3JzXATASCGqyPskWm5liLBFu2z1qZtQgQ2GBdOLNWf7VIsGVHgycVrEUgsMG6wDzrVFpLjYoEXCazVp+1iCeYUS2dKYPnWW40qTK4SNAVRzQaXCRXMKNaoTJ4SmVwkaALhYxYJKQVzER8wYxqLg1Y3nnWLR1JymKRkW+TiAypkmhYi6KI+IIZrNOpvP3VAI1tSSqKFaxFgq44GlKftYgvmMHapfNO2wJobE8wyd+xR0SCqyQa1mhwEV9Ag3Uqb381QFO7MmuRwEm09ThUHA0rsxbxBTRYu97L4O0JJhUrsxYJjB2/g9uOheaDXQ4XR8NawUzEF8xgnc6fWafTjuaOJJOUWYsER8MuSHVAy4Euh0uiYa1gJuILZrB26bzBujmexDnUZy0SJJm1/pMdXQ4XR0OaZy3iC2iwzp9ZN7YlANRnLRIk6aT3OxXvcrgkpqlbIhkBDdbpbJ/1a/ub+OgP/0BbPEVTu3fRq89aJEBcb5l1WJm1iC+YwTqnz/rxzQf43dY6dh9py8msFaxFAiNTBu+WWRdHw1rBTMQXzGDtUtl51m8ebgW83baymXWJyuAigdFLn7VWMBPpFNBg7bKZ9VuHvGDdkUzR2K7MWiRwMmXwVM9grTK4iCeYwTqdgpDX9DcPtwDQkZtZa4CZSHBky+CJLoeLoyFSaUcipVK4SDCDtb/caCKVZs+RdsAL1uqzFgmgzGjwPAPMQNtkikBgg7U3wGzPkTZSaQf4fdYdSYqjIW2RKRIkrvcBZoAWRhEBglkv9qduven3V4PfZ92WUFYtEjTdB5htfxrqd1ASPQ9AI8JFCGpm7U/dyowEB+hIeH3W6q8WCZh0twFmL/0EnvwXSmIqg4tkBDNY+33Wbx1qyR7qSKZpbFdmLRI42UVR/DJ4Kg4uRXHU+/Ok6VsigQ7WIRraEtn+6XgyRWN7UuuCiwRNdrlRP7NOxiGd1AAzkRzBDdahEGkHpX6prCOZpqktoXXBRYImnSezTicpUbAWyepTsDaz1WbUDZvNAAAgAElEQVS2xcy2mtlNvTznQ2a20cw2mNkvco6nzOxl/2ftkLTa77NOp132gu7wR4NXFClYiwSK8weQpboGa40GF+l01MhmZmHge8AFwC7gBTNb65zbmPOcBcAXgTOcc/VmNi3nLdqcc0uHtNV+n3XKOWKREOGQ0ZFM0RZPZQeliEhAdC+DpxKQTlEW8/48tSpYi/Qps14FbHXObXPOxYF7gDXdnnMN8D3nXD2Ac+4Aw8mfZ51KO8JmFEVCdCTStCVS2bK4iAREL2Xwcr9Lq7kjOUoNExk7+hKsZwE7c+7v8o/lWggsNLPfm9lzZrY657FiM1vvH79kkO31pFMQCpN2jlDIiEVCNHckSaUdpTGVwUUCpfva4KkEpJOUFXlfvBWsRYZuUZQIsAA4F5gNPGVmS5xzR4BjnXO7zew44DEz+7Nz7o3cF5vZtcC1AHPnzj36pznnlcFzMuv6Vu9beaafS0QCIrvcaCaz7oB0kqKwtxphZs1/kYmsL5n1bmBOzv3Z/rFcu4C1zrmEc2478Bpe8MY5t9v/vQ14AljW/QOcc3c451Y651ZOnTr16C1yKTAjlYZQyCiKhDnS6q0LrjK4SMCkMwPMMpm1H7RdmoqiCM0difyvE5lA+hKsXwAWmNl8M4sBlwPdR3Xfj5dVY2Y1eGXxbWZWZWZFOcfPADYyWP5yo2nnCIegKOLNuQYFa5HA6b6RR2b3Lb/fulmZtcjRy+DOuaSZfRZ4CAgDdzrnNpjZLcB659xa/7F3m9lGIAX8vXPukJm9A/gPM0vjfTG4LXcU+YCluw4wi0VC1DV7F3qJyuAiwdJ9I4/M73SK8qKI+qxF6GOftXNuHbCu27Gv5tx2wOf9n9znPAMsGXwzuzfIm7qVdg4zoyhi1PtlcE3dEgmY7ht5ZIN1kvKiiPqsRQjsCmb+oijOEfb7rONJr99LZXCRgMnOs050/Z1OUlGszFoEAhusvT7r7GjwaOdplEQ1dUskUFwvA8xUBhfJCmawTqf95UYhFIJYuPM0lFmLBEzuoijpdGemrQFmIlnBDNb+rlupTBk8Z1CZ+qxFAiZ3udFMVu0fLy+Kqs9ahMAG687R4CF/UZQMBWuRgHE5A8y6BeuK4gjxVJqOpNYHl4ktmME6Z7lRb4BZbp+1grVIoKRzpm6lEl2Ol/u76KkULhNdMIN1pgyeXW7UC9DRsBENB/OURCasdO+ZdTZYa5CZTHDBjGwulV0bPLORByirFgmkTBncpSDZ1nk8Z+ct9VvLRBfQYO06y+A5fdbacUskgNI5gTje0uV4hTJrESCowTqd2cgjMxo8E6yVWYsETjpn8FhHc5fj2T2tlVnLBBfMYO0vN+ocmJHts9b2mCIB5HKDdVPnbfVZi2QFNFinusyzjkWUWYsEVm5mHc8J1q4zs25SsJYJLqDButtyo5kBZgrWIsHTaxk8SUVRFFAZXCSYwdrfIjPtjwYvUmYtElx+pQyAeNdgXRwNEQ4ZzR2J/K8VmSCCGayd86Zuua7zrDV1SySA0kmIlnm3uw0wMzMqirVNpkhAg3VmuVG6ZNYlmrolEjzpNERLvNvxrgPMAKpKYxxuied5ocjEEcxgnU5BKLOfNSqDiwRZOtkZrDt6BuvqMgVrkWAG6+7LjWqetUhwuRTE/DJ4t0VRQMFaBCCYdWN/udHOAWaaZy0yEsxsB9AEpICkc27loN80ncrJrLv2WQNUl8Z4ZeeRQX+MSJAFNFj7U7f8AWaaZy0yos5zztUN2bulkxAt9W53Gw0OUF0eo741jnMOMxuyjxUJkuCVwZ3LlsEzW2RmRoGXFQXzu4fIhObSncE6T5/1lLIYiZSjUSPCZQILZrAGvwwOZsbsqhL+5YNv48JTjhndtomMfw74rZm9aGbXDsk7dimD5x9gBqjfWia04KWimXWEs8uNegH7Q6fOGd12iUwMZzrndpvZNOBhM9vsnHsq9wl+EL8WYO7cuUd/x3QSSqu92y11XY+TG6w7mF9TNvgzEAmgAGbWae93qHM0uIiMDOfcbv/3AeA+YFWe59zhnFvpnFs5derUPrxpCoonQygCHQ2dxzMDzPxgfahZmbVMXMEL1v4FnPabHgopWIuMBDMrM7OKzG3g3cCrg37jdMoL1CVV3Y53zazrWxWsZeIKYBncy6ydv5awMmuRETMduM8fkR0BfuGce3BQ75hOAw5CYSiphpaD3jrhLp39Yj6lrAiAQ+qzlgksgME6k1l7QVqZtcjIcM5tA2qH9k0zY1DCnf3W0TJv2VE/sy6JhSmJhjmsMrhMYMErg2cya7zpWmEFa5Hg8gOyl1n7ZfDMyPCcrTO1iplMdMEL1mkvWGcya5XBRQIsE5AzZXCASLH/WOe86uqymMrgMqEFL1hHYnDqJ0nWLAZUBhcJtC5lcD+zjsS8AWfdgrUya5nIghesiyrgff9KYs47AAgrVosEVzazzhkNHu4ZrGdOLmH3kbZRaKDI2BC8YO1L+SuZqc9aJMDylcHzBOu51aUcbonT1J4YhUaKjL7ABut02gvWWthfJMBcTrAuzQnWFu4ywGxutbd2+M7Dyq5lYgpssFZmLTIOZLJn655Zh7tk1sdO8YL1W4dbur+DyIQQ3GDtZ9YaDS4SYF3K4Jk+62iPMvic6kywbh3pFoqMCYEN1unsEuEK1iKBlZ1nHelaBu8WrCtLolSWRBWsZcIKbLDuLIOPckNEZOAyG/NYvsw61eWpx04p5c1DCtYyMQU21GXK4CGVwUWCK1sGD3krl0VK8vZZg1cK317Xwu9er8sOMBWZKAIbrNMaYCYSfLllcIBJM6C40rvvumbWc6tL2VXfxkd/9AeefP3gCDdUZHQFNlhrgJnIOJC7ghnAR+6F877Uo88a4L2nzOD8RdMA2Km+a5lgAhusM5m1BpiJBFjuCmYANQugfFrePuslsyv5wcdXEg0b+xraR7ihIqOrT8HazFab2RYz22pmN/XynA+Z2UYz22Bmv8g5fqWZve7/XDlUDc+MBldmLRJguVO3cuXpswbvy/m0imIFa5lwjrqftZmFge8BFwC7gBfMbK1zbmPOcxYAXwTOcM7Vm9k0/3g1cDOwEnDAi/5r6wfbcC2KIjIOZMvg3fKGTBk83gL/fa13bO7pMPUkjqksZV+jgrVMLEcN1sAqYKu/8Txmdg+wBtiY85xrgO9lgrBz7oB//D3Aw865w/5rHwZWA3cPtuGp7HKjg30nERk13cvgGaEIpOJw78fhjcegfDps/l/AOPaE/+XlfdqBSyaWvpTBZwE7c+7v8o/lWggsNLPfm9lzZra6H68dEI0GFxkHsqPBu5fBI3BgE2x9BN75Ffj8Jlh9G+CYU5pmb0M7zmn6lkwcfcms+/o+C4BzgdnAU2a2pK8vNrNrgWsB5s6d26fXaDS4yDjQfTR4RigMrYe82zPe5pXQiicDMLPM0ZZI0diepLIkOoKNFRk9fcmsdwNzcu7P9o/l2gWsdc4lnHPbgdfwgndfXotz7g7n3Ern3MqpU6f2qeGZRRE0GlwkwAqVwTOrmxVN8n5HSwCYXupd+xpkJhNJX4L1C8ACM5tvZjHgcmBtt+fcj5dVY2Y1eGXxbcBDwLvNrMrMqoB3+8cGTQPMRMaB3BXMcuUG71i59zsTrIu9IK5BZjKRHLUM7pxLmtln8YJsGLjTObfBzG4B1jvn1tIZlDcCKeDvnXOHAMzsG3gBH+CWzGCzwdJyoyLjgOsts84pixdVeL/9YD2lyA/WDdrbWiaOPvVZO+fWAeu6Hftqzm0HfN7/6f7aO4E7B9fMnjTATGQcyN3POlfeYO1tk1kV8wL8XpXBZQIJ7gpmWhRFJPh6XRQlTxk8UgxANN1OdVmMg00dI9BAkbEhsME6lV1udJQbIiIDlxlElm+AGXjZdDhz2yuDk2hnanmRgrVMKIENdZnR4CqDiwRYtgzeywCzTAkcsmVwEq3UVMSoa1awlokjsME6OxpcZXCR4Cq0Njh0lsABol4ZnESbl1krWMsEEtxgnV1uVMFaJLC672edUSizTrZRU15EXVMc5xx1zR188ifrOdyiJUhl/ApssNZocJFxoNcVzPIE63AMMC+zriiiLZGiJZ7iD9sO88im/byy88iINFlkNAQ2WKc0Glwk+I42Gjw3WJt52bUfrAHqmjrYWd8KoMxaxrWhWht8xBxq7uDttz3GScd4F7FGg4sEWKHlRqFrsAZvRHjCK4MDHGzuYOdhL1jXtypYy/gVuFAXi4SIJ9O0xL2LXGVwkQDrdT/rPAPMIBusczPrXfXeSmbKrGU8C1ywLop4F3FbJlirDC4SXAPKrFu7Ztb1yqxl/AtcsI6GDTNoS3gXuXbdEgmwQvtZQ/5gnfRWMAsZHGhUZi0TQ+CCtZkRC4dojXsXuTJrkQDrz2hwgIiXWYdDRnVZEZv2NhJPeqNN61sSw9xYkdETuGANUBQJ0Z7wLlBl1iIBlu5tuVE/eOctg3sbeEytKOKP/nStsliYwyqDyzgWzGAd7fwWrgFmIgGWLYP3YblRyA4wA1g4tZiGFu/2KbMqqVcZXMaxYAbrSGezVQYXCTCX6lkCh85jeUeDewPK/oXv8pOyfyNksGRWJfWt8eyeASLjTeCDtWK1SIClkz1L4JCTWU/qetwfYEYqSdGOx3h7yZvc9YlVzKoqIe2gsV391jI+BTRYqwwuMi6kUz1HgkPvfdb+ADMObIB4M+HmfZw9r5TqshigEeEyfgUyWMdUBhcZH1w6f2ZdWu0dL53S9Ximz/qt5zqP1e+gqtQL1pprLeNVIIN1bhlco8FFAiyd7Ll6GcBJa+Cv/wBl3YN1qVcGf/P3na87vD2bWW+va6VJpXAZh4IZrP3R4CqBiwRcb2XwcARqTuh5PLOn9bYn4Ph3ercPb6PKD9Z/98tX+Nt7XxmetoqMosBt5AGdmbVK4CIBN3tl/mDdm8ye1u0NcMK7YPdLUL+dar8MDrBlf9MQN1Jk9AUzs/aDtXbcEgm4pR+B936z78+PFHfenrEUqufD4W2UxMJ85/KlrFk6k131bSQye+iKjBOBDHeZ0eDKrEUmmExmDXDMKVB9HBzeBsCapbN4zzEtzHD72XOkbZQaKDI8ghmso5nMWsFaZEKJlnTeLqqAKQugYRfU7wDgnFf+jn+O/IgHXtnDslt+y6u7G0annSJDLJDBOhb2+6wVrEUmlswAs8q53u/lH/NK4w/fDO2NlNZv5vjQHn78+x3Utyb46v+8qlXNZFwIZLDOZtYqg4tMLHFvqVFqFni/J82EM/4GNt4PL/4YwzGDwzS1tFAaC/PSW0e48/fbR6+9IkMkmMHa77NWsBaZYGYt936f8w+dx06/zsuun/i/AITMMccO8Ikz5vGek6fzT7/exLce2qJ+bAm0gAbrTBl8lBsiIiOrcjZ8rQHmntZ5rLgSFr0PEi3ZDUDm2AHOOL6G71y+jHcvns6/Pb6VD9/xLM6pJC7BFMhwp3nWItJF7RXe7+POBWBB5CDLj62iOBrmjo+v5KsXLWbn4Tb2NLSPWhNFBiOYwdpfwUyjwUUEgOPOg0UXwds/g4uW8ZmlYYpz9r1fOncyAH/epdHhEkzBXsFsHAbrRCLBrl27aG9XBiCe4uJiZs+eTTQaHe2mjF3hCFz+cwCsej6Tj2yEl37mLboSCrN4xiTCIWPDngYWTi/n2Cll4/Lvh4xfwQ7W47AMvmvXLioqKpg3bx42Ds9P+sc5x6FDh9i1axfz588f7eYEQ9U82Py/8Naz3u5di95HcTTMgmnl3PfH3fzb41u5+aLFXHWG/ntKcASzDB4Zv4uitLe3M2XKFAVqAcDMmDJliiot/TFtMYSLvL2vX3soe/jkmZXsqm/DOfjli7tGsYEi/RfQYD2+lxtVoJZc+vfQT2f9LfzNy7DgAnj9YfBHgC+ZNcn/XcmGPY28pg0/JEACGqzHb2Y92g4dOsTSpUtZunQpxxxzDLNmzcrej8fjBV+7fv16rr/++qN+xjve8Y6hai4AN9xwA7NmzSKd1uYNgrfK2aSZsPA90LQH9v0ZgPcvm81XLlrMD69cSThk/PdLu0e5oSJ9F8w+66jmWQ+XKVOm8PLLLwPwta99jfLycv7u7/4u+3gymSQSyf/PZuXKlaxcufKon/HMM88MTWOBdDrNfffdx5w5c3jyySc577zzhuy9cxU6bxmjFrwbMNj0AMx4G5WlUf7qTK+f+owTalj35738w+oTcU5f/GXsC2S40wpmI+uqq67i05/+NKeddhpf+MIXeP7553n729/OsmXLeMc73sGWLVsAeOKJJ7jooosAL9BfffXVnHvuuRx33HF897vfzb5feXl59vnnnnsul156KYsWLeIv//Ivs4tWrFu3jkWLFrFixQquv/767Pt298QTT3DyySdz3XXXcffdd2eP79+/n/e///3U1tZSW1ub/YLw05/+lLe97W3U1tbysY99LHt+v/rVr/K276yzzuLiiy9m8eLFAFxyySWsWLGCk08+mTvuuCP7mgcffJDly5dTW1vL+eefTzqdZsGCBRw8eBDwvlSccMIJ2fsyAsqnwfHvhJd/AemUd8z/93XhKcfw1uFWvv7ARmq//lv2af61jHGBTBWyZfBxHqy//sAGNu5pHNL3XDxzEjf/xcn9ft2uXbt45plnCIfDNDY28vTTTxOJRHjkkUf40pe+xH/913/1eM3mzZt5/PHHaWpq4sQTT+S6667rMf3oj3/8Ixs2bGDmzJmcccYZ/P73v2flypV86lOf4qmnnmL+/PlcccUVvbbr7rvv5oorrmDNmjV86UtfIpFIEI1Guf766znnnHO47777SKVSNDc3s2HDBv7pn/6JZ555hpqaGg4fPnzU837ppZd49dVXsyOx77zzTqqrq2lra+PUU0/lgx/8IOl0mmuuuSbb3sOHDxMKhfjoRz/Kz3/+c2644QYeeeQRamtrmTp1aj//y8ugLPso/OoTsO0JaKv3Nvz4y1+yek4pt1o7dz2zA4C7n3+LGy9YOKpNFSkkkJl1bBzPsx6rLrvsMsJhr6LR0NDAZZddximnnMKNN97Ihg0b8r7mfe97H0VFRdTU1DBt2jT279/f4zmrVq1i9uzZhEIhli5dyo4dO9i8eTPHHXdcNkD2Fqzj8Tjr1q3jkksuYdKkSZx22mk89JA3+vexxx7juuuuAyAcDlNZWcljjz3GZZddRk1NDQDV1dVHPe9Vq1Z1mTL13e9+l9raWk4//XR27tzJ66+/znPPPcfZZ5+dfV7mfa+++mp++tOfAl6Q/8QnPnHUz5Mhtuh9UFIFv/kCPPA30LgL7v0YVT86jR9V3kk0bJwyaxJ3P/8WL+88QktHEoCGtgQPvrqXZErjIGRsCGhmPb5Hg2cMJAMeLmVlZdnbX/nKVzjvvPO477772LFjB+eee27e1xQVFWVvh8NhksnkgJ7Tm4ceeogjR46wZMkSAFpbWykpKem1ZN6bSCSSHZyWTqe7DKTLPe8nnniCRx55hGeffZbS0lLOPffcglOq5syZw/Tp03nsscd4/vnn+fnPf96vdskQiBTBpT+GtZ+DcBTe9XV45GYIF7Gq41l+cfm3aIpWc/Vd67nke7/n3Yunc/mqOXzuF3+kJZ7iG5ecwsdOP3a0z0IkmJl152jwUW7IBNXQ0MCsWbMAuOuuu4b8/U888US2bdvGjh07APjP//zPvM+7++67+eEPf8iOHTvYsWMH27dv5+GHH6a1tZXzzz+f22+/HYBUKkVDQwPvfOc7+eUvf8mhQ4cAsmXwefPm8eKLLwKwdu1aEolE3s9raGigqqqK0tJSNm/ezHPPPQfA6aefzlNPPcX27du7vC/AJz/5ST760Y92qUzICDv+PPjsevjcS952mlc+AFc/iLkUpx75DectnMr3PrKcj5w2l99u3M/1d7/MnOpSTphWzi/+8JY2/5AxoU/hzsxWm9kWM9tqZjflefwqMztoZi/7P5/MeSyVc3ztUDS6czT4+M6sx6ovfOELfPGLX2TZsmX9yoT7qqSkhO9///usXr2aFStWUFFRQWVlZZfntLa28uCDD/K+970ve6ysrIwzzzyTBx54gO985zs8/vjjLFmyhBUrVrBx40ZOPvlkvvzlL3POOedQW1vL5z//eQCuueYannzySWpra3n22We7ZNO5Vq9eTTKZ5KSTTuKmm27i9NNPB2Dq1KnccccdfOADH6C2tpYPf/jD2ddcfPHFNDc3qwQ+2qLF3mpmZjD/bG+rzTmnw6Nfx755PO879GO+XvbfXFy+mXgyzXevWMaV75jHpr2NPLRhPx3J1GifgUxwdrRvjWYWBl4DLgB2AS8AVzjnNuY85ypgpXPus3le3+ycK+9rg1auXOnWr19f8DnJVJoTvvwbzlpQw8/+6rSCzw2aTZs2cdJJJ412M0Zdc3Mz5eXlOOf4zGc+w4IFC7jxxhtHu1n9tn79em688UaefvrpQb1Pvn8XZvaic+7oc+VGUV+u51FTt9VblvTNZ+D1zpXO9i/8S6b/xVdpjE7h7H95nCOtCSaXRrngxCksTGxi8aoLqJlUyv7GdqrLYsypKuWL9/2Jq94xn1Xzq9l6oJl/f/INvvzek6gqi43iCUqQHO167kuf9Spgq3Num/+G9wBrgI0FXzWMIuEQkZApsx7HfvCDH/CTn/yEeDzOsmXL+NSnPjXaTeq32267jdtvv1191WNVzQlw5g3eT+MeiJXD4//M9OfvgG/fy6R5Z/L87BRvFS/guSNVnLrpvziR7TyxpZYfp08lQood7hj2Tzmd1w+2sGlvEw/dcDZff2ADT79eR1N7gn//6AqtQCdDoi+Z9aXAaufcJ/37HwNOy82i/cz6/wAH8bLwG51zO/3HksDLQBK4zTl3f6HP6+s38ZO/+iCnHzeFH1116lGfGyTKrCUfZdYj6PA2eOFH8Mbj3qC0fX8Gl4JJs0gu/gChP/w7Idc5ruHh1HJ2zHk/L+2oY8GMyfx2TwmTZ57Ac7vj1M6upKosRjQc4rwTp/HORdOYPqmITXubiIaNBdMrRvFEZSwZisy6Lx4A7nbOdZjZp4CfAO/0HzvWObfbzI4DHjOzPzvn3ujWyGuBawHmzp3bpw+MRUJadUhEhl71cfCeWzvvN+2HjiaoPo5IKARn3QDJdghFSb/yn7zzyf9LeM9XIAYcgs8Xeb/byytpPhzhSP1k6l05ka0tNP66jbR1UOSi1Fslbx0zmz3xEmYWx2mxMtrLZlNeNY1XdhzgHctOYYsdz4HQVFYcW01dS5xJxVFqymPUlBdl//455/jli7uYU1XK24+fgnOOtw63MruqlHDISKTStHakqCztXONgX0M7zR1JTpjWs4fSOcfjWw5wysxKpk0qzh5Pp12w/+amU2Ahb9xCfzjX/9cMg74E693AnJz7s/1jWc65Qzl3fwj8S85ju/3f28zsCWAZ8Ea3198B3AHeN/G+NLwoEh73U7dEZAyomO79ZJTVZG+GzrweTv807PkjxEpJJxNQv4NQw5sUH9lJcbKDmub9uPYGWpnMgY4IB1JFVEYTRA7uoWPvJo63ZppcCTXWylTzFkFaAPAQzPQ/J+2MGkppcGUcophUqIXScJpDxXOJJ5JMbwtTRylPVk3lUDuE2g7xelGElqLpvNEUpjTdzJSKUhIuRH27ozlhGI5jJxlFJWXsaw9zuC1NSTTEnIowjfu381Y4jBVP4nAiRixWRKqljgVl7RxMlXM4VMWqGRG2tRSxs66JyZMrOWbWPHY2JJgS30359ON4dfseQgbvOvVttBzeQ8P+N2mu20lTaDL11bXsb4ozu6qE/Q2tTCmLsWzOJA40ttPWEScaMpoa65np9nNKeTPPHIzRGndUTiqnfPJU6uIxzKUJuwTVib2EXJpE8RRmFrezqbWSSLSImeVGZeIA0brNFBcXc9z+h0gWV7F98V+zvaOCqY0bmVJZQVn1DNojFXBgEzPeuJcD0VlEOw5T1baTiOsgBOysOZOSmnkkEgl2NDoml0Yprt9CqmI2DcUzKWrYwdzUDnYtvJKGUCWRhjeZlKijwtp5tamMhWd+kPknLRvUP8O+BOsXgAVmNh8vSF8OfCT3CWY2wzm31797MbDJP14FtPoZdw1wBjmBfDCKoiFN3RIZYWa2GvgOEAZ+6Jy7bZSbNPoiMZjrDXQNAcxe3uMpBpQBuTto72to58nXDvAXtTPZta+JaHkRfzhwiN379rBs3nR+vO4p3l25kxPK2qlv6aDSWom21VPe0cKujij1rSmmtu4hRZiTqtJY+24ijRspsiSJsipa4ylqWp4hGkqSDMdwbWmi+LM3Mkl2m/+TEQcOQUesFFyaog5/HYF2cGGjqaOCctdMiDTsgOyWPPX+T8Z+b2ATAI92Hk4RIkwa9vgHMhufNdB5rJuOAxEWmd/uOv+ngNO73a9zkyijnSfSS5jfsZfFf/gHFvfy2ufTJ1LNdvZRzm/SZ9BOjBI6eO/+5yne/xwRwqyggxBp3nAzmVX/MgusjSZXwkFXycmHPp99r7Qz2onxHuvghddmDX+wds4lzeyzwEN4F+idzrkNZnYLsN45txa43swuxuuXPgxc5b/8JOA/zCyN9+/4ttxR5IPxkVVzmV1VOhRvJSJ94M8M+R45M0PMbO1QXdMTzTGVxXz4VK/bb9ncKgDmVJfCIq+Qectfz+t8brfXzuHoKgFSSUgniERLvIPOeeXgtB/8IkWQikNHM6STpBzsbIgzb/Zsr/SbTkG8GVIJrHgyk8IRiLeQbmukLlnE1HALFo7R0dpA4sg+yiNJqJpH/Z6tlE+qpi2e4s23tjNt5rFMmzWfcNlUaNgJBzZ7728hwOhIORrakkypKPEGDptBUQX1kalsaizitBlhwgYu0YZrO0Io0QKhMFgYKueAGanmOurSZUxLH4B0moZEiNboZI6ZOY+65g5mNcc50NxKW8NrHFp3lZUAAAipSURBVFfWQfKYZWza10jL4b2UppopKSunrug4Zs6uZEVlCUtSad442MwzWw+xd34197+8G8P423cv5FBTB8dNLmHXoSYaSFBZUU7d3kZsz6PESiuJTF9IvVWxuzHJqhkhTi0dgljlnBtTPytWrHAT2caNG0f1888991z34IMPdjn27W9/233605/u9TXnnHOOe+GFF5xzzl144YWuvr6+x3Nuvvlm981vfrPgZ993331uw4YN2ftf+cpX3MMPP9yf5hf0N3/zN27mzJkulUoN2XuOlHz/LvC+LI/YtQm8HXgo5/4XgS8Wes1Ev55F+upo17MKydLFFVdcwT333NPl2D333FNwM41c69atY/LkyQP67Pvvv5+NGzuTtFtuuYV3vetdA3qv7rpvpTlchmORmDFkFrAz5/4u/5iIDDMFa+ni0ksv5de//nV2fewdO3awZ88ezjrrLK677jpWrlzJySefzM0335z39fPmzaOuzutUuvXWW1m4cCFnnnlmdhtN8OZQn3rqqdTW1vLBD36Q1tZWnnnmGdauXcvf//3fs3TpUt54440uW1c++uijLFu2jCVLlnD11VfT0dGR/bybb76Z5cuXs2TJEjZv3py3XdpKc+SY2bVmtt7M1gf5PETGkkBu5DFh/OYmb47nUDpmCVzY+5ig6upqVq1axW9+8xvWrFnDPffcw4c+9CHMjFtvvZXq6mpSqRTnn38+f/rTn3jb296W931efPFF7rnnHl5++WWSySTLly9nxYoVAHzgAx/gmmuuAeAf//Ef+dGPfsTnPvc5Lr74Yi666CIuvfTSLu/V3t7OVVddxaOPPsrChQv5+Mc/zu23384NN9wAQE1NDS+99BLf//73+da3vsUPf/jDHu3RVppD4qgzQ2BgsztEpDBl1tJDbik8twR+7733snz5cpYtW8aGDRu6lKy7e/rpp3n/+99PaWkpkyZN4uKLL84+9uqrr3LWWWexZMkSfv7zn/e6xWbGli1bmD9/PgsXevsNX3nllTz11FPZxz/wgQ8AsGLFiuzmH7m0leaQyc4MMbMY3syQIVnvX0QKU2Y9lhXIgIfTmjVruPHGG3nppZdobW1lxYoVbN++nW9961u88MILVFVVcdVVVxXcHrKQq666ivvvv5/a2lruuusunnjiiUG1N7PNZm9bbGorzaHhepkZMsrNEpkQlFlLD+Xl5Zx33nlcffXV2ay6sbGRsrIyKisr2b9/P7/5zW8KvsfZZ5/N/fffT1tbG01NTTzwwAPZx5qampgxYwaJRKJLYKqoqKCpqanHe5144ons2LGDrVu3AvCzn/2Mc845p8/no600h45zbp1zbqFz7njn3K1Hf4WIDAUFa8nriiuu4JVXXskG69raWpYtW8aiRYv4yEc+whlnnFHw9cuXL+fDH/4wtbW1XHjhhZx6auca7t/4xjc47bTTOOOMM1i0aFH2+OWXX843v/lNli1bxhtvdC5yV1xczI9//GMuu+wylixZQigU4tOf/nSfzkNbaYrIeHDUjTxGWiAX/h9C2shjYjraVprayENkfBupjTxEZIC0laaIHI3K4CKj7KabbuLNN9/kzDPPHO2miMgYpWAtIiIyxilYj0FjbRyBjC79exARBesxpri4mEOHDukPtABeoD506BDFxcWj3RQRGUUaYDbGzJ49m127dgV6bWgZWsXFxcyePXu0myEio0jBeoyJRqNdlq0UERFRGVxERGSMU7AWEREZ4xSsRURExrgxt9yomR0E3uzDU2uAumFuzlg0Ec97Ip4zHP28j3XOjcmNrzP6eD3r/+/EovPOr+D1POaCdV+Z2fqxvi7ycJiI5z0RzxkmznlPlPPsTuc9sQz2vFUGFxERGeMUrEVERMa4IAfrO0a7AaNkIp73RDxnmDjnPVHOszud98QyqPMObJ+1iIjIRBHkzFpERGRCCFywNrPVZrbFzLaa2U2j3Z7hZGY7zOzPZvayma33j1Wb2cNm9rr/u2q02zlYZnanmR0ws1dzjuU9T/N81////yczWz56LR+cXs77a2a22/9//rKZvTfnsS/6573FzN4zOq0eWrqedT2Ph+t5JK7lQAVrMwsD3wMuBBYDV5jZ4tFt1bA7zzm3NGfI/03Ao865BcCj/v2guwtY3e1Yb+d5IbDA/7kWuH2E2jgc7qLneQN82/9/vtQ5tw7A/3d+OXCy/5rv+9dDYOl6BnQ9j5fr+S6G+VoOVLAGVgFbnXPbnHNx4B5gzSi3aaStAX7i3/4JcMkotmVIOOeeAg53O9zbea4Bfuo8zwGTzWzGyLR0aPVy3r1ZA9zjnOtwzm0HtuJdD0Gm61nX87i4nkfiWg5asJ4F7My5v8s/Nl454Ldm9qKZXesfm+6c2+vf3gdMH52mDbveznMi/Bv4rF8SvDOnLDoez3s8nlMhup49E+l6HrJrOWjBeqI50zm3HK9U9BkzOzv3QecN5R/3w/knynn6bgeOB5YCe4F/Hd3myBDS9czEOU+G+FoOWrDeDczJuT/bPzYuOed2+78PAPfhlUr2Z8pE/u8Do9fCYdXbeY7rfwPOuf3OuZRzLg38gM7y2Hg87/F4Tr3S9TyxruehvpaDFqxfABaY2Xwzi+F10q8d5TYNCzMrM7OKzG3g3cCreOd7pf+0K4H/GZ0WDrveznMt8HF/FOnpQENOeS3wuvXXvR/v/zl45325mRWZ2Xy8ATnPj3T7hpiuZ13P4/Z6HvJr2TkXqB/gvcBrwBvAl0e7PcN4nscBr/g/GzLnCkzBG035OvAIUD3abR2Cc70br0yUwOu/+avezhMwvBHEbwB/BlaOdvuH+Lx/5p/Xn/yLekbO87/sn/cW4MLRbv8Q/TfQ9azrOfDX80hcy1rBTEREZIwLWhlcRERkwlGwFhERGeMUrEVERMY4BWsREZExTsFaRERkjFOwFhERGeMUrEVERMY4BWsREZEx7v8HsIldENTf9cYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUbcv-JYAvJB",
        "colab_type": "text"
      },
      "source": [
        "###Predict values and use test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQHvN7bupzYp",
        "colab_type": "code",
        "outputId": "1ba75779-b527-46a1-a497-9a50d758dac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "example = df.iloc[[100]]\n",
        "print(f\"Label: {example['diagnosis']}\")\n",
        "data = (example[my_features]).to_numpy()\n",
        "data = tf.convert_to_tensor(data)\n",
        "print(data)\n",
        "model.predict(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 458    0\n",
            "Name: diagnosis, dtype: int64\n",
            "tf.Tensor(\n",
            "[[5.921e-02 9.106e+01 1.762e-02 1.434e+01 8.261e+01 6.285e+02 1.300e+01\n",
            "  5.202e+02 1.206e-02 4.462e-02 5.073e-02 1.093e-01]], shape=(1, 12), dtype=float64)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.89647883, 0.10352115]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAtQONUcg2lK",
        "colab_type": "code",
        "outputId": "e14b6889-1c8f-4907-c541-567a0ed1b036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(len(tf.keras.backend.get_value(test_features)))\n",
        "for test_feature, test_label in zip(test_features, test_labels):\n",
        "  true_label = tf.keras.backend.get_value(test_label)\n",
        "  print(f'Label: {true_label}', end=\"\")\n",
        "\n",
        "  test_feature = tf.expand_dims(test_feature, 0)\n",
        "  predicted = model.predict([[test_feature]])[0]\n",
        "  \n",
        "  if predicted[0] > predicted[1]:\n",
        "    if true_label == 0.0:\n",
        "      print(predicted, \"\\U0000274E\" + \"\\n\")\n",
        "    else:\n",
        "      print(predicted, \"\\U0000274C\" + \"\\n\")\n",
        "  else:\n",
        "    if true_label == 1.0:\n",
        "      print(predicted, \"\\U00002705\" + \"\\n\")\n",
        "    else:\n",
        "      print(predicted, \"\\U0000274C\" + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57\n",
            "Label: 0.0[0.99492115 0.00507888] ❎\n",
            "\n",
            "Label: 0.0[0.99682    0.00318007] ❎\n",
            "\n",
            "Label: 1.0[0.332444   0.66755605] ✅\n",
            "\n",
            "Label: 0.0[0.9966504  0.00334965] ❎\n",
            "\n",
            "Label: 1.0[0.05683011 0.94316995] ✅\n",
            "\n",
            "Label: 0.0[0.7934955  0.20650455] ❎\n",
            "\n",
            "Label: 1.0[0.02287536 0.97712463] ✅\n",
            "\n",
            "Label: 0.0[0.99840873 0.0015913 ] ❎\n",
            "\n",
            "Label: 0.0[0.9802924  0.01970766] ❎\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 0.0[0.88675743 0.11324259] ❎\n",
            "\n",
            "Label: 1.0[0.00964839 0.9903516 ] ✅\n",
            "\n",
            "Label: 1.0[0.05775782 0.9422422 ] ✅\n",
            "\n",
            "Label: 0.0[0.9707817  0.02921834] ❎\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 0.0[0.9975684  0.00243158] ❎\n",
            "\n",
            "Label: 1.0[2.1780832e-07 9.9999976e-01] ✅\n",
            "\n",
            "Label: 1.0[2.50495e-10 1.00000e+00] ✅\n",
            "\n",
            "Label: 1.0[0.02088888 0.97911114] ✅\n",
            "\n",
            "Label: 1.0[0.79783374 0.20216626] ❌\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 0.0[0.95790184 0.04209815] ❎\n",
            "\n",
            "Label: 0.0[0.8914219  0.10857808] ❎\n",
            "\n",
            "Label: 0.0[0.95792305 0.0420769 ] ❎\n",
            "\n",
            "Label: 1.0[0.00553979 0.9944602 ] ✅\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 0.0[0.91218835 0.08781162] ❎\n",
            "\n",
            "Label: 0.0[0.93296987 0.06703013] ❎\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 0.0[0.7614706  0.23852935] ❎\n",
            "\n",
            "Label: 0.0[0.7441603  0.25583968] ❎\n",
            "\n",
            "Label: 0.0[0.9900175  0.00998255] ❎\n",
            "\n",
            "Label: 0.0[0.99078393 0.00921605] ❎\n",
            "\n",
            "Label: 1.0[0.0674233 0.9325767] ✅\n",
            "\n",
            "Label: 0.0[0.8948452  0.10515484] ❎\n",
            "\n",
            "Label: 0.0[0.8001089  0.19989115] ❎\n",
            "\n",
            "Label: 0.0[0.83953613 0.16046382] ❎\n",
            "\n",
            "Label: 0.0[0.99539727 0.00460271] ❎\n",
            "\n",
            "Label: 0.0[0.9896632  0.01033681] ❎\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 0.0[0.9404574 0.0595426] ❎\n",
            "\n",
            "Label: 0.0[0.9696637  0.03033635] ❎\n",
            "\n",
            "Label: 0.0[0.9948769 0.0051231] ❎\n",
            "\n",
            "Label: 0.0[0.9072826  0.09271737] ❎\n",
            "\n",
            "Label: 0.0[0.96705776 0.03294221] ❎\n",
            "\n",
            "Label: 1.0[0.01097567 0.98902434] ✅\n",
            "\n",
            "Label: 1.0[7.761069e-11 1.000000e+00] ✅\n",
            "\n",
            "Label: 0.0[0.89647883 0.10352115] ❎\n",
            "\n",
            "Label: 1.0[0.16240719 0.8375928 ] ✅\n",
            "\n",
            "Label: 0.0[0.8354292  0.16457082] ❎\n",
            "\n",
            "Label: 1.0[1.8122942e-14 1.0000000e+00] ✅\n",
            "\n",
            "Label: 0.0[0.9144049  0.08559506] ❎\n",
            "\n",
            "Label: 0.0[0.85343015 0.14656991] ❎\n",
            "\n",
            "Label: 0.0[0.97527075 0.0247292 ] ❎\n",
            "\n",
            "Label: 0.0[0.84736836 0.1526316 ] ❎\n",
            "\n",
            "Label: 0.0[0.7957487  0.20425127] ❎\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vohvQk8ZW2ql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('./model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db7B8W23XBap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD6j2J8SXCin",
        "colab_type": "code",
        "outputId": "d45e08df-037a-4bcd-8379-c3862535875d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded = tf.keras.models.load_model('./model.h5')\n",
        "reloaded.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yacss5PrX_Tz",
        "colab_type": "code",
        "outputId": "39a98103-febb-4c66-b599-a10bdcadccec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "example = df.iloc[[100]]\n",
        "print(f\"Label: {example['diagnosis']}\")\n",
        "data = (example[my_features]).to_numpy()\n",
        "data = tf.convert_to_tensor(data)\n",
        "print(data)\n",
        "print(model.predict(data))\n",
        "print(reloaded.predict(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 458    0\n",
            "Name: diagnosis, dtype: int64\n",
            "tf.Tensor(\n",
            "[[5.921e-02 9.106e+01 1.762e-02 1.434e+01 8.261e+01 6.285e+02 1.300e+01\n",
            "  5.202e+02 1.206e-02 4.462e-02 5.073e-02 1.093e-01]], shape=(1, 12), dtype=float64)\n",
            "[[0.89647883 0.10352115]]\n",
            "[[0.89647883 0.10352115]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMQ0nlO7YC3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSOiV0HwYSn4",
        "colab_type": "code",
        "outputId": "a69c2dcb-d9bc-4d40-d177-b90a87cbe8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,814\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNSGKE3hYnRL",
        "colab_type": "text"
      },
      "source": [
        "Load model into Tensorflow mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoqYEL7kYWcy",
        "colab_type": "code",
        "outputId": "bdb128f6-7117-48b2-e2b4-34674c60afde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "tf.saved_model.save(model, './modelTF')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ./dosErroresTF/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2S-on1AYvPn",
        "colab_type": "code",
        "outputId": "532aad49-df38-488c-92e7-e6ce730b03d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dosErrores.h5  dosErroresTF.h5\tProyecto-CFGS\n",
            "dosErroresTF   model.zip\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwrUxdwKY3W_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded_tf = tf.saved_model.load('./modelTF')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWXOKymrY_0I",
        "colab_type": "code",
        "outputId": "603e8bca-07c3-442f-df95-561051214a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "reloaded_tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7f04fef71cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ito0Nf0wbB5v",
        "colab_type": "text"
      },
      "source": [
        "Al guardarlo con Tensorflow, el objeto devuelto no tiene las funciones de Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759oPHdOZCeb",
        "colab_type": "code",
        "outputId": "483a9fa1-bae2-4c26-8324-9b4b06968547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "reloaded = tf.keras.models.load_model('./modelTF')\n",
        "reloaded.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                416       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 2,814\n",
            "Trainable params: 2,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUdy-ax8b9Wf",
        "colab_type": "code",
        "outputId": "ffffd200-1acf-40c6-f64d-a2b3b8856868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "!zip -r model.zip ./modelTF\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: dosErroresTF/ (stored 0%)\n",
            "updating: dosErroresTF/assets/ (stored 0%)\n",
            "updating: dosErroresTF/saved_model.pb (deflated 89%)\n",
            "updating: dosErroresTF/variables/ (stored 0%)\n",
            "updating: dosErroresTF/variables/variables.index (deflated 65%)\n",
            "updating: dosErroresTF/variables/variables.data-00000-of-00001 (deflated 21%)\n",
            "dosErrores.h5  dosErroresTF.h5\tProyecto-CFGS\n",
            "dosErroresTF   model.zip\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRh5LRmycGS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('./model.zip')\n",
        "except ImportError:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}